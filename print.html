<!DOCTYPE HTML>
<html lang="pt" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Descomplicando o Prometheus</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="theme/css/style.css">
        <link rel="stylesheet" href="theme/css/mdbook-admonish.css">

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="index.html">Introdução</a></li><li class="spacer"></li><li class="chapter-item expanded affix "><a href="BOOKSUMMARY.html">Sumário</a></li><li class="spacer"></li><li class="chapter-item expanded affix "><li class="part-title">Capítulos</li><li class="chapter-item expanded "><a href="day-1/index.html"><strong aria-hidden="true">1.</strong> Dia 1</a></li><li class="chapter-item expanded "><a href="day-2/index.html"><strong aria-hidden="true">2.</strong> Dia 2</a></li><li class="chapter-item expanded "><a href="day-3/index.html"><strong aria-hidden="true">3.</strong> Dia 3</a></li><li class="chapter-item expanded "><a href="day-4/index.html"><strong aria-hidden="true">4.</strong> Dia 4</a></li><li class="chapter-item expanded "><a href="day-5/index.html"><strong aria-hidden="true">5.</strong> Dia 5</a></li><li class="chapter-item expanded "><a href="day-6/index.html"><strong aria-hidden="true">6.</strong> Dia 6</a></li><li class="chapter-item expanded "><a href="day-7/index.html"><strong aria-hidden="true">7.</strong> Dia 7</a></li><li class="chapter-item expanded "><a href="day-8/index.html"><strong aria-hidden="true">8.</strong> Dia 8</a></li><li class="chapter-item expanded "><a href="day-9/index.html"><strong aria-hidden="true">9.</strong> Dia 9</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Descomplicando o Prometheus</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/badtuxx/DescomplicandoPrometheus" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <h1 id="descomplicando-o-prometheus---o-livro"><a class="header" href="#descomplicando-o-prometheus---o-livro"><a href="https://www.linuxtips.io/course/descomplicando-prometheus">Descomplicando o Prometheus</a> - O LIVRO</a></h1>
<p>Pensamos em fazer um treinamento realmente prático. Um treinamento onde a pessoa consiga aprender os conceitos e toda a teoria com explicações interessantes e excelente didática, com exemplo e desafios práticos para que você consiga executar todo o conhecimento adquirido. Isso é muito importante para que você consiga fixar e explorar ainda mais o conteúdo do treinamento.
E por fim, vamos simular algumas conversas, para que pareça um pouco mais com o dia-a-dia no ambiente de trabalho.</p>
<p>Durante o treinamento vamos passar por todos os tópicos importantes do Prometheus, para que no final do treinamento você possua todo conhecimento e também toda a segurança para implementar e administrar o Prometheus em ambientes críticos e complexos.</p>
<p>Vamos entender o que é o Prometheus e como ele pode nos ajudar a monitorar nossas serviços e sistemas. Vamos aprender diversas formas de instalar e configurar o Prometheus, sempre visando a melhor performance e a cobertura de diversos cenários.
Vamos integra-lo com diversas ferramentas como o Grafana e o AlertManager, trazendo ainda mais poder ao Prometheus. 
Durante o treinamento iremos entender como criar queries performáticas e que consigam nos trazer as informações que precisamos.
Vamos aprender muito sobre exporters, rules e alerts.
Acreditamos que o melhor ambiente para ter o Prometheus sendo executado de maneira segura e em alta disponibilidade é dentro de clusters Kubernetes, portanto durante o treinamento seremos expostos a esse cenário com muita frequência, afinal esse treinamento é para te preparar para a vida real e ambientes reais.
Vamos aprender sobre a utilização de storage para persistir os dados coletas e também como configurar o Prometheus para se beneficiar de todo o dinamismo do service discovery.
Iremos aprender sobre como configurar e utilizar o Push Gateway e claro, aprender a monitorar o próprio Prometheus.</p>
<p>E claro, sempre trazendo exemplos de integrações e de caso de uso reais para ajudar a enriquecer ainda mais o treinamento.</p>
<p>Estamos prontos para iniciar a nossa viagem?</p>
<p> </p>
<p><strong>ACESSE O LIVRO GRATUITAMENTE <a href="https://livro.descomplicandoprometheus.com.br">CLICANDO AQUI</a></strong></p>
<p> </p>
<h3 id="conteúdo-do-livro"><a class="header" href="#conteúdo-do-livro">Conteúdo do Livro</a></h3>
<details>
<summary class="summary">Clique aqui para expandir</summary>
<ul>
<li>
<p><strong><a href="day-1/index.html">DAY-1</a> - Em revisão...</strong></p>
<ul>
<li><a href="day-1/index.html#por-que-precisamos-de-ferramentas-como-o-prometheus">Por que precisamos de ferramentas como o Prometheus?</a></li>
<li><a href="day-1/index.html#o-que-e-monitorar">O que é monitorar?</a>
<ul>
<li><a href="day-1/index.html#o-monitoramento-e-a-observabilidade">O monitoramento e a observabilidade</a></li>
</ul>
</li>
<li><a href="day-1/index.html#o-que-e-o-prometheus">O que é o Prometheus?</a>
<ul>
<li><a href="day-1/index.html#a-arquitetura-do-prometheus">A arquitetura do Prometheus</a></li>
</ul>
</li>
<li><a href="day-1/index.html#instalando-o-prometheus">Instalando o Prometheus</a>
<ul>
<li><a href="day-1/index.html#executando-o-prometheus-em-um-node-linux">Executando o Prometheus em um node Linux</a></li>
<li><a href="day-1/index.html#instala%C3%A7%C3%A3o-do-prometheus-no-linux">Instalação do Prometheus no Linux</a></li>
</ul>
</li>
<li><a href="day-1/index.html#a-sua-li%C3%A7%C3%A3o-de-casa">A sua lição de casa</a></li>
<li><a href="day-1/index.html#desafio-do-day-1">Desafio do Day-1</a></li>
<li><a href="day-1/index.html#final-do-day-1">Final do Day-1</a></li>
</ul>
</li>
<li>
<p><strong><a href="day-2/index.html">DAY-2</a> - Em revisão...</strong></p>
<ul>
<li><a href="day-2/index.html#o-data-model-do-prometheus">O Data Model do Prometheus</a></li>
<li><a href="day-2/index.html#as-queries-do-prometheus-e-o-promql">As queries do Prometheus e o PromQL</a></li>
<li><a href="day-2/index.html#o-nosso-primeiro-exporter">O nosso primeiro exporter</a></li>
<li><a href="day-2/index.html#nosso-primeiro-exporter-no-container">Nosso Primeiro Exporter no Container</a></li>
<li><a href="day-2/index.html#os-targets-do-prometheus">Os Targets do Prometheus</a></li>
<li><a href="day-2/index.html#visualizando-as-m%C3%A9tricas-do-nosso-primeiro-exporter">Visualizando as métricas do nosso primeiro exporter</a></li>
<li><a href="day-2/index.html#conhecendo-um-pouco-mais-sobre-os-tipos-de-dados-do-prometheus">Conhecendo um pouco mais sobre os tipos de dados do Prometheus</a> </li>
<li><a href="day-2/index.html#gauge-medidor">gauge: Medidor</a></li>
<li><a href="day-2/index.html#counter-contador">counter: Contador</a></li>
<li><a href="day-2/index.html#summary-resumo">summary: Resumo</a></li>
<li><a href="day-2/index.html#histogram-histograma">histogram: Histograma</a></li>
<li><a href="day-2/index.html#chega-por-hoje">Chega por hoje!</a></li>
<li><a href="day-2/index.html#li%C3%A7%C3%A3o-de-casa">Lição de casa</a></li>
</ul>
</li>
<li>
<p><strong><a href="day-3/index.html">DAY-3</a> - Em revisão...</strong></p>
<ul>
<li><a href="day-3/index.html#criando-o-nosso-segundo-exporter">Criando o nosso segundo exporter</a>
<ul>
<li><a href="day-3/index.html#criando-o-nosso-exporter-usando-go">Criando o nosso exporter usando Go</a></li>
<li><a href="day-3/index.html#adicionando-o-nosso-exporter-no-container">Adicionando o nosso exporter no container</a></li>
<li><a href="day-3/index.html#adicionando-o-novo-target-no-prometheus">Adicionando o novo Target no Prometheus</a></li>
</ul>
</li>
<li><a href="day-3/index.html#as-fun%C3%A7%C3%B5es">As Funções</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-rate">A função rate</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-irate">A função irate</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-delta">A função delta</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-increase">A função increase</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-sum">A função sum</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-count">A função count</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-avg">A função avg</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-min">A função min</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-max">A função max</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-avg_over_time">A função avg_over_time</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-sum_over_time">A função sum_over_time</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-max_over_time">A função max_over_time</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-min_over_time">A função min_over_time</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-stddev_over_time">A função stddev_over_time</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-by">A função by</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-without">A função without</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-histogram_quantile-e-quantile">A função histogram_quantile e quantile</a></li>
<li><a href="day-3/index.html#praticando-e-usando-as-fun%C3%A7%C3%B5es">Praticando e usando as funções</a></li>
<li><a href="day-3/index.html#operadores">Operadores</a>
<ul>
<li><a href="day-3/index.html#operador-de-igualdade">Operador de igualdade</a></li>
<li><a href="day-3/index.html#operador-de-diferen%C3%A7a">Operador de diferença</a></li>
<li><a href="day-3/index.html#operador-de-maior-que">Operador de maior que</a></li>
<li><a href="day-3/index.html#operador-de-menor-que">Operador de menor que</a></li>
<li><a href="day-3/index.html#operador-de-maior-ou-igual-que">Operador de maior ou igual que</a></li>
<li><a href="day-3/index.html#operador-de-menor-ou-igual-que">Operador de menor ou igual que</a></li>
<li><a href="day-3/index.html#operador-de-multiplica%C3%A7%C3%A3o">Operador de multiplicação</a></li>
<li><a href="day-3/index.html#operador-de-divis%C3%A3o">Operador de divisão</a></li>
<li><a href="day-3/index.html#operador-de-adi%C3%A7%C3%A3o">Operador de adição</a></li>
<li><a href="day-3/index.html#operador-de-subtra%C3%A7%C3%A3o">Operador de subtração</a></li>
<li><a href="day-3/index.html#operador-de-modulo">Operador de modulo</a></li>
<li><a href="day-3/index.html#operador-de-potencia%C3%A7%C3%A3o">Operador de potenciação</a></li>
<li><a href="day-3/index.html#operador-de-agrupamento">Operador de agrupamento</a></li>
<li><a href="day-3/index.html#operador-de-concatena%C3%A7%C3%A3o">Operador de concatenação</a></li>
<li><a href="day-3/index.html#operador-de-compara%C3%A7%C3%A3o-de-strings">Operador de comparação de strings</a></li>
<li><a href="day-3/index.html#chega-de-operadores-por-hoje">Chega de operadores por hoje</a></li>
</ul>
</li>
<li><a href="day-3/index.html#o-node-exporter">O Node Exporter</a>
<ul>
<li><a href="day-3/index.html#os-collectors">Os Collectors</a></li>
<li><a href="day-3/index.html#instala%C3%A7%C3%A3o-do-node-exporter-no-linux">Instalação do Node Exporter no Linux</a></li>
<li><a href="day-3/index.html#adicionando-o-node-exporter-no-prometheus">Adicionando o Node Exporter no Prometheus</a></li>
<li><a href="day-3/index.html#habilitando-novos-collectors-no-node-exporter">Habilitando novos collectors no Node Exporter</a></li>
</ul>
</li>
<li><a href="day-3/index.html#algumas-queries-capturando-m%C3%A9tricas-do-node-exporter">Algumas queries capturando métricas do Node Exporter</a></li>
<li><a href="day-3/index.html#o-grafana">O Grafana</a></li>
<li><a href="day-3/index.html#instala%C3%A7%C3%A3o-do-grafana">Instalação do Grafana</a></li>
<li><a href="day-3/index.html#adicionando-o-prometheus-como-data-source">Adicionando o Prometheus como Data Source</a></li>
<li><a href="day-3/index.html#criando-o-nosso-primeiro-dashboard">Criando o nosso primeiro Dashboard</a></li>
<li><a href="day-3/index.html#chega-por-hoje">Chega por hoje!</a></li>
<li><a href="day-3/index.html#li%C3%A7%C3%A3o-de-casa">Lição de casa</a></li>
<li><a href="day-3/index.html#refer%C3%AAncias">Referências</a></li>
</ul>
</li>
<li>
<p><strong><a href="day-4/index.html">DAY-4</a> - Em revisão...</strong></p>
<ul>
<li><a href="day-4/index.html#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="day-4/index.html#conte%C3%BAdo-do-day-4">Conteúdo do Day-4</a></li>
<li><a href="day-4/index.html#o-grafana">O Grafana</a></li>
<li><a href="day-4/index.html#instalando-o-grafana">Instalando o Grafana</a></li>
<li><a href="day-4/index.html#adicionando-o-prometheus-como-data-source">Adicionando o Prometheus como Data Source</a></li>
<li><a href="day-4/index.html#criando-o-nosso-primeiro-dashboard">Criando o nosso primeiro Dashboard</a></li>
<li><a href="day-4/index.html#alertmanager">Alertmanager</a></li>
<li><a href="day-4/index.html#instalando-o-alertmanager">Instalando o Alertmanager</a></li>
</ul>
</li>
<li>
<p><strong><a href="day-5/index.html">DAY-5</a> - Em revisão...</strong></p>
</li>
<li>
<p><strong><a href="day-6/index.html">DAY-6</a> - Em revisão...</strong></p>
<ul>
<li><a href="day-6/index.html#o-que-iremos-ver-hoje">O que iremos ver hoje</a></li>
<li><a href="day-6/index.html#conte%C3%BAdo-do-day-6">Conteúdo do Day-6</a></li>
<li><a href="day-6/index.html#o-que-%C3%A9-o-kube-prometheus">O que é o kube-prometheus</a></li>
<li><a href="day-6/index.html#instalando-o-nosso-cluster-kubernetes">Instalando o nosso cluster Kubernetes</a></li>
<li><a href="day-6/index.html#instalando-o-kube-prometheus">Instalando o Kube-Prometheus</a></li>
<li><a href="day-6/index.html#acessando-o-grafana">Acessando o Grafana</a></li>
<li><a href="day-6/index.html#acessando-o-prometheus">Acessando o Prometheus</a></li>
<li><a href="day-6/index.html#acessando-o-alertmanager">Acessando o AlertManager</a></li>
<li><a href="day-6/index.html#chega-por-hoje">Chega por hoje!</a></li>
<li><a href="day-6/index.html#li%C3%A7%C3%A3o-de-casa">Lição de casa</a></li>
</ul>
</li>
<li>
<p><strong><a href="day-7/index.html">DAY-7</a> - Em revisão...</strong></p>
<ul>
<li><a href="day-7/index.html#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="day-7/index.html#conte%C3%BAdo-do-day-7">Conteúdo do Day-7</a></li>
<li><a href="day-7/index.html#os-servicemonitors">Os ServiceMonitors</a></li>
<li><a href="day-7/index.html#criando-um-servicemonitor">Criando um ServiceMonitor</a></li>
<li><a href="day-7/index.html#os-podmonitors">Os PodMonitors</a></li>
<li><a href="day-7/index.html#criando-um-podmonitor">Criando um PodMonitor</a></li>
<li><a href="day-7/index.html#criando-nosso-primeiro-alerta">Criando nosso primeiro alerta</a></li>
<li><a href="day-7/index.html#o-que-%C3%A9-um-prometheusrule">O que é um PrometheusRule?</a>
<ul>
<li><a href="day-7/index.html#criando-um-prometheusrule">Criando um PrometheusRule</a></li>
</ul>
</li>
<li><a href="day-7/index.html#chega-por-hoje">Chega por hoje!</a></li>
<li><a href="day-7/index.html#li%C3%A7%C3%A3o-de-casa">Lição de casa</a></li>
</ul>
</li>
<li>
<p><strong><a href="day-8/index.html">DAY-8</a> - Em revisão...</strong></p>
<ul>
<li><a href="day-8/index.html#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="day-8/index.html#conte%C3%BAdo-do-day-8">Conteúdo do Day-8</a></li>
<li><a href="day-8/index.html#vamos-brincar-com-as-m%C3%A9tricas-do-kubernetes">Vamos brincar com as métricas do Kubernetes</a>
<ul>
<li><a href="day-8/index.html#o-que-podemos-saber-sobre-os-nodes-do-nosso-cluster">O que podemos saber sobre os nodes do nosso cluster?</a></li>
<li><a href="day-8/index.html#quantos-n%C3%B3s-temos-no-nosso-cluster">Quantos nós temos no nosso cluster?</a></li>
<li><a href="day-8/index.html#qual-a-quantidade-de-cpu-e-mem%C3%B3ria-que-cada-n%C3%B3-tem">Qual a quantidade de CPU e memória que cada nó tem?</a></li>
<li><a href="day-8/index.html#o-n%C3%B3-est%C3%A1-dispon%C3%ADvel-para-receber-novos-pods">O nó está disponível para receber novos pods?</a></li>
<li><a href="day-8/index.html#qual-a-quantidade-de-informa%C3%A7%C3%A3o-que-cada-n%C3%B3-est%C3%A1-recebendo-e-enviando">Qual a quantidade de informação que cada nó está recebendo e enviando?</a></li>
<li><a href="day-8/index.html#quantos-pods-est%C3%A3o-rodando-em-cada-n%C3%B3">Quantos pods estão rodando em cada nó?</a></li>
</ul>
</li>
<li><a href="day-8/index.html#agora-vamos-saber-se-o-nosso-cluster-est%C3%A1-com-problemas">Agora vamos saber se o nosso cluster está com problemas</a>
<ul>
<li><a href="day-8/index.html#o-que-podemos-saber-sobre-os-pods-do-nosso-cluster">O que podemos saber sobre os pods do nosso cluster?</a></li>
<li><a href="day-8/index.html#quantos-pods-est%C3%A3o-rodando-no-nosso-cluster">Quantos pods estão rodando no nosso cluster?</a></li>
<li><a href="day-8/index.html#quantos-pods-est%C3%A3o-com-problemas">Quantos pods estão com problemas?</a></li>
<li><a href="day-8/index.html#verificar-os-pods-e-os-limites-de-mem%C3%B3ria-e-cpu-configurados">Verificar os pods e os limites de memória e CPU configurados</a></li>
<li><a href="day-8/index.html#verificar-se-o-cluster-est%C3%A1-com-problemas-relacionados-ao-disco">Verificar se o cluster está com problemas relacionados ao disco</a></li>
<li><a href="day-8/index.html#verificar-se-o-cluster-est%C3%A1-com-problemas-relacionados-a-mem%C3%B3ria">Verificar se o cluster está com problemas relacionados a memória</a></li>
</ul>
</li>
<li><a href="day-8/index.html#e-como-saber-se-meus-deployments-est%C3%A3o-com-problemas">E como saber se meus deployments estão com problemas?</a>
<ul>
<li><a href="day-8/index.html#quantos-deployments-est%C3%A3o-rodando-no-meu-cluster">Quantos deployments estão rodando no meu cluster?</a></li>
<li><a href="day-8/index.html#quantos-deployments-est%C3%A3o-com-problemas">Quantos deployments estão com problemas?</a></li>
<li><a href="day-8/index.html#qual-o-status-dos-meus-deployments">Qual o status dos meus deployments?</a></li>
</ul>
</li>
<li><a href="day-8/index.html#e-como-saber-se-meus-servi%C3%A7os-est%C3%A3o-com-problemas">E como saber se meus serviços estão com problemas?</a>
<ul>
<li><a href="day-8/index.html#quantos-servi%C3%A7os-est%C3%A3o-rodando-no-meu-cluster">Quantos serviços estão rodando no meu cluster?</a></li>
<li><a href="day-8/index.html#todos-os-meus-servi%C3%A7os-est%C3%A3o-com-endpoints">Todos os meus serviços estão com endpoints?</a></li>
<li><a href="day-8/index.html#todos-os-meus-servi%C3%A7os-est%C3%A3o-com-endpoints-ativos">Todos os meus serviços estão com endpoints ativos?</a></li>
</ul>
</li>
<li><a href="day-8/index.html#como-eu-posso-modificar-as-configura%C3%A7%C3%B5es-do-meu-prometheus">Como eu posso modificar as configurações do meu Prometheus?</a>
<ul>
<li><a href="day-8/index.html#definindo-o-nosso-prometheus">Definindo o nosso Prometheus</a></li>
<li><a href="day-8/index.html#definindo-o-nosso-alertmanager">Definindo o nosso Alertmanager</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><a href="day-9/index.html">DAY-9</a> - Em revisão...</strong></p>
<ul>
<li><a href="index.html#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="index.html#conte%C3%BAdo-do-day-9">Conteúdo do Day-9</a></li>
<li><a href="index.html#o-que-%C3%A9-relabeling">O que é Relabeling?</a></li>
<li><a href="index.html#como-funciona-o-relabeling">Como funciona o Relabeling?</a></li>
<li><a href="index.html#exemplos-de-uso-do-relabeling">Exemplos de uso do Relabeling</a>
<ul>
<li><a href="index.html#-removendo-uma-m%C3%A9trica-baseado-em-uma-label"> Removendo uma métrica baseado em uma label</a></li>
<li><a href="index.html#junta-duas-labels-em-uma-s%C3%B3">Junta duas labels em uma só</a></li>
<li><a href="index.html#adicionando-uma-nova-label">Adicionando uma nova label</a></li>
<li><a href="index.html#armazenando-somente-m%C3%A9tricas-espec%C3%ADficas">Armazenando somente métricas específicas</a></li>
<li><a href="index.html#mapeando-todas-as-labels-do-kubernetes">Mapeando todas as labels do Kubernetes</a></li>
</ul>
</li>
<li><a href="as-metas-labels-do-prometheus">As meta labels do Prometheus</a></li>
</ul>
</li>
</ul>
</details>
<h3 id="como-adquirir-o-treinamento"><a class="header" href="#como-adquirir-o-treinamento">Como adquirir o treinamento?</a></h3>
<p>Para adquirir o treinamento <a href="https://www.linuxtips.io/course/descomplicando-prometheus">Descomplicando o Prometheus</a> você deverá ir até a loja da <a href="https://www.linuxtips.io/">LINUXtips</a>.</p>
<p>Para ir até o treinamento, <a href="https://www.linuxtips.io/course/descomplicando-prometheus">CLIQUE AQUI</a>.</p>
<h2 id="a-ideia-do-formato-do-treinamento"><a class="header" href="#a-ideia-do-formato-do-treinamento">A ideia do formato do treinamento</a></h2>
<p>Ensinar Prometheus de uma forma mais real, passando todo o conteúdo de forma prática e trazendo uma conexão com o ambiente real de trabalho.</p>
<p>Esse é o primeiro treinamento sobre Prometheus de forma realmente prática, da vida real. Pois entendemos que prática é o conjunto de entendimento sobre um assunto, seguido de exemplos reais que possam ser reproduzidos e conectando tudo isso com a forma como trabalhamos.</p>
<p>Assim a definição de prática passa a ser um focada em o conhecimento da ferramenta e adicionando a realidade de um profissional no seu dia-a-dia aprendendo uma nova tecnologia, uma nova ferramenta.</p>
<p>Prepare-se para um novo tipo de treinamento, e o melhor, prepare-se para um novo conceito sobre treinamento prático e de aprendizado de tecnologia.</p>
<h3 id="as-pessoas-personagens-no-treinamento"><a class="header" href="#as-pessoas-personagens-no-treinamento">As pessoas (personagens) no treinamento</a></h3>
<p>Temos algumas pessoas que vão nos ajudar durante o treinamento, simulando uma dinâmica um pouco maior e ajudando na imersão que gostaríamos. </p>
<p>Ainda estamos desenvolvendo e aprimorando os personagens e o enredo, portanto ainda teremos muitas novidades.</p>
<h4 id="a-pessoa_x"><a class="header" href="#a-pessoa_x">A Pessoa_X</a></h4>
<p>A Pessoa_X é uma das pessoas responsáveis pela loja de meias Strigus Socket, que está no meio da modernização de seu infra e das ferramentas que são utilizadas.</p>
<p>Segundo uma pessoa que já trabalhou com a Pessoa_X, ela é a pessoa que está sempre procurando aprender para inovar em seu ambiente. Normalmente é através dela que surgem as novas ferramentas, bem como a resolução de um monte de problemas.</p>
<p>O nível de conhecimento dela é sempre iniciante quando ela entra em um novo projeto, porém ao final dele, ela se torna uma especialista e com uma boa experiência prática, pois ela foi exposta a diversas situações, que a fizeram conhecer a nova tecnologia muito bem e se sentindo muito confortável em trabalhar no projeto.</p>
<p>Pessoa_X, foi um prazer fazer essa pequena descrição sobre você! </p>
<p>Seja bem-vinda nesse novo projeto e espero que você se divirta como sempre! </p>
<p>Lembre-se sempre que eu, Jeferson, estarei aqui para apoiar você em cada etapa dessa jornada! Eu sou o seu parceiro nesse projeto e tudo o que você precisar nessa jornada! Bora!</p>
<h4 id="a-pessoa_lider_x"><a class="header" href="#a-pessoa_lider_x">A Pessoa_Lider_X</a></h4>
<p>Iremos criando a personalidade dessa pessoa durante o treinamento.
O que já sabemos é que ela é a pessoa líder imediata da Pessoa_X, e que irá demandar a maioria das tarefas. E tem como o esteriótipo um líder meio tosco.</p>
<h4 id="a-pessoa_diretora_x"><a class="header" href="#a-pessoa_diretora_x">A Pessoa_Diretora_X</a></h4>
<p>Líder imediato da Pessoa_Lider_X e que tem um sobrinho 'jênio' e que está ali, dando os seus pitacos no setor de tecnologia, por que ele 'mereceu', entendeu?</p>
<h4 id="a-pessoa_rh_x"><a class="header" href="#a-pessoa_rh_x">A Pessoa_RH_X</a></h4>
<p>A pessoa responsável pelo RH da empresa, no decorrer do treinamento vamos faz
endo a história e características dela.</p>
<h2 id="vamos-começar"><a class="header" href="#vamos-começar">Vamos começar?</a></h2>
<p>Agora que você já conhece mais detalhes sobre o treinamento, acredito que já podemos começar, certo?</p>
<p>Lembrando que o treinamento está disponível na plataforma da escola da LINUXtips,para acessa-la <a href="https://linuxtips.io">CLIQUE AQUI</a>.</p>
<p><strong>Bons estudos!</strong></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="descomplicando-o-prometheus---o-livro-1"><a class="header" href="#descomplicando-o-prometheus---o-livro-1"><a href="https://www.linuxtips.io/course/descomplicando-prometheus">Descomplicando o Prometheus</a> - O LIVRO</a></h1>
<h3 id="conteúdo-do-livro-1"><a class="header" href="#conteúdo-do-livro-1">Conteúdo do Livro</a></h3>
<details>
<summary class="summary">DAY-1</summary>
<ul>
<li><strong><a href="day-1/index.html">DAY-1</a> - Em revisão...</strong>
<ul>
<li><a href="day-1/index.html#por-que-precisamos-de-ferramentas-como-o-prometheus">Por que precisamos de ferramentas como o Prometheus?</a></li>
<li><a href="day-1/index.html#o-que-e-monitorar">O que é monitorar?</a>
<ul>
<li><a href="day-1/index.html#o-monitoramento-e-a-observabilidade">O monitoramento e a observabilidade</a></li>
</ul>
</li>
<li><a href="day-1/index.html#o-que-e-o-prometheus">O que é o Prometheus?</a>
<ul>
<li><a href="day-1/index.html#a-arquitetura-do-prometheus">A arquitetura do Prometheus</a></li>
</ul>
</li>
<li><a href="day-1/index.html#instalando-o-prometheus">Instalando o Prometheus</a>
<ul>
<li><a href="day-1/index.html#executando-o-prometheus-em-um-node-linux">Executando o Prometheus em um node Linux</a></li>
<li><a href="day-1/index.html#instala%C3%A7%C3%A3o-do-prometheus-no-linux">Instalação do Prometheus no Linux</a></li>
</ul>
</li>
<li><a href="day-1/index.html#a-sua-li%C3%A7%C3%A3o-de-casa">A sua lição de casa</a></li>
<li><a href="day-1/index.html#desafio-do-day-1">Desafio do Day-1</a></li>
<li><a href="day-1/index.html#final-do-day-1">Final do Day-1</a></li>
</ul>
</li>
</ul>
</details>
<p> </p>
<details>
<summary class="summary">DAY-2</summary>
<ul>
<li><strong><a href="day-2/index.html">DAY-2</a> - Em revisão...</strong>
<ul>
<li><a href="day-2/index.html#o-data-model-do-prometheus">O Data Model do Prometheus</a></li>
<li><a href="day-2/index.html#as-queries-do-prometheus-e-o-promql">As queries do Prometheus e o PromQL</a></li>
<li><a href="day-2/index.html#o-nosso-primeiro-exporter">O nosso primeiro exporter</a></li>
<li><a href="day-2/index.html#nosso-primeiro-exporter-no-container">Nosso Primeiro Exporter no Container</a></li>
<li><a href="day-2/index.html#os-targets-do-prometheus">Os Targets do Prometheus</a></li>
<li><a href="day-2/index.html#visualizando-as-m%C3%A9tricas-do-nosso-primeiro-exporter">Visualizando as métricas do nosso primeiro exporter</a></li>
<li><a href="day-2/index.html#conhecendo-um-pouco-mais-sobre-os-tipos-de-dados-do-prometheus">Conhecendo um pouco mais sobre os tipos de dados do Prometheus</a> </li>
<li><a href="day-2/index.html#gauge-medidor">gauge: Medidor</a></li>
<li><a href="day-2/index.html#counter-contador">counter: Contador</a></li>
<li><a href="day-2/index.html#summary-resumo">summary: Resumo</a></li>
<li><a href="day-2/index.html#histogram-histograma">histogram: Histograma</a></li>
<li><a href="day-2/index.html#chega-por-hoje">Chega por hoje!</a></li>
<li><a href="day-2/index.html#li%C3%A7%C3%A3o-de-casa">Lição de casa</a></li>
</ul>
</li>
</ul>
</details>
<p> </p>
<details>
<summary class="summary">DAY-3</summary>
<ul>
<li><strong><a href="day-3/index.html">DAY-3</a> - Em revisão...</strong>
<ul>
<li><a href="day-3/index.html#criando-o-nosso-segundo-exporter">Criando o nosso segundo exporter</a>
<ul>
<li><a href="day-3/index.html#criando-o-nosso-exporter-usando-go">Criando o nosso exporter usando Go</a></li>
<li><a href="day-3/index.html#adicionando-o-nosso-exporter-no-container">Adicionando o nosso exporter no container</a></li>
<li><a href="day-3/index.html#adicionando-o-novo-target-no-prometheus">Adicionando o novo Target no Prometheus</a></li>
</ul>
</li>
<li><a href="day-3/index.html#as-fun%C3%A7%C3%B5es">As Funções</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-rate">A função rate</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-irate">A função irate</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-delta">A função delta</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-increase">A função increase</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-sum">A função sum</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-count">A função count</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-avg">A função avg</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-min">A função min</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-max">A função max</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-avg_over_time">A função avg_over_time</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-sum_over_time">A função sum_over_time</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-max_over_time">A função max_over_time</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-min_over_time">A função min_over_time</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-stddev_over_time">A função stddev_over_time</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-by">A função by</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-without">A função without</a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-histogram_quantile-e-quantile">A função histogram_quantile e quantile</a></li>
<li><a href="day-3/index.html#praticando-e-usando-as-fun%C3%A7%C3%B5es">Praticando e usando as funções</a></li>
<li><a href="day-3/index.html#operadores">Operadores</a>
<ul>
<li><a href="day-3/index.html#operador-de-igualdade">Operador de igualdade</a></li>
<li><a href="day-3/index.html#operador-de-diferen%C3%A7a">Operador de diferença</a></li>
<li><a href="day-3/index.html#operador-de-maior-que">Operador de maior que</a></li>
<li><a href="day-3/index.html#operador-de-menor-que">Operador de menor que</a></li>
<li><a href="day-3/index.html#operador-de-maior-ou-igual-que">Operador de maior ou igual que</a></li>
<li><a href="day-3/index.html#operador-de-menor-ou-igual-que">Operador de menor ou igual que</a></li>
<li><a href="day-3/index.html#operador-de-multiplica%C3%A7%C3%A3o">Operador de multiplicação</a></li>
<li><a href="day-3/index.html#operador-de-divis%C3%A3o">Operador de divisão</a></li>
<li><a href="day-3/index.html#operador-de-adi%C3%A7%C3%A3o">Operador de adição</a></li>
<li><a href="day-3/index.html#operador-de-subtra%C3%A7%C3%A3o">Operador de subtração</a></li>
<li><a href="day-3/index.html#operador-de-modulo">Operador de modulo</a></li>
<li><a href="day-3/index.html#operador-de-potencia%C3%A7%C3%A3o">Operador de potenciação</a></li>
<li><a href="day-3/index.html#operador-de-agrupamento">Operador de agrupamento</a></li>
<li><a href="day-3/index.html#operador-de-concatena%C3%A7%C3%A3o">Operador de concatenação</a></li>
<li><a href="day-3/index.html#operador-de-compara%C3%A7%C3%A3o-de-strings">Operador de comparação de strings</a></li>
<li><a href="day-3/index.html#chega-de-operadores-por-hoje">Chega de operadores por hoje</a></li>
</ul>
</li>
<li><a href="day-3/index.html#o-node-exporter">O Node Exporter</a>
<ul>
<li><a href="day-3/index.html#os-collectors">Os Collectors</a></li>
<li><a href="day-3/index.html#instala%C3%A7%C3%A3o-do-node-exporter-no-linux">Instalação do Node Exporter no Linux</a></li>
<li><a href="day-3/index.html#adicionando-o-node-exporter-no-prometheus">Adicionando o Node Exporter no Prometheus</a></li>
<li><a href="day-3/index.html#habilitando-novos-collectors-no-node-exporter">Habilitando novos collectors no Node Exporter</a></li>
</ul>
</li>
<li><a href="day-3/index.html#algumas-queries-capturando-m%C3%A9tricas-do-node-exporter">Algumas queries capturando métricas do Node Exporter</a></li>
<li><a href="day-3/index.html#o-grafana">O Grafana</a></li>
<li><a href="day-3/index.html#instala%C3%A7%C3%A3o-do-grafana">Instalação do Grafana</a></li>
<li><a href="day-3/index.html#adicionando-o-prometheus-como-data-source">Adicionando o Prometheus como Data Source</a></li>
<li><a href="day-3/index.html#criando-o-nosso-primeiro-dashboard">Criando o nosso primeiro Dashboard</a></li>
<li><a href="day-3/index.html#chega-por-hoje">Chega por hoje!</a></li>
<li><a href="day-3/index.html#li%C3%A7%C3%A3o-de-casa">Lição de casa</a></li>
<li><a href="day-3/index.html#refer%C3%AAncias">Referências</a></li>
</ul>
</li>
</ul>
</details>
<p> </p>
<details>
<summary class="summary">DAY-4</summary>
<ul>
<li><strong><a href="day-4/index.html">DAY-4</a> - Em revisão...</strong>
<ul>
<li><a href="day-4/index.html#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="day-4/index.html#conte%C3%BAdo-do-day-4">Conteúdo do Day-4</a></li>
<li><a href="day-4/index.html#o-grafana">O Grafana</a></li>
<li><a href="day-4/index.html#instalando-o-grafana">Instalando o Grafana</a></li>
<li><a href="day-4/index.html#adicionando-o-prometheus-como-data-source">Adicionando o Prometheus como Data Source</a></li>
<li><a href="day-4/index.html#criando-o-nosso-primeiro-dashboard">Criando o nosso primeiro Dashboard</a></li>
<li><a href="day-4/index.html#alertmanager">Alertmanager</a></li>
<li><a href="day-4/index.html#instalando-o-alertmanager">Instalando o Alertmanager</a></li>
</ul>
</li>
</ul>
</details>
<p> </p>
<details>
<summary class="summary">DAY-5</summary>
<ul>
<li><strong><a href="day-5/index.html">DAY-5</a> - Em revisão...</strong></li>
</ul>
</details>
<p> </p>
<details>
<summary class="summary">DAY-6</summary>
<ul>
<li><strong><a href="day-6/index.html">DAY-6</a> - Em revisão...</strong>
<ul>
<li><a href="day-6/index.html#o-que-iremos-ver-hoje">O que iremos ver hoje</a></li>
<li><a href="day-6/index.html#conte%C3%BAdo-do-day-6">Conteúdo do Day-6</a></li>
<li><a href="day-6/index.html#o-que-%C3%A9-o-kube-prometheus">O que é o kube-prometheus</a></li>
<li><a href="day-6/index.html#instalando-o-nosso-cluster-kubernetes">Instalando o nosso cluster Kubernetes</a></li>
<li><a href="day-6/index.html#instalando-o-kube-prometheus">Instalando o Kube-Prometheus</a></li>
<li><a href="day-6/index.html#acessando-o-grafana">Acessando o Grafana</a></li>
<li><a href="day-6/index.html#acessando-o-prometheus">Acessando o Prometheus</a></li>
<li><a href="day-6/index.html#acessando-o-alertmanager">Acessando o AlertManager</a></li>
<li><a href="day-6/index.html#chega-por-hoje">Chega por hoje!</a></li>
<li><a href="day-6/index.html#li%C3%A7%C3%A3o-de-casa">Lição de casa</a></li>
</ul>
</li>
</ul>
</details>
<p> </p>
<details>
<summary class="summary">DAY-7</summary>
<ul>
<li><strong><a href="day-7/index.html">DAY-7</a> - Em revisão...</strong>
<ul>
<li><a href="day-7/index.html#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="day-7/index.html#conte%C3%BAdo-do-day-7">Conteúdo do Day-7</a></li>
<li><a href="day-7/index.html#os-servicemonitors">Os ServiceMonitors</a></li>
<li><a href="day-7/index.html#criando-um-servicemonitor">Criando um ServiceMonitor</a></li>
<li><a href="day-7/index.html#os-podmonitors">Os PodMonitors</a></li>
<li><a href="day-7/index.html#criando-um-podmonitor">Criando um PodMonitor</a></li>
<li><a href="day-7/index.html#criando-nosso-primeiro-alerta">Criando nosso primeiro alerta</a></li>
<li><a href="day-7/index.html#o-que-%C3%A9-um-prometheusrule">O que é um PrometheusRule?</a>
<ul>
<li><a href="day-7/index.html#criando-um-prometheusrule">Criando um PrometheusRule</a></li>
</ul>
</li>
<li><a href="day-7/index.html#chega-por-hoje">Chega por hoje!</a></li>
<li><a href="day-7/index.html#li%C3%A7%C3%A3o-de-casa">Lição de casa</a></li>
</ul>
</li>
</ul>
</details>
<p> </p>
<details>
<summary class="summary">DAY-8</summary>
<ul>
<li><strong><a href="day-8/index.html">DAY-8</a> - Em revisão...</strong>
<ul>
<li><a href="day-8/index.html#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="day-8/index.html#conte%C3%BAdo-do-day-8">Conteúdo do Day-8</a></li>
<li><a href="day-8/index.html#vamos-brincar-com-as-m%C3%A9tricas-do-kubernetes">Vamos brincar com as métricas do Kubernetes</a>
<ul>
<li><a href="day-8/index.html#o-que-podemos-saber-sobre-os-nodes-do-nosso-cluster">O que podemos saber sobre os nodes do nosso cluster?</a></li>
<li><a href="day-8/index.html#quantos-n%C3%B3s-temos-no-nosso-cluster">Quantos nós temos no nosso cluster?</a></li>
<li><a href="day-8/index.html#qual-a-quantidade-de-cpu-e-mem%C3%B3ria-que-cada-n%C3%B3-tem">Qual a quantidade de CPU e memória que cada nó tem?</a></li>
<li><a href="day-8/index.html#o-n%C3%B3-est%C3%A1-dispon%C3%ADvel-para-receber-novos-pods">O nó está disponível para receber novos pods?</a></li>
<li><a href="day-8/index.html#qual-a-quantidade-de-informa%C3%A7%C3%A3o-que-cada-n%C3%B3-est%C3%A1-recebendo-e-enviando">Qual a quantidade de informação que cada nó está recebendo e enviando?</a></li>
<li><a href="day-8/index.html#quantos-pods-est%C3%A3o-rodando-em-cada-n%C3%B3">Quantos pods estão rodando em cada nó?</a></li>
</ul>
</li>
<li><a href="day-8/index.html#agora-vamos-saber-se-o-nosso-cluster-est%C3%A1-com-problemas">Agora vamos saber se o nosso cluster está com problemas</a>
<ul>
<li><a href="day-8/index.html#o-que-podemos-saber-sobre-os-pods-do-nosso-cluster">O que podemos saber sobre os pods do nosso cluster?</a></li>
<li><a href="day-8/index.html#quantos-pods-est%C3%A3o-rodando-no-nosso-cluster">Quantos pods estão rodando no nosso cluster?</a></li>
<li><a href="day-8/index.html#quantos-pods-est%C3%A3o-com-problemas">Quantos pods estão com problemas?</a></li>
<li><a href="day-8/index.html#verificar-os-pods-e-os-limites-de-mem%C3%B3ria-e-cpu-configurados">Verificar os pods e os limites de memória e CPU configurados</a></li>
<li><a href="day-8/index.html#verificar-se-o-cluster-est%C3%A1-com-problemas-relacionados-ao-disco">Verificar se o cluster está com problemas relacionados ao disco</a></li>
<li><a href="day-8/index.html#verificar-se-o-cluster-est%C3%A1-com-problemas-relacionados-a-mem%C3%B3ria">Verificar se o cluster está com problemas relacionados a memória</a></li>
</ul>
</li>
<li><a href="day-8/index.html#e-como-saber-se-meus-deployments-est%C3%A3o-com-problemas">E como saber se meus deployments estão com problemas?</a>
<ul>
<li><a href="day-8/index.html#quantos-deployments-est%C3%A3o-rodando-no-meu-cluster">Quantos deployments estão rodando no meu cluster?</a></li>
<li><a href="day-8/index.html#quantos-deployments-est%C3%A3o-com-problemas">Quantos deployments estão com problemas?</a></li>
<li><a href="day-8/index.html#qual-o-status-dos-meus-deployments">Qual o status dos meus deployments?</a></li>
</ul>
</li>
<li><a href="day-8/index.html#e-como-saber-se-meus-servi%C3%A7os-est%C3%A3o-com-problemas">E como saber se meus serviços estão com problemas?</a>
<ul>
<li><a href="day-8/index.html#quantos-servi%C3%A7os-est%C3%A3o-rodando-no-meu-cluster">Quantos serviços estão rodando no meu cluster?</a></li>
<li><a href="day-8/index.html#todos-os-meus-servi%C3%A7os-est%C3%A3o-com-endpoints">Todos os meus serviços estão com endpoints?</a></li>
<li><a href="day-8/index.html#todos-os-meus-servi%C3%A7os-est%C3%A3o-com-endpoints-ativos">Todos os meus serviços estão com endpoints ativos?</a></li>
</ul>
</li>
<li><a href="day-8/index.html#como-eu-posso-modificar-as-configura%C3%A7%C3%B5es-do-meu-prometheus">Como eu posso modificar as configurações do meu Prometheus?</a>
<ul>
<li><a href="day-8/index.html#definindo-o-nosso-prometheus">Definindo o nosso Prometheus</a></li>
<li><a href="day-8/index.html#definindo-o-nosso-alertmanager">Definindo o nosso Alertmanager</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</details>
<p> </p>
<details>
<summary class="summary">DAY-9</summary>
<ul>
<li><strong><a href="day-9/index.html">DAY-9</a> - Em revisão...</strong>
<ul>
<li><a href="day-9/index.html#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="day-9/index.html#conte%C3%BAdo-do-day-9">Conteúdo do Day-9</a></li>
<li><a href="day-9/index.html#o-que-%C3%A9-relabeling">O que é Relabeling?</a></li>
<li><a href="day-9/index.html#como-funciona-o-relabeling">Como funciona o Relabeling?</a></li>
<li><a href="day-9/index.html#exemplos-de-uso-do-relabeling">Exemplos de uso do Relabeling</a>
<ul>
<li><a href="day-9/index.html#-removendo-uma-m%C3%A9trica-baseado-em-uma-label"> Removendo uma métrica baseado em uma label</a></li>
<li><a href="day-9/index.html#junta-duas-labels-em-uma-s%C3%B3">Junta duas labels em uma só</a></li>
<li><a href="day-9/index.html#adicionando-uma-nova-label">Adicionando uma nova label</a></li>
<li><a href="day-9/index.html#armazenando-somente-m%C3%A9tricas-espec%C3%ADficas">Armazenando somente métricas específicas</a></li>
<li><a href="day-9/index.html#mapeando-todas-as-labels-do-kubernetes">Mapeando todas as labels do Kubernetes</a></li>
</ul>
</li>
<li><a href="day-9/index.html#as-meta-labels-do-prometheus">As meta labels do Prometheus</a></li>
</ul>
</li>
</ul>
</details>
<p> </p>
<details>
<summary class="summary">REVISAR</summary><!-- #TODO -->
<ul>
<li><strong><a href="day-3">DAY-3</a> - Em revisão...</strong></li>
<li><a href="day-3/#criando-o-nosso-segundo-exporter">Criando o nosso segundo exporter</a>
<ul>
<li><a href="day-3/#criando-o-nosso-exporter-usando-go">Criando o nosso exporter usando Go</a></li>
<li><a href="day-3/#adicionando-o-nosso-exporter-no-container">Adicionando o nosso exporter no container</a></li>
<li><a href="day-3/#adicionando-o-novo-target-no-prometheus">Adicionando o novo Target no Prometheus</a></li>
</ul>
</li>
<li><a href="day-3/#as-fun%C3%A7%C3%B5es">As Funções</a>
<ul>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-rate">A função rate</a></li>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-irate">A função irate</a></li>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-delta">A função delta</a></li>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-increase">A função increase</a></li>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-sum">A função sum</a></li>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-count">A função count</a></li>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-avg">A função avg</a></li>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-min">A função min</a></li>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-max">A função max</a></li>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-avg_over_time">A função avg_over_time</a></li>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-sum_over_time">A função sum_over_time</a></li>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-max_over_time">A função max_over_time</a></li>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-min_over_time">A função min_over_time</a></li>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-stddev_over_time">A função stddev_over_time</a></li>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-by">A função by</a></li>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-without">A função without</a></li>
<li><a href="day-3/#a-fun%C3%A7%C3%A3o-histogram_quantile-e-quantile">A função histogram_quantile e quantile</a></li>
</ul>
</li>
<li><a href="day-3/#praticando-e-usando-as-fun%C3%A7%C3%B5es">Praticando e usando as funções</a></li>
<li><a href="day-3/#operadores">Operadores</a>
<ul>
<li><a href="day-3/#operador-de-igualdade">Operador de igualdade</a></li>
<li><a href="day-3/#operador-de-diferen%C3%A7a">Operador de diferença</a></li>
<li><a href="day-3/#operador-de-maior-que">Operador de maior que</a></li>
<li><a href="day-3/#operador-de-menor-que">Operador de menor que</a></li>
<li><a href="day-3/#operador-de-maior-ou-igual-que">Operador de maior ou igual que</a></li>
<li><a href="day-3/#operador-de-menor-ou-igual-que">Operador de menor ou igual que</a></li>
<li><a href="day-3/#operador-de-multiplica%C3%A7%C3%A3o">Operador de multiplicação</a></li>
<li><a href="day-3/#operador-de-divis%C3%A3o">Operador de divisão</a></li>
<li><a href="day-3/#operador-de-adi%C3%A7%C3%A3o">Operador de adição</a></li>
<li><a href="day-3/#operador-de-subtra%C3%A7%C3%A3o">Operador de subtração</a></li>
<li><a href="day-3/#operador-de-modulo">Operador de modulo</a></li>
<li><a href="day-3/#operador-de-potencia%C3%A7%C3%A3o">Operador de potenciação</a></li>
<li><a href="day-3/#operador-de-agrupamento">Operador de agrupamento</a></li>
<li><a href="day-3/#operador-de-concatena%C3%A7%C3%A3o">Operador de concatenação</a></li>
<li><a href="day-3/#operador-de-compara%C3%A7%C3%A3o-de-strings">Operador de comparação de strings</a></li>
<li><a href="day-3/#chega-de-operadores-por-hoje">Chega de operadores por hoje</a></li>
</ul>
</li>
<li><a href="day-3/#o-node-exporter">O Node Exporter</a>
<ul>
<li><a href="day-3/#os-collectors">Os Collectors</a></li>
<li><a href="day-3/#instala%C3%A7%C3%A3o-do-node-exporter-no-linux">Instalação do Node Exporter no Linux</a></li>
<li><a href="day-3/#adicionando-o-node-exporter-no-prometheus">Adicionando o Node Exporter no Prometheus</a></li>
<li><a href="day-3/#habilitando-novos-collectors-no-node-exporter">Habilitando novos collectors no Node Exporter</a></li>
</ul>
</li>
<li><a href="day-3/#algumas-queries-capturando-m%C3%A9tricas-do-node-exporter">Algumas queries capturando métricas do Node Exporter</a></li>
<li><a href="day-3/#o-grafana">O Grafana</a>
<ul>
<li><a href="day-3/#instala%C3%A7%C3%A3o-do-grafana">Instalação do Grafana</a></li>
<li><a href="day-3/#adicionando-o-prometheus-como-data-source">Adicionando o Prometheus como Data Source</a></li>
<li><a href="day-3/#criando-o-nosso-primeiro-dashboard">Criando o nosso primeiro Dashboard</a></li>
</ul>
</li>
<li><a href="day-3/#chega-por-hoje">Chega por hoje!</a></li>
<li><a href="day-3/#li%C3%A7%C3%A3o-de-casa">Lição de casa</a></li>
<li><a href="day-3/#refer%C3%AAncias">Referências</a></li>
</ul>
<p> </p>
<ul>
<li><strong><a href="day-4">DAY-4</a> - Em revisão...</strong></li>
<li><a href="day-4/#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="day-4/#conte%C3%BAdo-do-day-4">Conteúdo do Day-4</a></li>
<li><a href="day-4/#o-grafana">O Grafana</a>
<ul>
<li><a href="day-4/#instalando-o-grafana">Instalando o Grafana</a></li>
<li><a href="day-4/#adicionando-o-prometheus-como-data-source">Adicionando o Prometheus como Data Source</a></li>
<li><a href="day-4/#criando-o-nosso-primeiro-dashboard">Criando o nosso primeiro Dashboard</a></li>
</ul>
</li>
<li><a href="day-4/#alertmanager">Alertmanager</a>
<ul>
<li><a href="day-4/#instalando-o-alertmanager">Instalando o Alertmanager</a></li>
</ul>
</li>
</ul>
<p> </p>
<ul>
<li><strong><a href="day-5">DAY-5</a> - Em revisão...</strong></li>
</ul>
<p> </p>
<ul>
<li><strong><a href="day-6">DAY-6</a> - Em revisão...</strong></li>
<li><a href="day-6/#o-que-iremos-ver-hoje">O que iremos ver hoje</a></li>
<li><a href="day-6/#conte%C3%BAdo-do-day-6">Conteúdo do Day-6</a></li>
<li><a href="day-6/#o-que-%C3%A9-o-kube-prometheus">O que é o kube-prometheus</a>
<ul>
<li><a href="day-6/#instalando-o-nosso-cluster-kubernetes">Instalando o nosso cluster Kubernetes</a></li>
<li><a href="day-6/#instalando-o-kube-prometheus">Instalando o Kube-Prometheus</a></li>
<li><a href="day-6/#acessando-o-grafana">Acessando o Grafana</a></li>
<li><a href="day-6/#acessando-o-prometheus">Acessando o Prometheus</a></li>
<li><a href="day-6/#acessando-o-alertmanager">Acessando o AlertManager</a></li>
</ul>
</li>
<li><a href="day-6/#chega-por-hoje">Chega por hoje!</a></li>
<li><a href="day-6/#li%C3%A7%C3%A3o-de-casa">Lição de casa</a></li>
</ul>
<p> </p>
<ul>
<li><strong><a href="day-7">DAY-7</a> - Em revisão...</strong></li>
<li><a href="day-7/#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="day-7/#conte%C3%BAdo-do-day-7">Conteúdo do Day-7</a>
<ul>
<li><a href="day-7/#os-servicemonitors">Os ServiceMonitors</a></li>
<li><a href="day-7/#criando-um-servicemonitor">Criando um ServiceMonitor</a></li>
<li><a href="day-7/#os-podmonitors">Os PodMonitors</a></li>
<li><a href="day-7/#criando-um-podmonitor">Criando um PodMonitor</a></li>
<li><a href="day-7/#criando-nosso-primeiro-alerta">Criando nosso primeiro alerta</a></li>
<li><a href="day-7/#o-que-%C3%A9-um-prometheusrule">O que é um PrometheusRule?</a>
<ul>
<li><a href="day-7/#criando-um-prometheusrule">Criando um PrometheusRule</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="day-7/#chega-por-hoje">Chega por hoje!</a></li>
<li><a href="day-7/#li%C3%A7%C3%A3o-de-casa">Lição de casa</a></li>
</ul>
<p> </p>
<ul>
<li><strong><a href="day-8">DAY-8</a> - Em revisão...</strong></li>
<li><a href="day-8/#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="day-8/#conte%C3%BAdo-do-day-8">Conteúdo do Day-8</a>
<ul>
<li><a href="day-8/#vamos-brincar-com-as-m%C3%A9tricas-do-kubernetes">Vamos brincar com as métricas do Kubernetes</a>
<ul>
<li><a href="day-8/#o-que-podemos-saber-sobre-os-nodes-do-nosso-cluster">O que podemos saber sobre os nodes do nosso cluster?</a>
<ul>
<li><a href="day-8/#quantos-n%C3%B3s-temos-no-nosso-cluster">Quantos nós temos no nosso cluster?</a></li>
<li><a href="day-8/#qual-a-quantidade-de-cpu-e-mem%C3%B3ria-que-cada-n%C3%B3-tem">Qual a quantidade de CPU e memória que cada nó tem?</a></li>
<li><a href="day-8/#o-n%C3%B3-est%C3%A1-dispon%C3%ADvel-para-receber-novos-pods">O nó está disponível para receber novos pods?</a></li>
<li><a href="day-8/#qual-a-quantidade-de-informa%C3%A7%C3%A3o-que-cada-n%C3%B3-est%C3%A1-recebendo-e-enviando">Qual a quantidade de informação que cada nó está recebendo e enviando?</a></li>
</ul>
</li>
<li><a href="day-8/#quantos-pods-est%C3%A3o-rodando-em-cada-n%C3%B3">Quantos pods estão rodando em cada nó?</a></li>
</ul>
</li>
<li><a href="day-8/#agora-vamos-saber-se-o-nosso-cluster-est%C3%A1-com-problemas">Agora vamos saber se o nosso cluster está com problemas</a>
<ul>
<li><a href="day-8/#o-que-podemos-saber-sobre-os-pods-do-nosso-cluster">O que podemos saber sobre os pods do nosso cluster?</a>
<ul>
<li><a href="day-8/#quantos-pods-est%C3%A3o-rodando-no-nosso-cluster">Quantos pods estão rodando no nosso cluster?</a></li>
<li><a href="day-8/#quantos-pods-est%C3%A3o-com-problemas">Quantos pods estão com problemas?</a></li>
<li><a href="day-8/#verificar-os-pods-e-os-limites-de-mem%C3%B3ria-e-cpu-configurados">Verificar os pods e os limites de memória e CPU configurados</a></li>
<li><a href="day-8/#verificar-se-o-cluster-est%C3%A1-com-problemas-relacionados-ao-disco">Verificar se o cluster está com problemas relacionados ao disco</a></li>
<li><a href="day-8/#verificar-se-o-cluster-est%C3%A1-com-problemas-relacionados-a-mem%C3%B3ria">Verificar se o cluster está com problemas relacionados a memória</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="day-8/#e-como-saber-se-meus-deployments-est%C3%A3o-com-problemas">E como saber se meus deployments estão com problemas?</a>
<ul>
<li><a href="day-8/#quantos-deployments-est%C3%A3o-rodando-no-meu-cluster">Quantos deployments estão rodando no meu cluster?</a></li>
<li><a href="day-8/#quantos-deployments-est%C3%A3o-com-problemas">Quantos deployments estão com problemas?</a></li>
<li><a href="day-8/#qual-o-status-dos-meus-deployments">Qual o status dos meus deployments?</a></li>
</ul>
</li>
<li><a href="day-8/#e-como-saber-se-meus-servi%C3%A7os-est%C3%A3o-com-problemas">E como saber se meus serviços estão com problemas?</a>
<ul>
<li><a href="day-8/#quantos-servi%C3%A7os-est%C3%A3o-rodando-no-meu-cluster">Quantos serviços estão rodando no meu cluster?</a></li>
<li><a href="day-8/#todos-os-meus-servi%C3%A7os-est%C3%A3o-com-endpoints">Todos os meus serviços estão com endpoints?</a></li>
<li><a href="day-8/#todos-os-meus-servi%C3%A7os-est%C3%A3o-com-endpoints-ativos">Todos os meus serviços estão com endpoints ativos?</a></li>
</ul>
</li>
<li><a href="day-8/#como-eu-posso-modificar-as-configura%C3%A7%C3%B5es-do-meu-prometheus">Como eu posso modificar as configurações do meu Prometheus?</a>
<ul>
<li><a href="day-8/#definindo-o-nosso-prometheus">Definindo o nosso Prometheus</a></li>
<li><a href="day-8/#definindo-o-nosso-alertmanager">Definindo o nosso Alertmanager</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p> </p>
<ul>
<li><strong><a href="day-9">DAY-9</a> - Em revisão...</strong></li>
<li><a href="day-9#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="day-9#conte%C3%BAdo-do-day-9">Conteúdo do Day-9</a></li>
<li><a href="day-9#o-que-%C3%A9-relabeling">O que é Relabeling?</a>
<ul>
<li><a href="day-9#como-funciona-o-relabeling">Como funciona o Relabeling?</a></li>
<li><a href="day-9#exemplos-de-uso-do-relabeling">Exemplos de uso do Relabeling</a>
<ul>
<li><a href="day-9#-removendo-uma-m%C3%A9trica-baseado-em-uma-label"> Removendo uma métrica baseado em uma label</a></li>
<li><a href="day-9#junta-duas-labels-em-uma-s%C3%B3">Junta duas labels em uma só</a></li>
<li><a href="day-9#adicionando-uma-nova-label">Adicionando uma nova label</a></li>
<li><a href="day-9#armazenando-somente-m%C3%A9tricas-espec%C3%ADficas">Armazenando somente métricas específicas</a></li>
<li><a href="day-9#mapeando-todas-as-labels-do-kubernetes">Mapeando todas as labels do Kubernetes</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="day-9#as-metas-labels-do-prometheus">As meta labels do Prometheus</a></li>
</ul>
</details><div style="break-before: page; page-break-before: always;"></div><h1 id="descomplicando-o-prometheus---o-treinamento"><a class="header" href="#descomplicando-o-prometheus---o-treinamento"><a href="https://www.linuxtips.io/course/descomplicando-prometheus">Descomplicando o Prometheus</a> - O Treinamento</a></h1>
<h2 id="day-1"><a class="header" href="#day-1">DAY-1</a></h2>
<p> </p>
<h3 id="o-que-iremos-ver-hoje"><a class="header" href="#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></h3>
<p>Durante o dia de hoje, nós iremos focar em o que é o Prometheus e qual problema ele resolve.
Iremos entender os diferentes tipos de monitoramento e as diferenças entre eles.
Hoje é dia de conhecer a história do Prometheus e também a motivação para a sua criação lá na SoundCloud.
Vamos entender a arquitetura do Prometheus e como ele se relaciona com outros aplicativos.
E por fim, vamos instalar o Prometheus e fazer a nossa primeira configuração para o nosso mais novo serviço de monitoração.
Teremos ainda o nosso primeiro contato com a interface web do Prometheus e vamos criar a nossa primeira query.</p>
<p> </p>
<h3 id="conteúdo-do-day-1"><a class="header" href="#conteúdo-do-day-1">Conteúdo do Day-1</a></h3>
<details>
<summary class="summary">DAY-1</summary>
<ul>
<li><a href="day-1/index.html#por-que-precisamos-de-ferramentas-como-o-prometheus">Por que precisamos de ferramentas como o Prometheus?</a></li>
<li><a href="day-1/index.html#o-que-%C3%A9-monitorar">O que é monitorar?</a>
<ul>
<li><a href="day-1/index.html#o-monitoramento-e-a-observabilidade">O monitoramento e a observabilidade</a></li>
</ul>
</li>
<li><a href="day-1/index.html#o-que-%C3%A9-o-prometheus">O que é o Prometheus?</a>
<ul>
<li><a href="day-1/index.html#a-arquitetura-do-prometheus">A arquitetura do Prometheus</a></li>
</ul>
</li>
<li><a href="day-1/index.html#instalando-o-prometheus">Instalando o Prometheus</a>
<ul>
<li><a href="day-1/index.html#executando-o-prometheus-em-um-node-linux">Executando o Prometheus em um node Linux</a></li>
<li><a href="day-1/index.html#instala%C3%A7%C3%A3o-do-prometheus-no-linux">Instalação do Prometheus no Linux</a></li>
</ul>
</li>
<li><a href="day-1/index.html#a-sua-li%C3%A7%C3%A3o-de-casa">A sua lição de casa</a></li>
<li><a href="day-1/index.html#desafio-do-day-1">Desafio do Day-1</a></li>
<li><a href="day-1/index.html#final-do-day-1">Final do Day-1</a></li>
</ul>
</details>
<h3 id="por-que-precisamos-de-ferramentas-como-o-prometheus"><a class="header" href="#por-que-precisamos-de-ferramentas-como-o-prometheus">Por que precisamos de ferramentas como o Prometheus?</a></h3>
<p>Sei que ainda não falamos sobre o que é monitoramento em si, mas acho importante trazer esse cenário para que você entenda depois o que é e para que serve o Prometheus e essa tal de monitoração.</p>
<p>Bem, como você sabe toda empresa possui um ambiente, onde uma ou mais aplicações estão em execução consumindo algum recurso computacional, seja local, em algum datacenter ou ainda em algum cloud provider, o que é mais comum hoje em dia.</p>
<p>Vamos imaginar que temos um loja online, o famoso e-commerce. Você consegue imaginar a quantidade componentes que temos que monitorar para ter a certeza, ou quase, de que tudo está funcionando como o esperado?</p>
<p>No caso do e-commerce, vamos imaginar algo bem simples e pequeno. Para ter um loja online você precisa de um servidor web, vamos pegar o Nginx.
Mas para rodar o Nginx nós vamos precisar de uma VM, container, Pod ou uma instancia no cloud, logo já temos mais coisas para nos preocupar.</p>
<p>Vamos imaginar que escolhemos rodar o Nginx em uma VM, somente para simplificar as coisas por enquanto. Se temos a VM, temos um hypervisor que está gerenciando a VM, temos o host onde a VM está sendo executada, temos o Linux que está instalado na VM onde o Nginx está rodando. Sem contar todos os elementos de redes envolvidos durante as requisições a essa nossa loja.</p>
<p>Com isso você já consegue imaginar o tamanho da encrenca, e olha que estamos falando de uma loja simples rodando em uma VM, sem se preocupar com ambientes complexos em alta disponibilidade, resilientes e que devem seguir normas para se adequarem a determinados nichos de mercado ou legislação local.</p>
<p>Se a gente parar para pensar somente nos itens que temos que monitorar somente no host que está hospedando essa VM já seria uma lista bem grande, e com bastante trabalho para os próximos dias.</p>
<p>Definitivamente o que não faltam são coisas que precisamos monitorar em nosso ambiente.</p>
<p>Se começar a pensar bem, vai ver que a monitoração é muito importante para as coisas do nosso dia-a-dia, onde não tem relação com o nosso trabalho. Por exemplo, agora enquanto escrevo esse material estou acompanhando o vôo de volta para o Brasil da minha Mãe e da minha sogra, tudo isso graças a algum sistema de monitoramento, que me traz esse informação em tempo real.</p>
<p>Perceba que monitoramento não é somente necessário para quando as coisas dão problema, o monitoramento é importante para acompanhar padrão, para entender como os seus sistemas estão operando, para acompanhar determinada atividade, como é o meu caso agora acompanhando o vôo.</p>
<p>Para nós profissionais de tecnologia, é fundamental ter um bom entendimento sobre a importância e como implementar um bom sistema de monitoramento para nossos serviços e sistemas.
Somente através do monitoramento vamos conseguir ter confiabilidade e eficiência em nossos serviços, trazendo muito valor ao negócio por conta da eficiência e disponibilidade de nossos sistemas.</p>
<p>Através da monitoração iremos entender se o nosso serviço está totalmente operacional ou se está degradado, entregando uma péssima experiência para os nossos usuários.</p>
<p> </p>
<h3 id="o-que-é-monitorar"><a class="header" href="#o-que-é-monitorar">O que é monitorar?</a></h3>
<p>No meu entendimento, monitorar significa ter o status atual sobre o item desejado. No caso de uma máquina física rodando Linux, eu quero monitorar o hardware para ter certeza de que problemas de aquecimento de CPU não irão atrapalhar a disponibilidade do meu sistema. Ainda usando esse exemplo, temos que monitorar o sistema operacional, pois não queremos que um disco cheio ou uma placa de rede sobrecarregada onerando o sistema inteiro.
Isso que ainda nem falamos do sistema operacional da VM e nem da própria aplicação, o Nginx.</p>
<p>Monitorar é você saber o que está acontecendo em sua infra, em sua app, em seu serviço em tempo real e em caso de falha ou anomalia, que as pessoas envolvidas para a recuperação daquele componente sejam notificadas com o máximo de informação para auxiliar o troubleshooting.</p>
<p> </p>
<h4 id="o-monitoramento-e-a-observabilidade"><a class="header" href="#o-monitoramento-e-a-observabilidade">O monitoramento e a observabilidade</a></h4>
<p>Agora que você já sabe o que significa monitorar (pelo menos no meu ponto de vista), acho que já podemos trazer um pouco mais de tempero nessa conversa, digo, trazer mais recursos para conseguir monitorar ainda melhor o nosso ambiente.</p>
<p>Usando ainda o exemplo do Nginx rodando em uma VM Linux, nós estávamos falando sobre possíveis <strong>eventos</strong> sobre falhas hardware ou coletando <strong>métricas</strong> sobre a carga de informações trafegando em nossa placa de rede, agora imagina descer um pouco mais o nível e poder <strong>medir o tempo de cada requisição</strong> que nosso servidor web está tratando?</p>
<p>Imagina ainda receber e armazenar todos <strong>os logs</strong> das requisições que retornaram erro para o nosso usuário ou que contenham informações sobre o desempenho de nossa aplicação?</p>
<p>Ou ainda, imagina fazer todo o <strong>acompanhamento da requisição</strong> do usuário, desde o momento que ela chegou no primeiro serviço de nossa infra, até o último milésimo de vida daquela requisição após ela passear por diversos serviços de nosso ambiente e ainda podendo entender e visualizar <strong>métricas</strong> internas sobre o comportamento e o consumo de recursos por sua aplicação?</p>
<p>E agora o melhor, imagine reunir toda essa informação e poder correlaciona-las, e ainda, visualizar essas informações de maneira <strong>gráfica</strong>, através de bonitos e informativos dashboards com gráficos e tabelas dos mais variados tipos?</p>
<p>Imaginou?</p>
<p>Pronto, você foi capaz de imaginar um ambiente onde seria possível ter a observabilidade em sua melhor forma! </p>
<p>Observability normalmente é apoiada principalmente em 3 pilares:</p>
<ul>
<li>Logs</li>
<li>Metrics</li>
<li>Traces</li>
</ul>
<p> </p>
<p>Eu adiciono mais um item nessa lista, o Eventos. Ter os eventos que ocorrem em seu ambiente e correlaciona-lo com os demais pilares é sensacional demais e ajuda muito a entender o comportamento de um item no momento de um problema ou degradação do serviço. 
Então eu vou atualizar essa lista e adiciona-lo. :D</p>
<ul>
<li>Logs</li>
<li>Métricas</li>
<li>Traces</li>
<li>Eventos</li>
</ul>
<p> </p>
<p>E para ser sincero, eu ainda adicionaria Dashboards pois acho que é fundamental ver de modo mais visual possível o resultado dos 4 pilares correlacionados através de gráficos que irão ajudar a entender o comportamento de determinado item em seu momento de falha ou degradação.</p>
<p>Se você possui um sistema para observar o seu ambiente que cobre esses 4 pilares, parabéns! \o/</p>
<p>Nos exemplos que eu listei acima e pedi para você imaginar, você pode verificar que temos exemplos para os quatro pilares da observabilidade. Volta lá e confere! </p>
<p>Eu estava certo, né? haha</p>
<p>Ok, eu sei que você já entendeu tudo isso e agora está se perguntado:</p>
<p>E o que o Prometheus tem haver com tudo isso?</p>
<p>E eu te explico logo abaixo: :D</p>
<p> </p>
<h3 id="o-que-é-o-prometheus"><a class="header" href="#o-que-é-o-prometheus">O que é o Prometheus?</a></h3>
<p>O Prometheus é um dos mais modernos sistemas de monitoramento, capas de coletar e guardar métricas dos mais variados componentes de suas infra-estrutura. O inicio de seu desenvolvimento se deu em 2012, porém somente foi anunciado oficialmente pela SoundCloud em 2015. Ele foi inspirado no Borgmon, plataforma de monitoramento no Google, responsável por monitor o Borg, plataforma de gerenciamento de containers do Google e conhecido também por ser o pai do Kubernetes.</p>
<p>O Prometheus além de ser uma ótima ferramenta para coletar métricas, ele também é capaz de armazena-las em seu próprio TSDB. Sim, ele também é um time series database! </p>
<p>Eu não traduzi o time series database por que acho estranho falar banco de dados temporais, apesar de ser o certo em português. haha</p>
<p>Quando falamos de time series database, estamos basicamente falando sobre um banco de dados construindo para ter uma excelente performance no armazenamento e leitura de dados que são armazenados com data e hora. Sendo assim é um banco de dados projetado para lidar muito bem com dados, como por exemplo as métricas, onde é importante a data e hora. Seja na leitura e resgate de um minuto especifico durante o dia ou então na facilidade e performance para armazenar e organizar milhares, ou até milhões, de mensagens por hora. </p>
<p>É possível ainda realizar riquíssimas queries para buscar a melhor correlação de métricas e visualizar através de dashboards, em sua bonita e intuitiva interface. Nós vamos falar muito mais sobre isso no decorrer do treinamento.</p>
<p>E antes que eu me esqueça, quando falamos em observabilidade, o Prometheus se encaixa no pilar <em>Métricas</em>, pois ele tem como função coletar e armazenar métricas de diferentes componentes em suas infra-estrutura.
E para não falar que eu não falei sobre opções de ferramentas para as outras pilastras, segue:</p>
<ul>
<li>Logs -&gt; Graylog ou Datadog</li>
<li>Métricas -&gt; Prometheus</li>
<li>Traces -&gt; Jaeger ou eBPF</li>
<li>Eventos -&gt; Zabbix ou Datadog</li>
<li>Visualização/Dashboards -&gt; Grafana, Datadog ou Pixie</li>
</ul>
<p> </p>
<p>Pronto, agora acho que já sabemos o que é monitoração, observabilidade e o Prometheus, acho que já podemos começar a aprofundar o nosso conhecimento nessa sensacional ferramenta, o Prometheus!</p>
<p> </p>
<h4 id="a-arquitetura-do-prometheus"><a class="header" href="#a-arquitetura-do-prometheus">A arquitetura do Prometheus</a></h4>
<p>Fiz um desenho da arquitetura do Prometheus para que possamos ter um melhor entendimento de como ele funciona.</p>
<p><img src="day-1/images/arquitetura-prometheus.jpg" alt="Arquitetura do Prometheus" /></p>
<p> </p>
<p>Perceba que temos 03 componentes <em>core</em> no Prometheus:</p>
<ul>
<li>Retrieval</li>
<li>Storage</li>
<li>PromQL</li>
</ul>
<p> </p>
<p>O <em>Retrieval</em> é o responsável por coletar as métricas e conversar com o <em>Storage</em> para armazená-las. É o <em>Retrieval</em> também o responsável por conversar com o Service Discovery para encontrar os serviços que estão disponíveis para coletar métricas.</p>
<p>Já o <em>Storage</em> é o responsável por armazenar as métricas no TSDB, lembre-se que o TSDB é um time series database, super importante para otimizar a performance de coleta e leitura das métricas. Importante lembrar que o <em>Storage</em> armazena as métricas no disco local do node que ele está sendo executado. Com isso, caso você esteja com o Prometheus instalado em uma VM, os dados serão armazenados no disco local da VM.</p>
<p>O <em>PromQL</em> é o responsável por executar as queries do usuário. Ele é o responsável por conversar com o <em>Storage</em> para buscar as métricas que o usuário deseja.
O <em>PromQL</em> é uma riquíssima linguagem de consulta, ela não é parecida com outras linguagens de consulta como o SQL, por exemplo.</p>
<p>Durante o treinamento nós teremos diversos exemplos de como construir queries para o <em>PromQL</em> e como o <em>PromQL</em> pode nos ajudar a obter as métricas que precisamos.</p>
<p>Mas somente para dar um gostinho do que vem pela frente, veja um pequeno exemplo de como o <em>PromQL</em> funciona:</p>
<pre><code class="language-promql">query = 'avg(rate(container_cpu_usage_seconds_total{container_name!=&quot;meu-nginx&quot;,image!=&quot;nginx&quot;}[5m]))'
</code></pre>
<p>Nesse exemplo, o <em>PromQL</em> está buscando a média da taxa de uso de CPU de todos os containers que não tenham o nome &quot;meu-nginx&quot; e que não estejam utilizando a imagem de container &quot;nginx&quot;.</p>
<p>Perceba que um fator super importante no ecossistema do Prometheus é a quantidade e a facilidade de integra-lo com outras ferramentas, como o Grafana, Alertmanager, Zabbix e por aí vai.</p>
<p> </p>
<h3 id="instalando-o-prometheus"><a class="header" href="#instalando-o-prometheus">Instalando o Prometheus</a></h3>
<p>Agora que já sabemos o que é monitoração, observabilidade e o Prometheus, acho que já é o momento de começar a brincar com a estrela desse treinamento, o Prometheus!</p>
<p>É possível realizar a instalação do Prometheus de diversas maneiras. Podemos utilizar uma VM, instancia em algum cloud provider, ou mesmo instalar o Prometheus em um servidor físico local. 
Mas é claro que é possível ter o Prometheus rodando em containers, seja em sua máquina local utilizando Docker ou outro container runtime. Agora se o objetivo é ter o Prometheus rodando em ambiente produtivo é necessário utilizar um orquestrador de containers, como o Kubernetes ou Nomad.</p>
<p>Vamos começar a instalar o Prometheus em uma máquina Linux. Está máquina Linux poderia ser facilmente uma VM, instancia em algum cloud provider, ou mesmo um servidor físico local.</p>
<p>Essa é a nossa primeira instalação do Prometheus, fique tranquilo que no decorrer do treinamento vamos utilizar outras formas, visando passar todo o conhecimento para que você se sinta seguro em utilizar o Prometheus no seu ambiente. E Lembre-se, o nosso foco é ter um treinamento que se aproxima o máximo possível do que seria em seu ambiente de trabalho.</p>
<p> </p>
<h4 id="executando-o-prometheus-em-um-node-linux"><a class="header" href="#executando-o-prometheus-em-um-node-linux">Executando o Prometheus em um node Linux</a></h4>
<p>Uma coisa muito importante é estar familiarizado com o site do Prometheus, pois é de lá que vamos aprender todos os detalhes do Prometheus através da documentação, além de acompanhar outros detalhes e novidades do projeto.</p>
<p>Você pode acessar o site do Prometheus em: https://prometheus.io/</p>
<p>Você pode acessar a seção de Download do site do Prometheus em: https://prometheus.io/download/</p>
<p>Para fazer a execução do Prometheus no Linux de uma maneira que irá funcionar na maioria das distribuições, vamos fazer da seguinte forma:</p>
<p>Primeiro vamos fazer o download do binário do Prometheus, lembrando que existem binários para Linux, Windows e MacOS.</p>
<p>Na verdade, vamos fazer o download dos binários, pois dentro do pacote .tar.gz, existem dois binários, o binário do <strong>Prometheus</strong> e o binário do <strong>Promtool</strong>.</p>
<p>O <strong>Promtool</strong> é um utilitário super legal que permite que você execute queries no Prometheus via linha de comando, ou seja, você pode executar queries no Prometheus através do terminal.</p>
<p>Já o binário do <strong>Prometheus</strong> é o <em>Prometheus Server</em> e que faz toda a mágica acontecer.</p>
<p>Ainda existe o diretório <strong>consoles</strong>, <strong>console_libraries</strong> e o arquivo <strong>prometheus.yml</strong>, que é o arquivo de configuração do Prometheus.</p>
<p>Bom, já sabemos de todos os detalhes, bora começar!</p>
<p>Fazendo o download:</p>
<pre><code class="language-bash">curl -LO https://github.com/prometheus/prometheus/releases/download/v2.38.0/prometheus-2.38.0.linux-amd64.tar.gz
</code></pre>
<p> </p>
<p>Após o download, vamos extrair o arquivo e acessar o diretório extraído.</p>
<pre><code class="language-bash">tar -xvf prometheus-2.38.0.linux-amd64.tar.gz
cd prometheus-2.38.0.linux-amd64
</code></pre>
<p> </p>
<p>Como mencionado anteriormente, o arquivo <strong>prometheus.yml</strong> é o arquivo de configuração do Prometheus e será ele que iremos utilizar para configurar o Prometheus nesse nosso primeiro exemplo.</p>
<p>Vamos ver o conteúdo do arquivo:</p>
<pre><code class="language-yaml"># my global config
global:
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - &quot;first_rules.yml&quot;
  # - &quot;second_rules.yml&quot;

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.
  - job_name: &quot;prometheus&quot;

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
      - targets: [&quot;localhost:9090&quot;]
</code></pre>
<p> </p>
<p>Vamos tirar alguns comentários e remover os campos que não iremos utilizar por agora.</p>
<pre><code class="language-yaml">global: # Configurações globais do Prometheus, ou seja, configurações que serão utilizadas em todos os jobs caso não sejam configuradas separadamente dentro de cada job.
  
  scrape_interval: 15s # Intervalo de coleta dos dados, ou seja, a cada 15 segundos o Prometheus vai até o alvo monitorado coletar as métricas, o padrão é 1 minuto.
  
  evaluation_interval: 15s # Intervalo para o Prometheus avaliar as regras de alerta, o padrão é 1 minuto. Não estamos utilizando regras para os alertas, vamos manter aqui somente para referência.

  scrape_timeout: 10s # Intervalos para o Prometheus aguardar o alvo monitorado responder antes de considerar que o alvo está indisponível, o padrão é 10 segundos.

rule_files: # Inicio da definição das regras de alerta, nesse primeiro exemplo vamos deixar sem regras, pois não iremos utilizar alertas por agora.

scrape_configs: # Inicio da definição das configurações de coleta, ou seja, como o Prometheus vai coletar as métricas e onde ele vai encontrar essas métricas.

  - job_name: &quot;prometheus&quot; # Nome do job, ou seja, o nome do serviço que o Prometheus vai monitorar.

    static_configs: # Inicio da definição das configurações estáticas, ou seja, configurações que não serão alteradas durante o processo de coleta.

      - targets: [&quot;localhost:9090&quot;] # Endereço do alvo monitorado, ou seja, o endereço do serviço que o Prometheus vai monitorar. Nesse caso é o próprio Prometheus.
</code></pre>
<p> </p>
<p>Eu tirei a parte referente ao AlertManager, pois não iremos utilizar ele neste momento para deixar as coisas mais simples e darmos o nosso primeiro passo.</p>
<p>Para saber o que cada linha significa, eu adicionei um comentário em cada uma delas explicando o que ela faz.</p>
<p>Agora que já deixamos o arquivo da forma como queremos e já sabemos cada detalhe, vamos executar o binário do Prometheus.</p>
<pre><code class="language-bash">./prometheus

ts=2022-08-17T13:08:21.924Z caller=main.go:495 level=info msg=&quot;No time or size retention was set so using the default time retention&quot; duration=15d
ts=2022-08-17T13:08:21.924Z caller=main.go:539 level=info msg=&quot;Starting Prometheus Server&quot; mode=server version=&quot;(version=2.38.0, branch=HEAD, revision=818d6e60888b2a3ea363aee8a9828c7bafd73699)&quot;
ts=2022-08-17T13:08:21.924Z caller=main.go:544 level=info build_context=&quot;(go=go1.18.5, user=root@e6b781f65453, date=20220816-13:23:14)&quot;
ts=2022-08-17T13:08:21.924Z caller=main.go:545 level=info host_details=&quot;(Linux 5.18.10-76051810-generic #202207071639~1659403207~22.04~cb5f582 SMP PREEMPT_DYNAMIC Tue A x86_64 nu-derval (none))&quot;
ts=2022-08-17T13:08:21.924Z caller=main.go:546 level=info fd_limits=&quot;(soft=1024, hard=1048576)&quot;
ts=2022-08-17T13:08:21.924Z caller=main.go:547 level=info vm_limits=&quot;(soft=unlimited, hard=unlimited)&quot;
ts=2022-08-17T13:08:21.926Z caller=web.go:553 level=info component=web msg=&quot;Start listening for connections&quot; address=0.0.0.0:9090
ts=2022-08-17T13:08:21.926Z caller=main.go:976 level=info msg=&quot;Starting TSDB ...&quot;
ts=2022-08-17T13:08:21.927Z caller=tls_config.go:195 level=info component=web msg=&quot;TLS is disabled.&quot; http2=false
ts=2022-08-17T13:08:21.928Z caller=head.go:495 level=info component=tsdb msg=&quot;Replaying on-disk memory mappable chunks if any&quot;
ts=2022-08-17T13:08:21.928Z caller=head.go:538 level=info component=tsdb msg=&quot;On-disk memory mappable chunks replay completed&quot; duration=1.773µs
ts=2022-08-17T13:08:21.928Z caller=head.go:544 level=info component=tsdb msg=&quot;Replaying WAL, this may take a while&quot;
ts=2022-08-17T13:08:21.928Z caller=head.go:615 level=info component=tsdb msg=&quot;WAL segment loaded&quot; segment=0 maxSegment=0
ts=2022-08-17T13:08:21.928Z caller=head.go:621 level=info component=tsdb msg=&quot;WAL replay completed&quot; checkpoint_replay_duration=9.788µs wal_replay_duration=213.05µs total_replay_duration=237.767µs
ts=2022-08-17T13:08:21.928Z caller=main.go:997 level=info fs_type=XFS_SUPER_MAGIC
ts=2022-08-17T13:08:21.929Z caller=main.go:1000 level=info msg=&quot;TSDB started&quot;
ts=2022-08-17T13:08:21.929Z caller=main.go:1181 level=info msg=&quot;Loading configuration file&quot; filename=prometheus.yml
ts=2022-08-17T13:08:21.931Z caller=main.go:1218 level=info msg=&quot;Completed loading of configuration file&quot; filename=prometheus.yml totalDuration=2.070216ms db_storage=531ns remote_storage=1.002µs web_handler=220ns query_engine=420ns scrape=1.716011ms scrape_sd=201.818µs notify=1.222µs notify_sd=4.198µs rules=1.473µs tracing=8.426µs
ts=2022-08-17T13:08:21.931Z caller=main.go:961 level=info msg=&quot;Server is ready to receive web requests.&quot;
ts=2022-08-17T13:08:21.931Z caller=manager.go:941 level=info component=&quot;rule manager&quot; msg=&quot;Starting rule manager...&quot;
</code></pre>
<p> </p>
<p>Através da linha abaixo podemos ver que o prometheus está rodando.</p>
<pre><code class="language-bash">ts=2022-08-17T13:08:21.931Z caller=main.go:961 level=info msg=&quot;Server is ready to receive web requests.&quot;
</code></pre>
<p> </p>
<p>Evidentemente, estamos utilizando o Prometheus dessa forma apenas para testes e para que possamos dar os primeiros passos em nosso treinamento.</p>
<p>Se você pressionar CTRL+C, o Prometheus irá ser finalizado.</p>
<p>Caso você queira executar o Prometheus e deixar o seu terminal livre e independente do processo do Prometheus, você pode fazer isso através do comando abaixo.</p>
<pre><code class="language-bash">nohup ./prometheus &amp;
</code></pre>
<p> </p>
<p>Assim ele irá rodar em segundo plano e não será interrompido caso você feche o terminal.</p>
<p>Mas lembre-se novamente, estamos fazendo isso somente para dar os primeiros passos, não vá colocar isso em ambiente de produção, e ainda dizer que aprendeu comigo, seria muita mancada. hahaha</p>
<p>Para verificar se o processo está em execução, basta fazer o seguinte:</p>
<pre><code class="language-bash">ps -ef | grep prometheus
jeferson   23539    6584  0 16:20 pts/0    00:00:00 ./prometheus
</code></pre>
<p> </p>
<p>Vamos deixar o terminal de lado por um segundo, e bora acessar a interface web do Prometheus usando o nosso navegador.</p>
<p>O Prometheus roda por padrão na porta TCP 9090, portanto vamos acessar a interface web através do seguinte endereço:</p>
<pre><code class="language-bash">http://localhost:9090
</code></pre>
<p> </p>
<p>A tela que você vê é a seguinte, correto?</p>
<p><img src="day-1/./images/interface_web_prometheus.png" alt="Interface web do Prometheus" /></p>
<p> </p>
<p>Nós vamos brincar bastante nessa interface e iremos conhecer cada pixel dela, porém por agora vamos apenas testar uma query super simples, somente para dar um gostinho de como funciona.</p>
<p>Na barra de criação de queries, vamos escrever a query que queremos testar.</p>
<pre><code class="language-promql">process_cpu_seconds_total{job=&quot;prometheus&quot;}[1m]
</code></pre>
<p> </p>
<p><img src="day-1/./images/barra_criacao_queries.png" alt="Barra de criação de queries" /></p>
<p> </p>
<p>Nessa query, estamos pegando os valores da métrica process_cpu_seconds_total, que é a métrica que nos informa o tempo de CPU gasto por cada processo, filtrando apenas pelos jobs que tem o nome prometheus e estamos pegando somente os valores do último minuto.</p>
<p>Você lembra que definimos no arquivo de configuração do Prometheus o parâmetro <em>scrape_interval</em> para que ele coletasse os dados a cada 15 segundos? </p>
<p>Eu espero que sim! :D</p>
<p>Então, se tudo está correndo bem você terá como resultado da query acima 4 valores, afinal estamos pegando os valores do último minuto.</p>
<p><img src="day-1/./images/resultado_query.png" alt="Resultado da query" /></p>
<p> </p>
<p>Muito bem, já demos o primeiro passo para o nosso treinamento, já conhecemos a cara do Prometheus e inclusive fizemos a nossa primeira query.</p>
<p>Agora vamos ver uma instalação da maneira correta em uma máquina Linux. Ainda vamos utilizar a configuração básica do Prometheus, mas iremos cuidar dos binários e do serviço do Prometheus da maneira correta. :D</p>
<p> </p>
<h4 id="instalação-do-prometheus-no-linux"><a class="header" href="#instalação-do-prometheus-no-linux">Instalação do Prometheus no Linux</a></h4>
<p>Vamos fazer a instalação em uma máquina Linux rodando a distribuição Ubuntu, mas lembre-se que é possível fazer isso em qualquer outra distribuição.</p>
<p>Primeiro vamos fazer o download do binário do Prometheus, lembrando que existem binários para Linux, Windows e MacOS.</p>
<p>Na verdade, vamos fazer o download dos binários, pois dentro do pacote .tar.gz, existem dois binários, o binário do <strong>Prometheus</strong> e o binário do <strong>Promtool</strong>.</p>
<p>O <strong>Promtool</strong> é um utilitário super legal que permite que você execute queries no Prometheus via linha de comando, ou seja, você pode executar queries no Prometheus através do terminal.</p>
<p>Já o binário do <strong>Prometheus</strong> é o <em>Prometheus Server</em> e que faz toda a mágica acontecer.</p>
<p>Ainda existe o diretório <strong>consoles</strong>, <strong>console_libraries</strong> e o arquivo <strong>prometheus.yml</strong>, que é o arquivo de configuração do Prometheus.</p>
<p>Bom, já sabemos de todos os detalhes, bora começar!</p>
<p>Fazendo o download:</p>
<pre><code class="language-bash">curl -LO https://github.com/prometheus/prometheus/releases/download/v2.38.0/prometheus-2.38.0.linux-amd64.tar.gz
</code></pre>
<p> </p>
<p>Após o download, vamos extrair os arquivos.</p>
<pre><code class="language-bash">tar -xvf prometheus-2.38.0.linux-amd64.tar.gz
</code></pre>
<p> </p>
<p>Agora vamos mover os binários para o diretório /usr/local/bin.</p>
<pre><code class="language-bash">sudo mv prometheus-2.38.0.linux-amd64/prometheus /usr/local/bin/prometheus
sudo mv prometheus-2.38.0.linux-amd64/promtool /usr/local/bin/promtool
</code></pre>
<p> </p>
<p>Vamos ver se o binário está funcionando.</p>
<pre><code class="language-bash">prometheus --version

prometheus, version 2.38.0 (branch: HEAD, revision: 818d6e60888b2a3ea363aee8a9828c7bafd73699)
  build user:       root@e6b781f65453
  build date:       20220816-13:23:14
  go version:       go1.18.5
  platform:         linux/amd64
</code></pre>
<p> </p>
<p>Agora vamos criar o diretório de configuração do Prometheus.</p>
<pre><code class="language-bash">sudo mkdir /etc/prometheus
</code></pre>
<p> </p>
<p>Vamos mover os diretórios <em>consoles</em>, <em>console_libraries</em> e o arquivo <em>prometheus.yml</em> para o diretório de configuração do Prometheus.</p>
<pre><code class="language-bash">sudo mv prometheus-2.38.0.linux-amd64/prometheus.yml /etc/prometheus/prometheus.yml
sudo mv prometheus-2.38.0.linux-amd64/consoles /etc/prometheus
sudo mv prometheus-2.38.0.linux-amd64/console_libraries /etc/prometheus
</code></pre>
<p> </p>
<p>Vamos editar o arquivo de configuração do Prometheus para deixar como fizemos em nosso primeiro exemplo.</p>
<pre><code class="language-bash">sudo vim /etc/prometheus/prometheus.yml
</code></pre>
<p> </p>
<p>Agora edite o arquivo e deixe com o seguinte conteúdo: (você pode remover os comentários para deixar mais simples o arquivo)</p>
<pre><code class="language-yaml">global: # Configurações globais do Prometheus, ou seja, configurações que serão utilizadas em todos os jobs caso não sejam configuradas separadamente dentro de cada job.
  
  scrape_interval: 15s # Intervalo de coleta dos dados, ou seja, a cada 15 segundos o Prometheus vai até o alvo monitorado coletar as métricas, o padrão é 1 minuto.
  
  evaluation_interval: 15s # Intervalo para o Prometheus avaliar as regras de alerta, o padrão é 1 minuto. Não estamos utilizando regras para os alertas, vamos manter aqui somente para referência.

  scrape_timeout: 10s # Intervalos para o Prometheus aguardar o alvo monitorado responder antes de considerar que o alvo está indisponível, o padrão é 10 segundos.

rule_files: # Inicio da definição das regras de alerta, nesse primeiro exemplo vamos deixar sem regras, pois não iremos utilizar alertas por agora.

scrape_configs: # Inicio da definição das configurações de coleta, ou seja, como o Prometheus vai coletar as métricas e onde ele vai encontrar essas métricas.

  - job_name: &quot;prometheus&quot; # Nome do job, ou seja, o nome do serviço que o Prometheus vai monitorar.

    static_configs: # Inicio da definição das configurações estáticas, ou seja, configurações que não serão alteradas durante o processo de coleta.

      - targets: [&quot;localhost:9090&quot;] # Endereço do alvo monitorado, ou seja, o endereço do serviço que o Prometheus vai monitorar. Nesse caso é o próprio Prometheus.
</code></pre>
<p> </p>
<p>Não podemos esquecer do diretório onde o Prometheus guardará seus dados.</p>
<pre><code class="language-bash">sudo mkdir /var/lib/prometheus
</code></pre>
<p> </p>
<p>Vamos criar um grupo e um usuário para o Prometheus.</p>
<pre><code class="language-bash">sudo addgroup --system prometheus
sudo adduser --shell /sbin/nologin --system --group prometheus
</code></pre>
<p> </p>
<p>Precisamos fazer com que o Prometheus seja um serviço em nossa máquina, para isso precisamos criar o arquivo de <em>service unit</em> do <em>SystemD</em>.</p>
<pre><code class="language-bash">sudo vim /etc/systemd/system/prometheus.service
</code></pre>
<p> </p>
<p>Vou deixar o conteúdo do arquivo aqui embaixo e linha por linha comentada, somente para que você possa entender o que está rolando e aprender alguma coisa extra. :D</p>
<pre><code class="language-yaml">[Unit] # Inicio da definição do serviço.
Description=Prometheus # Descrição do serviço.
Documentation=https://prometheus.io/docs/introduction/overview/ # Documentação do serviço.
Wants=network-online.target # Para que o serviço do Prometheus seja iniciado, precisamos antes que o serviço de rede esteja ativo.
After=network-online.target # Depois que o serviço de rede esteja ativo, o serviço do Prometheus será iniciado.

[Service] # Inicio da definição do serviço.
Type=simple # Tipo do serviço, o padrão é simple, ou seja, o serviço é simples, não tem subserviços.
User=prometheus # Usuário do serviço, o padrão é prometheus, o mesmo que criamos no passo anterior.
Group=prometheus # Grupo do serviço, o padrão é prometheus, o mesmo que criamos no passo anterior.
ExecReload=/bin/kill -HUP \$MAINPID # Comando para o serviço do Prometheus ser reiniciado, o padrão é /bin/kill -HUP \$MAINPID, ou seja, o serviço do Prometheus será reiniciado ao receber um sinal de reinicialização.
ExecStart=/usr/local/bin/prometheus \ # Comando para o serviço do Prometheus ser iniciado, o padrão é /usr/local/bin/prometheus, o mesmo lugar para onde mandamos o binário do Prometheus no passo anterior.
  --config.file=/etc/prometheus/prometheus.yml \ # Arquivo de configuração do serviço do Prometheus, o padrão é /etc/prometheus/prometheus.yml, o mesmo lugar onde mandamos o arquivo de configuração do Prometheus no passo anterior.
  --storage.tsdb.path=/var/lib/prometheus \ # Diretório onde o serviço do Prometheus vai armazenar seus dados, o padrão é /var/lib/prometheus, o mesmo lugar onde criamos o diretório para armazenar os dados do Prometheus.
  --web.console.templates=/etc/prometheus/consoles \ # Diretório onde o serviço do Prometheus vai encontrar os templates para os consoles, o padrão é /etc/prometheus/consoles, o mesmo lugar para onde movemos o diretório para armazenar os templates dos consoles.
  --web.console.libraries=/etc/prometheus/console_libraries \ # Diretório onde o serviço do Prometheus vai encontrar as bibliotecas para os consoles, o padrão é /etc/prometheus/console_libraries, o mesmo lugar para onde movemos o diretório para armazenar as bibliotecas dos consoles.
  --web.listen-address=0.0.0.0:9090 \ # Endereço do serviço do Prometheus, o padrão é o serviço escutar na porta 9090.
  --web.external-url= # Endereço externo do serviço do Prometheus, por exemplo o endereço DNS do serviço.

SyslogIdentifier=prometheus # Identificador do serviço no syslog, o padrão é prometheus.
Restart=always # Reinicialização do serviço, o padrão é always, ou seja, o serviço será reiniciado sempre que ocorrer alguma alteração.

[Install] # Inicio da definição do instalador do serviço.
WantedBy=multi-user.target # Definir em qual grupo o serviço será iniciado, o padrão é multi-user.target.
</code></pre>
<p> </p>
<p>Agora vamos adicionar o seguinte conteúdo ao arquivo de configuração do service unit do Prometheus: 
Eu tirei os comentários para evitar algum problema e para deixar o arquivo mais legível.</p>
<pre><code class="language-bash">[Unit]
Description=Prometheus
Documentation=https://prometheus.io/docs/introduction/overview/
Wants=network-online.target
After=network-online.target

[Service]
Type=simple
User=prometheus
Group=prometheus
ExecReload=/bin/kill -HUP \$MAINPID
ExecStart=/usr/local/bin/prometheus \
  --config.file=/etc/prometheus/prometheus.yml \
  --storage.tsdb.path=/var/lib/prometheus \
  --web.console.templates=/etc/prometheus/consoles \
  --web.console.libraries=/etc/prometheus/console_libraries \
  --web.listen-address=0.0.0.0:9090 \
  --web.external-url=

SyslogIdentifier=prometheus
Restart=always

[Install]
WantedBy=multi-user.target
</code></pre>
<p> </p>
<p>Se você não sabe o que é o <em>SystemD</em>, você pode consultar o manual do <em>SystemD</em> ou ainda ver o conteúdo sobre SystemD que eu já criei lá no canal da <a href="https://www.youtube.com/LINUXtips">LINUXtips</a>.</p>
<p>Acredito que já criamos todos os arquivos e diretórios necessários para o funcionamento do Prometheus, agora vamos mudar o dono desses diretórios e arquivos que criamos para que o usuário do prometheus seja o dono dos mesmos.</p>
<pre><code class="language-bash">sudo chown -R prometheus:prometheus /var/log/prometheus
sudo chown -R prometheus:prometheus /etc/prometheus
sudo chown -R prometheus:prometheus /var/lib/prometheus
sudo chown -R prometheus:prometheus /usr/local/bin/prometheus
sudo chown -R prometheus:prometheus /usr/local/bin/promtool
</code></pre>
<p> </p>
<p>Vamos fazer um reload no systemd para que o serviço do Prometheus seja iniciado.</p>
<pre><code class="language-bash">sudo systemctl daemon-reload
</code></pre>
<p> </p>
<p>Vamos iniciar o serviço do Prometheus.</p>
<pre><code class="language-bash">sudo systemctl start prometheus
</code></pre>
<p> </p>
<p>Temos que deixar o serviço do Prometheus configurado para que seja iniciado automaticamente ao iniciar o sistema.</p>
<pre><code class="language-bash">sudo systemctl enable prometheus
</code></pre>
<p> </p>
<p>Para garantir, vamos ver o status do serviço do Prometheus.</p>
<pre><code class="language-bash">sudo systemctl status prometheus
</code></pre>
<p> </p>
<p>Você pode verificar nos logs se tudo está rodando maravilhosamente.</p>
<pre><code class="language-bash">sudo journalctl -u prometheus
</code></pre>
<p> </p>
<p>E se você encontrar a seguinte mensagem no log, significa que o serviço do Prometheus está funcionando corretamente.</p>
<pre><code class="language-bash">level=info msg=&quot;Server is ready to receive web requests.&quot;
</code></pre>
<p> </p>
<p>E para finalizar a brincadeira, vamos acessar a nossa interface web do Prometheus através do seguinte endereço em seu navegador.</p>
<pre><code class="language-bash">http://localhost:9090
</code></pre>
<p> </p>
<p>Você verá uma tela maravilhosa como mostra a imagem abaixo.</p>
<p><img src="day-1/images/interface-web-prometheus-2.png" alt="Prometheus instalado no Linux" />
 </p>
<p> </p>
<h3 id="a-sua-lição-de-casa"><a class="header" href="#a-sua-lição-de-casa">A sua lição de casa</a></h3>
<p>A sua lição de casa é estudar cada conceito que você aprendeu até o momento, e claro, vamos explorar ao máximo a interface do Prometheus.
Tente brincar criando algumas queries e visualizando os resultados, além de navegar pela interface para conhecer todos os recursos do Prometheus.
Nós vamos explorar e muito essa interface, afinal o nosso treinamento é criado para que você possa aprender de maneira evolutiva, um pouco a cada dia e sempre criando algo, saindo do treinamento com algo que você aprendeu executado na prática.</p>
<p> </p>
<h2 id="desafio-do-day-1"><a class="header" href="#desafio-do-day-1">Desafio do Day-1</a></h2>
<p>Não esqueça de realizar o desafio do Day-1, para que você possa ir para o próximo Day.
O desafio consiste de perguntas e um teste prático, para que você possa aprender ainda mais e se familiarizar com o que você aprendeu.
Veja na plataforma do treinamento o desafio do Day-1.</p>
<p> </p>
<h2 id="final-do-day-1"><a class="header" href="#final-do-day-1">Final do Day-1</a></h2>
<p>Durante o Day-1 você aprendeu o que é monitoração, qual a relação dela com observabilidade, quais os pilares da observabilidade, o que é o Prometheus e como ele funciona.
Fizemos a instalação do Prometheus, entendemos sua configuração inicial, como configurar o service unit, como configurar o Prometheus através do arquivo de configuração, criamos a estrutura de arquivos e diretórios, como configurar o grupo de usuários e como configurar o usuário do serviço.
Acessamos a interface do Prometheus e fizemos a nossa primeira query.
Verificamos o status do serviço do Prometheus e verificamos nos logs se tudo está rodando corretamente.
Entendemos a arquitetura do Prometheus e tivemos o prazer de ver o desenho feito por mim. hahaha</p>
<p>Agora é hora de descansar e depois rever todo o conteúdo do Day-1.</p>
<p> </p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="descomplicando-o-prometheus"><a class="header" href="#descomplicando-o-prometheus">Descomplicando o Prometheus</a></h1>
<h2 id="day-2"><a class="header" href="#day-2">DAY-2</a></h2>
<h3 id="o-que-iremos-ver-hoje-1"><a class="header" href="#o-que-iremos-ver-hoje-1">O que iremos ver hoje?</a></h3>
<p>Seja muito bem-vinda e muito bem-vindo para o seu segundo dia de treinamento! Sim, eu considero esse livro um treinamento e não somente um guia de como obter o melhor do sensacional Prometheus!</p>
<p>Hoje nós vamos aprender como criar as nossa primeiras <em>queries</em> e para isso vamos precisar entender o modelo de dados que o Prometheus utiliza, vamos entender no detalhe o que é uma métrica para o Prometheus e vamos aprender como criar a nossa propria métrica e as nossas primeiras queries.</p>
<p>Vamos criar o nosso primeiro exporter utilizando Python Docker. Vamos entender os tipos de dados que o Prometheus utiliza, como utiliza-los e pra que servem.</p>
<p>Vamos conhecer as nossas primeiras funções para que possamos ter ainda mais poderes para criar as nossa queries PromQL.</p>
<p> </p>
<h3 id="conteúdo-do-day-2"><a class="header" href="#conteúdo-do-day-2">Conteúdo do Day-2</a></h3>
<details>
<summary class="summary">DAY-2</summary>
<ul>
<li><a href="day-2/index.html#o-data-model-do-prometheus">O Data Model do Prometheus</a></li>
<li><a href="day-2/index.html#as-queries-do-prometheus-e-o-promql">As queries do Prometheus e o PromQL</a></li>
<li><a href="day-2/index.html#o-nosso-primeiro-exporter">O nosso primeiro exporter</a>
<ul>
<li><a href="day-2/index.html#nosso-primeiro-exporter-no-container">Nosso Primeiro Exporter no Container</a></li>
</ul>
</li>
<li><a href="day-2/index.html#os-targets-do-prometheus">Os Targets do Prometheus</a></li>
<li><a href="day-2/index.html#visualizando-as-m%C3%A9tricas-do-nosso-primeiro-exporter">Visualizando as métricas do nosso primeiro exporter</a></li>
<li><a href="day-2/index.html#conhecendo-um-pouco-mais-sobre-os-tipos-de-dados-do-prometheus">Conhecendo um pouco mais sobre os tipos de dados do Prometheus</a> 
<ul>
<li><a href="day-2/index.html#gauge-medidor">gauge: Medidor</a></li>
<li><a href="day-2/index.html#counter-contador">counter: Contador</a></li>
<li><a href="day-2/index.html#summary-resumo">summary: Resumo</a></li>
<li><a href="day-2/index.html#histogram-histograma">histogram: Histograma</a></li>
</ul>
</li>
<li><a href="day-2/index.html#chega-por-hoje">Chega por hoje!</a></li>
<li><a href="day-2/index.html#li%C3%A7%C3%A3o-de-casa">Lição de casa</a></li>
</ul>
</details>
<p> 
 </p>
<h3 id="o-data-model-do-prometheus"><a class="header" href="#o-data-model-do-prometheus">O Data Model do Prometheus</a></h3>
<p>O formato de dados que o Prometheus utiliza é bastante simples, vamos pegar uma métrica e fazer uma consulta para saber o valor atual dela, assim você poderá entender melhor esse tal de <em>data model</em>.</p>
<p>Vamos fazer uma query para saber o valor atual da métrica <code>up</code> do servidor onde Prometheus está rodando.</p>
<pre><code>up
</code></pre>
<p> </p>
<p>Lembrando que estamos executando a query na porta 9090, que é a porta padrão do Prometheus, lá no navegador, certo?</p>
<p>Somente para que você não tenha duvidas, vamos abrir o navegador e digitar:</p>
<pre><code>http://localhost:9090/

</code></pre>
<p> </p>
<p>Se liga no print do navegador:</p>
<p><img src="day-2/images/resultado-query-up.png" alt="Query buscando o valor atual da métrica up" /></p>
<p> </p>
<p>Aqui, o resultado dessa query é:</p>
<pre><code>up{instance=&quot;localhost:9090&quot;,job=&quot;prometheus&quot;} 1.0
</code></pre>
<p> </p>
<p>Nós precisamos entender o que essa linha está dizendo, o Prometheus sempre vai seguir um padrão, e você entendendo essa padrão tudo ficará muito mais fácil.</p>
<p>Ahhh, caso você queira pegar o resultado da query via terminal, basta digitar:</p>
<pre><code>curl -GET http://localhost:9090/api/v1/query --data-urlencode &quot;query=up&quot;
</code></pre>
<p> </p>
<p>Somente para explicar o que a linha do curl acima faz, vamos explicar o que está acontecendo.</p>
<p> </p>
<p>Vamos lá!</p>
<ul>
<li>
<p>O <code>curl</code> é um programa que permite fazer requisições HTTP, ou seja, você pode fazer requisições para uma URL e receber uma resposta. Nesse caso estamos pedindo para que ele faça um GET na URL <code>http://localhost:9090/api/v1/query</code> e envie uma query para o Prometheus.</p>
</li>
<li>
<p>O <code>curl</code> está fazendo uma requisição para a URL <code>http://localhost:9090/api/v1/query</code>, que é a URL padrão do Prometheus.</p>
</li>
<li>
<p>O <code>curl</code> está passando uma query para o Prometheus, que é a query que você estamos querendo saber o valor, ou seja, a nossa métrica <code>up</code>. <em>&quot;query=up&quot;</em></p>
</li>
<li>
<p>E ainda estamos passando o parâmetro <code>--data-urlencode</code> para o <code>curl</code>, que é um parâmetro que permite você fazer um  POST com dados via URL, similar ao parâmetro <code>--data</code> do <code>curl</code>.</p>
</li>
</ul>
<p> </p>
<p>O resultado será algo parecido com a saída abaixo:</p>
<pre><code class="language-json">{
  &quot;status&quot;: &quot;success&quot;,
  &quot;data&quot;: {
    &quot;resultType&quot;: &quot;vector&quot;,
    &quot;result&quot;: [
      {
        &quot;metric&quot;: {
            &quot;__name__&quot;: &quot;up&quot;,
            &quot;instance&quot;: &quot;localhost:9090&quot;,
            &quot;job&quot;: &quot;prometheus&quot;
            },
        &quot;value&quot;: [
            1661595487.119,
            &quot;1&quot;
            ]
        }
        ]
    }
}
</code></pre>
<p> </p>
<p>Bem, o resultado da query que queriamos já está aqui, mostrei das duas formas, via interface web usando o navegador ou via terminal usando o <code>curl</code>.</p>
<p>Agora vamos entender o que está acontecendo.</p>
<p>O que o Prometheus retornou?</p>
<p>Vou fazer rabiscar para eu conseguir explicar melhor. :D</p>
<p>Primeiro vamos entender que o resultado está dividido em duas partes:</p>
<ul>
<li>
<p>O 'identificador' do resultado, que é o nome da métrica que você está buscando e suas labels. Ahh, as <em>labels</em> são informações que ajudam a melhorar o filtro da sua query. Por exemplo, podemos buscar a mesma métrica, mas com diferentes labels, como por exemplo, com o label <code>instance</code> como <code>localhost:9090</code>, poderíamos ter outras <code>instance</code> como <code>webserver-01</code> e <code>webserver-02</code>, por exemplo.</p>
</li>
<li>
<p>O 'valor' do resultado, que é o valor atual da métrica. Essa é a segunda parte do resultado, onde você encontra o valor atual da métrica.</p>
</li>
</ul>
<p>Se liga no desenho que eu fiz para você entender melhor, vamos lá:</p>
<p><img src="day-2/images/desenho-data-model-prometheus-1.jpg" alt="Desenho Data Model do Prometheus" /></p>
<p> </p>
<p>Se der um zoom no desenho, vai ver que o resultado está subdivido em mais partes, afinal, além do nome da métrica, temos as labels e seus valores e finalizando com o valor atual da métrica.</p>
<p>Se liga nesse outro desenho:</p>
<p><img src="day-2/images/desenho-data-model-prometheus-2.jpg" alt="Desenho Data Model do Prometheus" /></p>
<p> </p>
<p>O que sabemos então olhando o resultado dessa query é que o nosso servidor está rodando, ou seja, o Prometheus está funcionando corretamente.
Perceba que somente está o valor '1', não está falando desde quando está em execução, somente trouxe que o valor atual, o que está acontecendo agora é '1', ou seja, está rodando.</p>
<p>Se o valor fosse '0', significaria que o servidor não está rodando, ou seja, o Prometheus está parado.</p>
<p>Agora, se eu quero saber o valor da métrica <code>up</code> do servidor onde está rodando o Prometheus na última hora, teriamos que passar esse desejo para a nossa query, que fica assim:</p>
<pre><code>up{instance=&quot;localhost:9090&quot;,job=&quot;prometheus&quot;}[1h]
</code></pre>
<p> </p>
<p>Nesse caso estamos especificando que queremos os valores da métrica <code>up</code> do servidor <code>localhost:9090</code> do job <code>prometheus</code> da última hora, estamos sendo bem específicos. :)</p>
<p>Para pedir as métricas da última hora, vamos usar o parâmetro <code>[1h]</code> no final da query.
Você usar <code>h</code> para hora, <code>d</code> para dia, <code>w</code> para semana, <code>m</code> para mês, <code>y</code> para ano.</p>
<p><img src="day-2/images/desenho-query-prometheus-1.jpg" alt="Desenho Query Simples Prometheus" /></p>
<p> </p>
<p>O resultado foi enorme, certo?
E você não sabe o porquê?</p>
<p>Lembra que nós configuramos o Prometheus para ele fazer o <em>scrape</em> das métricas que queremos a cada 15 segundos? Então, o resultado vai ser bem grande.</p>
<p>Vou copiar aqui somente o primeiro resultado para você entender melhor:</p>
<pre><code>up{instance=&quot;localhost:9090&quot;, job=&quot;prometheus&quot;} 1 @1661595094.114
</code></pre>
<p> </p>
<p>Perceba que agora ele trouxe o @1661595094.114, que é o timestamp da execução do scrape, ou seja, a hora em que o scrape foi capturado.</p>
<p>Acho que já entendemos o modelo de dados que o Prometheus retorna, então já podemos ir um pouco mais além, bora entender e descomplicar as queries utilizando a poderossa linguagem de query do Prometheus, a PromQL!</p>
<p> 
 </p>
<h3 id="as-queries-do-prometheus-e-o-promql"><a class="header" href="#as-queries-do-prometheus-e-o-promql">As queries do Prometheus e o PromQL</a></h3>
<p>Como mencionado ainda no Day-1, o <em>PromQL</em> é uma linguagem de query do Prometheus que permite fazer queries completas e super eficientes, e hoje vamos descomplica-la.</p>
<p>Eu sei que não é nenhuma novidade para você, pois nós já brincamos um pouco durante os exemplos anteriores, mas agora vamos gastar mais energia para que tudo seja mais claro e que possamos ter uma melhor compreensão do PromQL.</p>
<p>Antes de qualquer coisa, vamos colocar mais algumas métricas em nosso servidor, para podermos se divertir um pouco mais.</p>
<p>Antes vamos fazer um novo <em>exporter</em> para o Prometheus, o <em>exporter</em> é um programa que é executado no host alvo e o responsável por expor as métricas para o Prometheus capturar.</p>
<p>Ahhh, PromQL significa <em>Prometheus Query Language</em>. :)</p>
<p>Vamos entender isso melhor, mas antes vamos criar o nosso primeiro <em>exporter</em> para o Prometheus.</p>
<p> 
 </p>
<h3 id="o-nosso-primeiro-exporter"><a class="header" href="#o-nosso-primeiro-exporter">O nosso primeiro exporter</a></h3>
<p>Para o nosso exemplo, vamos criar uma aplicação bem simples feita em Python irá exportar as métricas que queremos.</p>
<p>A métrica que queremos é a quantidade de pessoas que estão na Estação Espacial Internacional nesse momento.
Então a métrica que queremos é simples, pelo menos por agora:</p>
<ul>
<li>Número de astronautas que estão no espaço</li>
</ul>
<p>Para saber a quantidade de pessoas que estão no espaço, vamos utilizar a API Rest do <a href="http://open-notify.org/Open-Notify-API/People-In-Space/">OpenNotify</a>.</p>
<p>Vamos criar um arquivo chamado <code>exporter.py</code> no diretório <code>exporter</code>.</p>
<p> </p>
<pre><code class="language-python">import requests # Importa o módulo requests para fazer requisições HTTP
import json # Importa o módulo json para converter o resultado em JSON
import time # Importa o módulo time para fazer o sleep
from prometheus_client import start_http_server, Gauge # Importa o módulo Gauge do Prometheus para criar a nossa métrica e o módulo start_http_server para iniciar o servidor

url_numero_pessoas = 'http://api.open-notify.org/astros.json' # URL para pegar o número de astronautas

def pega_numero_astronautas(): # Função para pegar o número de astronautas
    try: # Tenta fazer a requisição HTTP
        &quot;&quot;&quot;
        Pegar o número de astronautas no espaço 
        &quot;&quot;&quot;
        response = requests.get(url_numero_pessoas) # Faz a requisição HTTP
        data = response.json() # Converte o resultado em JSON
        return data['number'] # Retorna o número de astronautas
    except Exception as e: # Se der algum erro
        print(&quot;Não foi possível acessar a url!&quot;) # Imprime que não foi possível acessar a url
        raise e # Lança a exceção

def atualiza_metricas(): # Função para atualizar as métricas
    try:
        &quot;&quot;&quot;
        Atualiza as métricas com o número de astronautas e local da estação espacial internacional
        &quot;&quot;&quot;
        numero_pessoas = Gauge('numero_de_astronautas', 'Número de astronautas no espaço') # Cria a métrica
        
        while True: # Enquanto True
            numero_pessoas.set(pega_numero_astronautas()) # Atualiza a métrica com o número de astronautas
            time.sleep(10) # Faz o sleep de 10 segundos
            print(&quot;O número atual de astronautas no espaço é: %s&quot; % pega_numero_astronautas()) # Imprime o número de astronautas no espaço
    except Exception as e: # Se der algum erro
        print(&quot;A quantidade de astronautas não pode ser atualizada!&quot;) # Imprime que não foi possível atualizar a quantidade de astronautas
        raise e # Lança a exceção
        
def inicia_exporter(): # Função para iniciar o exporter
    try:
        &quot;&quot;&quot;
        Iniciar o exporter
        &quot;&quot;&quot;
        start_http_server(8899) # Inicia o servidor do Prometheus na porta 8899
        return True # Retorna True
    except Exception as e: # Se der algum erro
        print(&quot;O Servidor não pode ser iniciado!&quot;) # Imprime que não foi possível iniciar o servidor
        raise e # Lança a exceção

def main(): # Função principal
    try:
        inicia_exporter() # Inicia o exporter
        print('Exporter Iniciado') # Imprime que o exporter foi iniciado
        atualiza_metricas() # Atualiza as métricas
    except Exception as e: # Se der algum erro
        print('\nExporter Falhou e Foi Finalizado! \n\n======&gt; %s\n' % e) # Imprime que o exporter falhou e foi finalizado
        exit(1) # Finaliza o programa com erro


if __name__ == '__main__': # Se o programa for executado diretamente
    main() # Executa o main
    exit(0) # Finaliza o programa

</code></pre>
<p> </p>
<p>Agora vamos executar o nosso script para ver se está tudo certo.</p>
<pre><code class="language-bash">chmod +x exporter.py
python exporter.py
</code></pre>
<p> </p>
<p>Abra um outro terminal e execute o comando <code>curl http://localhost:8899/metrics/</code> para ver se está tudo certo.</p>
<pre><code class="language-bash">curl http://localhost:8899/metrics/
</code></pre>
<p> </p>
<p>A saída será:</p>
<pre><code class="language-bash">curl http://localhost:8899/metrics/


# HELP python_gc_objects_collected_total Objects collected during gc
# TYPE python_gc_objects_collected_total counter
python_gc_objects_collected_total{generation=&quot;0&quot;} 208.0
python_gc_objects_collected_total{generation=&quot;1&quot;} 33.0
python_gc_objects_collected_total{generation=&quot;2&quot;} 0.0
# HELP python_gc_objects_uncollectable_total Uncollectable object found during GC
# TYPE python_gc_objects_uncollectable_total counter
python_gc_objects_uncollectable_total{generation=&quot;0&quot;} 0.0
python_gc_objects_uncollectable_total{generation=&quot;1&quot;} 0.0
python_gc_objects_uncollectable_total{generation=&quot;2&quot;} 0.0
# HELP python_gc_collections_total Number of times this generation was collected
# TYPE python_gc_collections_total counter
python_gc_collections_total{generation=&quot;0&quot;} 55.0
python_gc_collections_total{generation=&quot;1&quot;} 4.0
python_gc_collections_total{generation=&quot;2&quot;} 0.0
# HELP python_info Python platform information
# TYPE python_info gauge
python_info{implementation=&quot;CPython&quot;,major=&quot;3&quot;,minor=&quot;10&quot;,patchlevel=&quot;4&quot;,version=&quot;3.10.4&quot;} 1.0
# HELP process_virtual_memory_bytes Virtual memory size in bytes.
# TYPE process_virtual_memory_bytes gauge
process_virtual_memory_bytes 1.99507968e+08
# HELP process_resident_memory_bytes Resident memory size in bytes.
# TYPE process_resident_memory_bytes gauge
process_resident_memory_bytes 2.7099136e+07
# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.
# TYPE process_start_time_seconds gauge
process_start_time_seconds 1.66178245236e+09
# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.
# TYPE process_cpu_seconds_total counter
process_cpu_seconds_total 0.060000000000000005
# HELP process_open_fds Number of open file descriptors.
# TYPE process_open_fds gauge
process_open_fds 6.0
# HELP process_max_fds Maximum number of open file descriptors.
# TYPE process_max_fds gauge
process_max_fds 1024.0
# HELP number_of_astronauts Number of astronauts in space
# TYPE number_of_astronauts gauge
number_of_astronauts 10.0
</code></pre>
<p> </p>
<p>Lembrando que você pode acessar via navegador acessando http://localhost:8899/metrics/.</p>
<p><img src="day-2/images/primeiro-export.png" alt="Print das métricas do nosso primeiro export!" /></p>
<p>Perceba que estamos passando o path <code>/metrics</code>, mas qualquer path que você passar port agora, o <code>start_http_serve</code> irá responder. Por enquanto vamos deixar dessa forma, mas em breve vamos melhorar isso, mas por agora e para fins didáticos, vamos deixar assim.</p>
<p> </p>
<h3 id="nosso-primeiro-exporter-no-container"><a class="header" href="#nosso-primeiro-exporter-no-container">Nosso Primeiro Exporter no Container</a></h3>
<p>Vamos colocar esse nosso primeiro exporter para rodar em um container Docker.
Antes de mais nada, faça a instalação do Docker na maioria das distribuições Linux, execute o famoso <code>curl</code>!</p>
<pre><code class="language-bash">curl -fsSL https://get.docker.com | bash
</code></pre>
<p> </p>
<p>Caso queira saber mais detalhes de como instalar o Docker em outros sistemas operacionais, clique <a href="https://docs.docker.com/install/">aqui</a>.</p>
<p>Vamos ter certeza de que o Docker está instalado, execute o comando <code>docker --version</code> para verificar se está funcionando.</p>
<pre><code class="language-bash">docker --version
</code></pre>
<p> </p>
<p>Boa! Agora já podemos criar o nosso Dockerfile para criar a nossa imagem Docker do exporter.</p>
<pre><code class="language-dockerfile"># Vamos utilizar a imagem slim do Python
FROM python:3.8-slim

# Adicionando algumas labels para identificar a imagem
LABEL maintainer Jeferson Fernando &lt;jeferson@linuxtips.com.br&gt;
LABEL description &quot;Dockerfile para criar o nosso primeiro exporter para o Prometheus&quot;

# Adicionando o exporter.py para a nossa imagem
COPY . .

# Instalando as bibliotecas necessárias para o exporter
# através do `requirements.txt`.
RUN pip3 install -r requirements.txt

# Executando o exporter
CMD python3 exporter.py
</code></pre>
<p> </p>
<p>Muito bom!
Já temos o nosso <code>Dockerfile</code> criado, vamos criar a nossa imagem Docker.</p>
<pre><code class="language-bash">docker build -t primeiro-exporter:0.1 .

Sending build context to Docker daemon  5.632kB
Step 1/7 : FROM python:3.8-slim
 ---&gt; bdd3315885d4
Step 2/7 : LABEL maintainer Jeferson Fernando &lt;jeferson@linuxtips.com.br&gt;
 ---&gt; Using cache
 ---&gt; 3d1bad97c1cb
Step 3/7 : LABEL description &quot;Dockerfile para criar o nosso primeiro exporter para o Prometheus&quot;
 ---&gt; Using cache
 ---&gt; 9f41ad63e03a
Step 4/7 : COPY . /app
 ---&gt; Using cache
 ---&gt; 5d9cdbc9dd36
Step 5/7 : WORKDIR /app
 ---&gt; Using cache
 ---&gt; 4164e416a25e
Step 6/7 : RUN pip3 install -r requirements.txt
 ---&gt; Using cache
 ---&gt; 9d4517e8a5c4
Step 7/7 : CMD python3 exporter.py
 ---&gt; Using cache
 ---&gt; 7f971cbc97ce
Successfully built 7f971cbc97ce
Successfully tagged primeiro-exporter:0.1
</code></pre>
<p> </p>
<p>Se você quiser ver a imagem criada, execute o comando <code>docker images</code> para verificar.</p>
<pre><code class="language-bash">docker images | grep primeiro-exporter

primeiro-exporter   0.1   7f971cbc97ce   4 minutes ago   134MB
</code></pre>
<p> </p>
<p>Ótimo! Agora vamos rodar o nosso primeiro exporter.</p>
<pre><code class="language-bash">docker run -p 8899:8899 --name primeiro-exporter -d primeiro-exporter:0.1
</code></pre>
<p> </p>
<p>Bora verificar se o nosso primeiro exporter está rodando.</p>
<pre><code class="language-bash">curl -s http://localhost:8899/metrics
</code></pre>
<p> </p>
<p>Está rodando maravilhosamente bem!</p>
<p> </p>
<h3 id="os-targets-do-prometheus"><a class="header" href="#os-targets-do-prometheus">Os Targets do Prometheus</a></h3>
<p>Agora que já temos o nosso exporter rodando maravilhosamente em nosso container Docker, vamos adicionar um novo host alvo para o Prometheus, ou seja, vamos adicionar o nosso primeiro exporter para o Prometheus.</p>
<p>Caso você queira executar o nosso primeiro exporter em outro computador ou vm, lembre-se de passar corretamento o endereço no momento em que adicionarmos o host alvo lá nas configurações do Prometheus.</p>
<p>Antes de mais nada, vamos conhecer os hosts alvos que já estão configurados no Prometheus.
Sempre que falar sobre esses hosts alvos, vamos falar em <code>targets</code>, pois um host alvo é um servidor/serviço que o Prometheus monitora, e ele chama esses hosts alvos de <code>targets</code>.</p>
<p>Vamos ver os hosts alvos, ou <code>targets</code>, que estão configurados no Prometheus.</p>
<pre><code class="language-bash">curl -s http://localhost:9090/api/v1/targets
</code></pre>
<p> </p>
<p>Para ficar mais bonita essa saída, vamos converter para JSON e para isso vamos utilizar o comando <code>jq</code>.</p>
<p>O comando <code>jq</code> é um comando lindo demais do <a href="https://stedolan.github.io/jq/">JSON</a> que permite fazer o parse de um arquivo JSON.</p>
<p>Se você ainda não tem o <code>jq</code> instalado, execute o comando <code>sudo apt install jq</code> para instalar.</p>
<pre><code class="language-bash">curl -s http://localhost:9090/api/v1/targets | jq .
</code></pre>
<p> </p>
<p>A saída deve ter ficado bem mais bonita.</p>
<pre><code class="language-json">{
  &quot;status&quot;: &quot;success&quot;,
  &quot;data&quot;: {
    &quot;activeTargets&quot;: [
      {
        &quot;discoveredLabels&quot;: {
          &quot;__address__&quot;: &quot;localhost:9090&quot;,
          &quot;__metrics_path__&quot;: &quot;/metrics&quot;,
          &quot;__scheme__&quot;: &quot;http&quot;,
          &quot;__scrape_interval__&quot;: &quot;15s&quot;,
          &quot;__scrape_timeout__&quot;: &quot;10s&quot;,
          &quot;job&quot;: &quot;prometheus&quot;
        },
        &quot;labels&quot;: {
          &quot;instance&quot;: &quot;localhost:9090&quot;,
          &quot;job&quot;: &quot;prometheus&quot;
        },
        &quot;scrapePool&quot;: &quot;prometheus&quot;,
        &quot;scrapeUrl&quot;: &quot;http://localhost:9090/metrics&quot;,
        &quot;globalUrl&quot;: &quot;http://nu-derval:9090/metrics&quot;,
        &quot;lastError&quot;: &quot;&quot;,
        &quot;lastScrape&quot;: &quot;2022-08-29T18:18:19.080077725+02:00&quot;,
        &quot;lastScrapeDuration&quot;: 0.004360807,
        &quot;health&quot;: &quot;up&quot;,
        &quot;scrapeInterval&quot;: &quot;15s&quot;,
        &quot;scrapeTimeout&quot;: &quot;10s&quot;
      }
    ],
    &quot;droppedTargets&quot;: []
  }
}

</code></pre>
<p> </p>
<p>Perceba que somente temos um host alvo configurado no Prometheus, que é o próprio Prometheus. Perceba que ele está configurado para buscar as métricas na porta 9090, e ele está configurado para buscar as métricas em um intervalo de 15 segundos. A porta 9090 é a porta padrão do Prometheus, a diferença é o path que ele está buscando, que é <code>/metrics</code>.</p>
<p>Testa a saída do comando <code>curl -s http://localhost:9090/metrics</code> e você verá as métricas do Prometheus.
IMPORTANTE: Métricas do Prometheus e não do nosso primeiro exporter.</p>
<p>Voltando a falar dos nossos targets, caso você não goste dessa saída via linha de comando, você pode verificar a saída via browser, claro!</p>
<pre><code class="language-bash">http://localhost:9090/targets
</code></pre>
<p> </p>
<p>No nosso caso, como já sabemos, somente temos um host alvo configurado no Prometheus, que é o próprio Prometheus.</p>
<p><img src="day-2/images/prometheus-targets-1.png" alt="O único target configurado no Prometheus" /></p>
<p>O que temos que fazer agora é adicionar o nosso novo target, ou host alvo, ou chame lá como você quiser. hahaha.</p>
<p> </p>
<h3 id="adicionando-o-nosso-primeiro-exporter-para-o-prometheus"><a class="header" href="#adicionando-o-nosso-primeiro-exporter-para-o-prometheus">Adicionando o nosso primeiro exporter para o Prometheus</a></h3>
<p>Primeira coisa que precisamos fazer é editar o arquivo <code>prometheus.yml</code> para adicionar o nosso primeiro exporter.
Como sabemos, o nosso arquivo <code>prometheus.yml</code> está no diretório <code>/etc/prometheus/</code>.</p>
<p>Edite o arquivo <code>prometheus.yml</code> para adicionar o seguinte:</p>
<pre><code class="language-yaml">global: # Configurações globais do Prometheus, ou seja, configurações que serão utilizadas em todos os jobs caso não sejam configuradas separadamente dentro de cada job.
  
  scrape_interval: 15s # Intervalo de coleta dos dados, ou seja, a cada 15 segundos o Prometheus vai até o alvo monitorado coletar as métricas, o padrão é 1 minuto.
  
  evaluation_interval: 15s # Intervalo para o Prometheus avaliar as regras de alerta, o padrão é 1 minuto. Não estamos utilizando regras para os alertas, vamos manter aqui somente para referência.

  scrape_timeout: 10s # Intervalos para o Prometheus aguardar o alvo monitorado responder antes de considerar que o alvo está indisponível, o padrão é 10 segundos.

rule_files: # Inicio da definição das regras de alerta, nesse primeiro exemplo vamos deixar sem regras, pois não iremos utilizar alertas por agora.

scrape_configs: # Inicio da definição das configurações de coleta, ou seja, como o Prometheus vai coletar as métricas e onde ele vai encontrar essas métricas.

  - job_name: &quot;prometheus&quot; # Nome do job, ou seja, o nome do serviço que o Prometheus vai monitorar.

    static_configs: # Inicio da definição das configurações estáticas, ou seja, configurações que não serão alteradas durante o processo de coleta.

      - targets: [&quot;localhost:9090&quot;] # Endereço do alvo monitorado, ou seja, o endereço do serviço que o Prometheus vai monitorar. Nesse caso é o próprio Prometheus.
  
  - job_name: &quot;Primeiro Exporter&quot; # Nome do job que vai coletar as métricas do primeiro exporter.
    static_configs:
      - targets: [&quot;localhost:8899&quot;] # Endereço do alvo monitorado, ou seja, o nosso primeiro exporter.
</code></pre>
<p> </p>
<p>Agora que já editamos o arquivo e adicionamos um novo job, precisamos atualizar o Prometheus.</p>
<pre><code class="language-bash">sudo systemctl restart prometheus
</code></pre>
<p> </p>
<p>Bora conferir se o nosso primeiro exporter já está configurado como target no Prometheus.</p>
<pre><code class="language-bash">curl -s http://localhost:9090/api/v1/targets | jq . 
</code></pre>
<p> </p>
<p>A saída mudou, não?!?</p>
<pre><code class="language-json">{
  &quot;status&quot;: &quot;success&quot;,
  &quot;data&quot;: {
    &quot;activeTargets&quot;: [
      {
        &quot;discoveredLabels&quot;: {
          &quot;__address__&quot;: &quot;localhost:8899&quot;,
          &quot;__metrics_path__&quot;: &quot;/metrics&quot;,
          &quot;__scheme__&quot;: &quot;http&quot;,
          &quot;__scrape_interval__&quot;: &quot;15s&quot;,
          &quot;__scrape_timeout__&quot;: &quot;10s&quot;,
          &quot;job&quot;: &quot;Primeiro Exporter&quot;
        },
        &quot;labels&quot;: {
          &quot;instance&quot;: &quot;localhost:8899&quot;,
          &quot;job&quot;: &quot;Primeiro Exporter&quot;
        },
        &quot;scrapePool&quot;: &quot;Primeiro Exporter&quot;,
        &quot;scrapeUrl&quot;: &quot;http://localhost:8899/metrics&quot;,
        &quot;globalUrl&quot;: &quot;http://nu-derval:8899/metrics&quot;,
        &quot;lastError&quot;: &quot;&quot;,
        &quot;lastScrape&quot;: &quot;2022-08-29T18:37:17.239059844+02:00&quot;,
        &quot;lastScrapeDuration&quot;: 0.002143502,
        &quot;health&quot;: &quot;up&quot;,
        &quot;scrapeInterval&quot;: &quot;15s&quot;,
        &quot;scrapeTimeout&quot;: &quot;10s&quot;
      },
      {
        &quot;discoveredLabels&quot;: {
          &quot;__address__&quot;: &quot;localhost:9090&quot;,
          &quot;__metrics_path__&quot;: &quot;/metrics&quot;,
          &quot;__scheme__&quot;: &quot;http&quot;,
          &quot;__scrape_interval__&quot;: &quot;15s&quot;,
          &quot;__scrape_timeout__&quot;: &quot;10s&quot;,
          &quot;job&quot;: &quot;prometheus&quot;
        },
        &quot;labels&quot;: {
          &quot;instance&quot;: &quot;localhost:9090&quot;,
          &quot;job&quot;: &quot;prometheus&quot;
        },
        &quot;scrapePool&quot;: &quot;prometheus&quot;,
        &quot;scrapeUrl&quot;: &quot;http://localhost:9090/metrics&quot;,
        &quot;globalUrl&quot;: &quot;http://nu-derval:9090/metrics&quot;,
        &quot;lastError&quot;: &quot;&quot;,
        &quot;lastScrape&quot;: &quot;2022-08-29T18:37:19.08239274+02:00&quot;,
        &quot;lastScrapeDuration&quot;: 0.004655397,
        &quot;health&quot;: &quot;up&quot;,
        &quot;scrapeInterval&quot;: &quot;15s&quot;,
        &quot;scrapeTimeout&quot;: &quot;10s&quot;
      }
    ],
    &quot;droppedTargets&quot;: []
  }
}
</code></pre>
<p> </p>
<p>Essa é a saída que é importante para nos sabermos se o nosso primeiro exporter está configurado como target no Prometheus.</p>
<pre><code class="language-json">&quot;activeTargets&quot;: [
      {
        &quot;discoveredLabels&quot;: {
          &quot;__address__&quot;: &quot;localhost:8899&quot;,
          &quot;__metrics_path__&quot;: &quot;/metrics&quot;,
          &quot;__scheme__&quot;: &quot;http&quot;,
          &quot;__scrape_interval__&quot;: &quot;15s&quot;,
          &quot;__scrape_timeout__&quot;: &quot;10s&quot;,
          &quot;job&quot;: &quot;Primeiro Exporter&quot;
        },
        &quot;labels&quot;: {
          &quot;instance&quot;: &quot;localhost:8899&quot;,
          &quot;job&quot;: &quot;Primeiro Exporter&quot;
        },
        &quot;scrapePool&quot;: &quot;Primeiro Exporter&quot;,
        &quot;scrapeUrl&quot;: &quot;http://localhost:8899/metrics&quot;,
        &quot;globalUrl&quot;: &quot;http://nu-derval:8899/metrics&quot;,
        &quot;lastError&quot;: &quot;&quot;,
        &quot;lastScrape&quot;: &quot;2022-08-29T18:37:17.239059844+02:00&quot;,
        &quot;lastScrapeDuration&quot;: 0.002143502,
        &quot;health&quot;: &quot;up&quot;,
        &quot;scrapeInterval&quot;: &quot;15s&quot;,
        &quot;scrapeTimeout&quot;: &quot;10s&quot;
      },
</code></pre>
<p> </p>
<p>Caso queira fazer um <code>grep</code> na saída para ver se o nosso primeiro exporter está na lista de targets, vamos fazer isso:</p>
<pre><code class="language-bash">curl -s http://localhost:9090/api/v1/targets | jq . | grep -i &quot;localhost:8899&quot;
</code></pre>
<p> </p>
<p>E ainda podemos ver via navegador, conforme abaixo:</p>
<p><img src="day-2/images/prometheus-targets-2.png" alt="O nosso novo target está configurado" /></p>
<p> </p>
<h3 id="visualizando-as-métricas-do-nosso-primeiro-exporter"><a class="header" href="#visualizando-as-métricas-do-nosso-primeiro-exporter">Visualizando as métricas do nosso primeiro exporter</a></h3>
<p>Muito bem, fizemos tudo isso somente para mostrar uma nova métrica aparecendo no Prometheus, além da métrica que já vem por padrão.</p>
<p>A métrica que criamos é totalmente customizada e nem tem muita utilidade, mas é importante para sabermos todos os detalhes da construção de uma métrica, e como o Prometheus lida com ela, desde o primeiro passo até o último.</p>
<p>Noiz já entendemos como construir uma métrica do zero, aprendemos como o Prometheus lida e armazena ela, agora vamos ver o que precisamos, nesse primeiro momento, para busca-la utilizando as queries no Prometheus.</p>
<p>Vamos acessar a interface web do Prometheus e digite a seguinte query na barra de pesquisa:</p>
<pre><code class="language-PROMQL">numero_de_astronautas
</code></pre>
<p> </p>
<p>Com isso você já receberá o valor da métrica, ou melhor, o último valor que foi armazenado no Prometheus.</p>
<p><img src="day-2/images/prometheus-metric-1.png" alt="O valor da métrica" />
 </p>
<p>Via linha de comando você já sabe como fazer, certo?</p>
<pre><code class="language-bash">curl -s http://localhost:9090/api/v1/query?query=numero_de_astronautas | jq .
</code></pre>
<p> </p>
<p>Você vai receber a seguinte saída:</p>
<pre><code class="language-json">{
  &quot;status&quot;: &quot;success&quot;,
  &quot;data&quot;: {
    &quot;resultType&quot;: &quot;vector&quot;,
    &quot;result&quot;: [
      {
        &quot;metric&quot;: {
          &quot;__name__&quot;: &quot;numero_de_astronautas&quot;,
          &quot;instance&quot;: &quot;localhost:8899&quot;,
          &quot;job&quot;: &quot;Primeiro Exporter&quot;
        },
        &quot;value&quot;: [
          1661792007.877,
          &quot;10&quot;
        ]
      }
    ]
  }
}
</code></pre>
<p> </p>
<p>Muito bom! A nossa métrica está por lá!
Uma coisa que podemos fazer é começar a ser mais cirúrgicos, e fazer as queries utilizando o máximo de parâmetros possíveis.</p>
<p>Por exemplo, podemos passar alguns labels para a query, como o nome do job e o nome do instance.</p>
<pre><code class="language-PROMQL">numero_de_astronautas{instance=&quot;localhost:8899&quot;,job=&quot;Primeiro Exporter&quot;}
</code></pre>
<p> </p>
<p>O resultado será o mesmo que o anterior, porém agora com os labels passados. :D</p>
<p>Agora, eu consigo ver o valor dessa métrica nos últimos 5 minutos?</p>
<p>Claro!</p>
<pre><code class="language-PROMQL">numero_de_astronautas{instance=&quot;localhost:8899&quot;,job=&quot;Primeiro Exporter&quot;}[5m]
</code></pre>
<p> </p>
<p><img src="day-2/images/prometheus-metric-2.png" alt="O valor da métrica" />
 </p>
<p>O valor não muda, afinal não é tão fácil assim mudar os astronautas que estão na Estação Espacial. hahaha</p>
<p>E se adicionarmos mais uma métrica?
Vamos imaginar que é importante saber onde está a Estação Espacial nesse momento! Eu sei que ela está no espaço, engraçadão!</p>
<p>O que eu quero saber é em qual parte do planeta Terra (que é redondo) ela está passando por cima? 
Eu sei que o open-notify tem uma API para isso, vamos adicionar essa nova métrica para o nosso primeiro exporter.</p>
<p>Vamos editar e adicionar essa nova configuração em nosso script Python, o arquivo <code>exporter.py</code>:</p>
<p> </p>
<pre><code class="language-python">import requests # Importa o módulo requests para fazer requisições HTTP
import json # Importa o módulo json para converter o resultado em JSON
import time # Importa o módulo time para fazer o sleep
from prometheus_client import start_http_server, Gauge # Importa o módulo Gauge do Prometheus para criar a nossa métrica e o módulo start_http_server para iniciar o servidor

url_numero_pessoas = 'http://api.open-notify.org/astros.json' # URL para pegar o número de astronautas
url_local_ISS = 'http://api.open-notify.org/iss-now.json' # URL para pegar a localização do ISS

def pega_local_ISS(): # Função para pegar a localização da ISS
    try:
        &quot;&quot;&quot;
        Pegar o local da estação espacial internacional
        &quot;&quot;&quot;
        response = requests.get(url_local_ISS) # Faz a requisição para a URL
        data = response.json() # Converte o resultado em JSON
        return data['iss_position'] # Retorna o resultado da requisição
    except Exception as e: # Caso ocorra algum erro
        print(&quot;Não foi possível acessar a url!&quot;) # Imprime uma mensagem de erro
        raise e # Lança a exceção

def pega_numero_astronautas(): # Função para pegar o número de astronautas
    try: # Tenta fazer a requisição HTTP
        &quot;&quot;&quot;
        Pegar o número de astronautas no espaço 
        &quot;&quot;&quot;
        response = requests.get(url) # Faz a requisição HTTP
        data = response.json() # Converte o resultado em JSON
        return data['number'] # Retorna o número de astronautas
    except Exception as e: # Se der algum erro
        print(&quot;Não foi possível acessar a url!&quot;) # Imprime que não foi possível acessar a url
        raise e # Lança a exceção

def atualiza_metricas(): # Função para atualizar as métricas
    try:
        &quot;&quot;&quot;
        Atualiza as métricas com o número de astronautas e local da estação espacial internacional
        &quot;&quot;&quot;
        numero_pessoas = Gauge('numero_de_astronautas', 'Número de astronautas no espaço') # Cria a métrica para o número de astronautas
        longitude = Gauge('longitude_ISS', 'Longitude da Estação Espacial Internacional') # Cria a métrica para a longitude da estação espacial internacional
        latitude = Gauge('latitude_ISS', 'Latitude da Estação Espacial Internacional') # Cria a métrica para a latitude da estação espacial internacional

        while True: # Enquanto True
            numero_pessoas.set(pega_numero_astronautas()) # Atualiza a métrica com o número de astronautas
            longitude.set(pega_local_ISS()['longitude']) # Atualiza a métrica com a longitude da estação espacial internacional
            latitude.set(pega_local_ISS()['latitude']) # Atualiza a métrica com a latitude da estação espacial internacional
            time.sleep(10) # Faz o sleep de 10 segundos
            print(&quot;O número atual de astronautas no espaço é: %s&quot; % pega_numero_astronautas()) # Imprime o número atual de astronautas no espaço
            print(&quot;A longitude atual da Estação Espacial Internacional é: %s&quot; % pega_local_ISS()['longitude']) # Imprime a longitude atual da estação espacial internacional
            print(&quot;A latitude atual da Estação Espacial Internacional é: %s&quot; % pega_local_ISS()['latitude']) # Imprime a latitude atual da estação espacial internacional
    except Exception as e: # Se der algum erro
        print(&quot;Problemas para atualizar as métricas! \n\n====&gt; %s \n&quot; % e) # Imprime que ocorreu um problema para atualizar as métricas
        raise e # Lança a exceção
        
def inicia_exporter(): # Função para iniciar o exporter
    try:
        &quot;&quot;&quot;
        Iniciar o exporter
        &quot;&quot;&quot;
        start_http_server(8899) # Inicia o servidor do Prometheus na porta 8899
        return True # Retorna True
    except Exception as e: # Se der algum erro
        print(&quot;O Servidor não pode ser iniciado!&quot;) # Imprime que não foi possível iniciar o servidor
        raise e # Lança a exceção

def main(): # Função principal
    try:
        inicia_exporter() # Inicia o exporter
        print('Exporter Iniciado') # Imprime que o exporter foi iniciado
        atualiza_metricas() # Atualiza as métricas
    except Exception as e: # Se der algum erro
        print('\nExporter Falhou e Foi Finalizado! \n\n======&gt; %s\n' % e) # Imprime que o exporter falhou e foi finalizado
        exit(1) # Finaliza o programa com erro


if __name__ == '__main__': # Se o programa for executado diretamente
    main() # Executa o main
    exit(0) # Finaliza o programa

</code></pre>
<p> </p>
<p>Muito bem, já adicionamos as novas instruções para o nosso exporter.
Basicamente falamos para a biblioteca <code>prometheus_client</code> que temos duas novas métricas:</p>
<ul>
<li>longitude_ISS: Longitude da Estação Espacial Internacional</li>
<li>latitude_ISS: Latitude da Estação Espacial Internacional</li>
</ul>
<p> </p>
<p>Vamos executar o nosso script para saber se está tudo funcionando bem:</p>
<pre><code class="language-bash">python3 exporter.py

O número atual de astronautas no espaço é: 10
A longitude atual da Estação Espacial Internacional é: 57.7301
A latitude atual da Estação Espacial Internacional é: -32.7545
</code></pre>
<p> </p>
<p>Muito bem, está funcionando! As duas novas métricas já estão disponível e sendo expostas. 
Agora já podemos criar uma nova imagem com a nova versão do nosso script!</p>
<pre><code class="language-bash">docker build -t primeiro-exporter:1.0 .

Sending build context to Docker daemon  6.656kB
Step 1/7 : FROM python:3.8-slim
 ---&gt; bdd3315885d4
Step 2/7 : LABEL maintainer Jeferson Fernando &lt;jeferson@linuxtips.com.br&gt;
 ---&gt; Using cache
 ---&gt; 3d1bad97c1cb
Step 3/7 : LABEL description &quot;Dockerfile para criar o nosso primeiro exporter para o Prometheus&quot;
 ---&gt; Using cache
 ---&gt; 9f41ad63e03a
Step 4/7 : COPY . /app
 ---&gt; Using cache
 ---&gt; 6bc6f9a126f4
Step 5/7 : WORKDIR /app
 ---&gt; Using cache
 ---&gt; 05f03d2025c2
Step 6/7 : RUN pip3 install -r requirements.txt
 ---&gt; Using cache
 ---&gt; 3f2ec4cdfe6a
Step 7/7 : CMD python3 exporter.py
 ---&gt; Using cache
 ---&gt; 6d63ade160c4
Successfully built 6d63ade160c4
Successfully tagged primeiro-exporter:1.0
</code></pre>
<p> </p>
<p>Vamos executar e conferir o resultado!</p>
<pre><code class="language-bash">docker run -d -p 8899:8899 primeiro-exporter:1.0
</code></pre>
<p> </p>
<p>Vamos conferir se as nossas métricas estão chegando no Prometheus.
Vamos primeiro verificar a <code>longitude_ISS</code>:</p>
<pre><code class="language-bash">curl -s http://localhost:9090/api/v1/query\?query\=longitude_ISS | jq .
</code></pre>
<p> </p>
<p>Agora bora conferir a a <code>latitude_ISS</code>:</p>
<pre><code class="language-bash">curl -s http://localhost:9090/api/v1/query\?query\=latitude_ISS | jq .
</code></pre>
<p> </p>
<p>Evidente que podemos conferir tudo isso via interface web. </p>
<p>Vamos verificar a <code>latitude_ISS</code> nos últimos 05 minutos:</p>
<pre><code class="language-PROMQL">latitude_ISS{instance=&quot;localhost:8899&quot;,job=&quot;Primeiro Exporter&quot;}[5m]
</code></pre>
<p> </p>
<p><img src="day-2/images/resultado-query-latitude.png" alt="resultado da nossa query buscando a métrica sobre a latitude" /></p>
<p> </p>
<h3 id="conhecendo-um-pouco-mais-sobre-os-tipos-de-dados-do-prometheus"><a class="header" href="#conhecendo-um-pouco-mais-sobre-os-tipos-de-dados-do-prometheus">Conhecendo um pouco mais sobre os tipos de dados do Prometheus</a></h3>
<p>Vocês sabem que quando estamos descomplicando algo, nós gostamos de ir a fundo e conhecer no detalhe, tudo o que precisamos para ser um expert no assunto. </p>
<p>Aqui com o Prometheus não seria diferente, queremos que você conheça o Prometheus da forma como nós acreditamos ser importante para os desafios do mundo atual, no ambiente das melhores empresas de tecnologia da mundo.</p>
<p>Estou dizendo isso, pois vamos ter que conhecer com um pouco mais de detalhes os tipos de métricas que podemos criar.</p>
<p>Quais os tipos de dados que o Prometheus suporta e que podemos utilizar quando estamos criando os nossos exporters?</p>
<p>Quando nós criamos o nosso primeiro exporter, nós apenas utilizamos um tipo de dado, o <code>gauge</code> que é o tipo de dado utilizado para crirar métricas que podem ser atualizadas.</p>
<p>Esse é apenas um dos tipos de dados que podemos trabalhar no Prometheus, vamos conhecer mais alguns:</p>
<p> </p>
<h4 id="gauge-medidor"><a class="header" href="#gauge-medidor"><strong>gauge: Medidor</strong></a></h4>
<ul>
<li>
<p>O tipo de dado <code>gauge</code> é o tipo de dado utilizado para criar métricas que podem ter seus valores alterados para cima ou para baixo, por exemplo, a ultilização de memória ou cpu. Se quiser trazer para exemplos da vida real, podemos falar que aquelas filas que você odeia é o tipo de dado <code>gauge</code>, ou então a temperatura da sua cidade, ela pode ser alterada para cima ou para baixo, ou seja, é um medidor, é um <code>gauge</code>! :D
Um exemplo de métrica do tipo <code>gauge</code> é a métrica <code>memory_usage</code>, que é uma métrica que mostra a utilização de memória.</p>
<pre><code class="language-PROMQL">memory_usage{instance=&quot;localhost:8899&quot;,job=&quot;Primeiro Exporter&quot;}
</code></pre>
</li>
</ul>
<p> </p>
<h4 id="counter-contador"><a class="header" href="#counter-contador"><strong>counter: Contador</strong></a></h4>
<ul>
<li>
<p>O tipo de dado <code>counter</code> é o tipo de dado utilizado que vai ser incrementado no decorrer do tempo, por exemplo, quando eu quero contar os erros em uma aplicação no decorrer da última hora.
O valor atual do <code>counter</code> quase nunca é importante, pois o que queremos dele são os valores durante uma janela de tempo, por exemplo, quantas vezes a minha aplicação falhou durante o final de semana.
Normalmente as métricas <code>counter</code> possuem o sufixo <code>_total</code> para indicar que é o total de valores que foram contados, por exemplo:</p>
<pre><code class="language-PROMQL">requests_total{instance=&quot;localhost:8899&quot;,job=&quot;Primeiro Exporter&quot;}
</code></pre>
</li>
</ul>
<p> </p>
<h4 id="histogram-histograma"><a class="header" href="#histogram-histograma"><strong>histogram: Histograma</strong></a></h4>
<ul>
<li>
<p>O tipo de dado <code>histogram</code> é o tipo de dado que te permite especificar o seu valor através de buckets predefinidos, por exemplo, o tempo de execução de uma aplicação. Com o <code>histogram</code> eu consigo contar todas as requisições que minha aplicação respondeu entre 0 e 0,5 segundos, ou então as requisições que tiveram respostas entre 1,0 e 2,5 e assim por diante.
Por padrão, os buckets predefinidos são até no máximo 10 segundos, se você quiser mais, você pode criar seus próprios buckets personalizados.
Um coisa super importante, o Prometheus irá contar cada item em cada bucket, e também a soma dos valores.
Uma métrica do tipo <code>histogram</code> inclui alguns itens importantes são adicionados ao final do nome da métrica para indicar o tipo de dado e o tamanho do bucket, por exemplo:</p>
<pre><code class="language-PROMQL">requests_duration_seconds_bucket{le=&quot;0.5&quot;}
</code></pre>
<p>Onde <code>le</code> é o valor limite do bucket, o valor <code>0.5</code> indica que o valor do bucket é até 0,5 segundos, ou seja, aqui nesse bucket poderiam estar os requisições que tiveram respostas entre 0 e 0,5 segundos.</p>
<p>O <code>_bucket</code> é um sufixo que indica que o valor é um bucket.</p>
<p>Ainda temos alguns sufixos que são importantes e que podem ser úteis para nós:</p>
<ul>
<li>
<p>_count: Contador</p>
<ul>
<li>O sufixo <code>_count</code> indica que o valor é um contador, ou seja, o valor é incrementado a cada vez que a métrica é atualizada.</li>
</ul>
</li>
<li>
<p>_sum: Soma</p>
<ul>
<li>O sufixo <code>_sum</code> indica que o valor é uma soma, ou seja, o valor é somado a cada vez que a métrica é atualizada.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>_bucket: Bucket</p>
<ul>
<li>
<p>O sufixo <code>_bucket</code> indica que o valor é um bucket, ou seja, o valor é um bucket.</p>
<p>O ponto alto do <code>histogram</code> é a excelente flexibilidades, pois percentuais e as janelas de tempos podem definidas durante a criação das queries, o ponto negativo é a precisão é um pouco inferior quando comparado com o <code>summary</code>.</p>
</li>
</ul>
</li>
</ul>
<p> </p>
<h4 id="summary-resumo"><a class="header" href="#summary-resumo"><strong>summary: Resumo</strong></a></h4>
<ul>
<li>
<p>O tipo de dado <code>summary</code> é bem parecido com o <code>histogram</code>, com a diferença que os buckets, aqui chamados de <code>quantiles</code>, são definidos por um valor entre 0 e 1, ou seja, o valor do bucket é o valor que está entre os quantiles.</p>
<p>Da mesma forma como no <code>histogram</code>, podemos criar métricas do tipo <code>summary</code> com alguns itens importantes adicionados ao final do nome da métrica, por exemplo:</p>
<pre><code class="language-PROMQL">requests_duration_seconds_sum{instance=&quot;localhost:8899&quot;,job=&quot;Primeiro Exporter&quot;}
</code></pre>
<p>Utilizamos o sufixo <code>_sum</code> indica que o valor é uma soma, ou seja, o valor é somado a cada vez que a métrica é atualizada e o sufixo <code>_count</code> para indicar que o valor é um contador, ou seja, o valor é incrementado a cada vez que a métrica é atualizada.</p>
<p>O ponto alto do <code>summary</code> é a excelente precisão e o ponto baixo é a baixa flexibilidades, pois percentuais e as janelas de tempos precisam ser definidos durante a criação da métrica e não é possível agregar métricas do tipo <code>summary</code> com outras métricas do tipo <code>summary</code> durante a criação das queries.</p>
</li>
</ul>
<p>Percebam que em nosso primeiro exporter, nós somente utilizamos métricas do tipo <code>gauge</code>, pois queremos saber quantas pessoas estão no espaço e também a localização da ISS (International Space Station) ao longo do tempo. </p>
<p>Faz sentido agora? 
Fala a verdade!
Em voz alta! ahahahha!</p>
<p>Em breve vamos criar outros tipos de dados para o Prometheus tratar, agora vamos focar novamente nas queries! </p>
<p> </p>
<h3 id="chega-por-hoje"><a class="header" href="#chega-por-hoje">Chega por hoje!</a></h3>
<p>Muito bem! </p>
<p>Agora é hora de reforçar os conceitos aprendidos até agora.</p>
<p>Então é hora de você ler novamente todo o material e começar a práticar. </p>
<p>Não esqueça, a coisa mais importante aqui nesse momento é a prática, e não apenas o conhecimento. O conhecimento é a base, mas o que faz com que você domine o assunto é a prática.</p>
<p>Então já sabe, né?</p>
<p>Curtiu o dia de hoje? Posso contar com o seu feedback nas redes sociais?</p>
<p>Bora ajudar o projeto e o treinamento a ficarem cada dia melhores!</p>
<p> 
 </p>
<h3 id="lição-de-casa"><a class="header" href="#lição-de-casa">Lição de casa</a></h3>
<p>Agora você tem uma missão, é hora de brincar com tudo o que aprendemos hoje, e claro, tudo o que você puder adicionar a sessão de estudos para deixar o seu aprendizado mais rápido.</p>
<p>A sua lição hoje é criar novas queries somente consumindo as métricas que já estão disponíveis no Prometheus e que você conhece.</p>
<p>Sem preguiça e deixar a imaginação comandar, vamos criar novas queries para nos ajudar a entender melhor o que está acontecendo, certo?</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="descomplicando-o-prometheus-1"><a class="header" href="#descomplicando-o-prometheus-1">Descomplicando o Prometheus</a></h1>
<h2 id="day-3"><a class="header" href="#day-3">DAY-3</a></h2>
<h3 id="o-que-iremos-ver-hoje-2"><a class="header" href="#o-que-iremos-ver-hoje-2">O que iremos ver hoje?</a></h3>
<p>Durante o nosso terceiro dia nessa jornada do conhecimento em relação ao Prometheus, vamos entender e aprender como construir um exporter, o nosso segundo exporter, e dessa vez em Go.
Vamos aprender muito sobre operadores, como o <code>and</code> e o <code>or</code>, e como podemos utilizar esses operadores para criar queries mais complexas e que nos ajudem a entender melhor o que está acontecendo com nossos serviços.
Vamos ainda aprender muito sobre o sensacional Node Exporter, como configura-lo e consultar as métricas que ele nos disponibiliza.
E claro, realizar algumas queries durante o dia de hoje, somente para não perder o costume.
Ahhh, já vamos deixar o Grafana instalado e configurado para que possamos utiliza-lo durante o Day-4. Vamos instalar hoje, no Day-3, somente para deixa-lo um pouco mais ansioso para o nosso próximo dia de aprendizado. :D</p>
<p> </p>
<h3 id="conteúdo-do-day-3"><a class="header" href="#conteúdo-do-day-3">Conteúdo do Day-3</a></h3>
<details>
<summary class="summary">DAY-3</summary>
<ul>
<li><a href="day-3/index.html#descomplicando-o-prometheus">Descomplicando o Prometheus</a>
<ul>
<li><a href="day-3/index.html#day-3">DAY-3</a>
<ul>
<li><a href="day-3/index.html#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="day-3/index.html#conte%C3%BAdo-do-day-3">Conteúdo do Day-3</a></li>
<li><a href="day-3/index.html#criando-o-nosso-segundo-exporter">Criando o nosso segundo exporter</a>
<ul>
<li><a href="day-3/index.html#criando-o-nosso-exporter-usando-go">Criando o nosso exporter usando Go</a></li>
<li><a href="day-3/index.html#adicionando-o-nosso-exporter-no-container">Adicionando o nosso exporter no container</a></li>
<li><a href="day-3/index.html#adicionando-o-novo-target-no-prometheus">Adicionando o novo Target no Prometheus</a></li>
</ul>
</li>
<li><a href="day-3/index.html#as-fun%C3%A7%C3%B5es">As Funções</a>
<ul>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-rate">A função <em>rate</em></a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-irate">A função <em>irate</em></a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-delta">A função <em>delta</em></a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-increase">A função <em>increase</em></a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-sum">A função <em>sum</em></a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-count">A função <em>count</em></a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-avg">A função <em>avg</em></a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-min">A função <em>min</em></a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-max">A função <em>max</em></a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-avg_over_time">A função <em>avg_over_time</em></a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-sum_over_time">A função <em>sum_over_time</em></a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-max_over_time">A função <em>max_over_time</em></a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-min_over_time">A função <em>min_over_time</em></a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-stddev_over_time">A função <em>stddev_over_time</em></a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-by">A função <em>by</em></a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-without">A função <em>without</em></a></li>
<li><a href="day-3/index.html#a-fun%C3%A7%C3%A3o-histogram_quantile-e-quantile">A função <em>histogram_quantile e quantile</em></a></li>
</ul>
</li>
<li><a href="day-3/index.html#praticando-e-usando-as-fun%C3%A7%C3%B5es">Praticando e usando as funções</a></li>
<li><a href="day-3/index.html#operadores">Operadores</a>
<ul>
<li><a href="day-3/index.html#operador-de-igualdade">Operador de igualdade</a></li>
<li><a href="day-3/index.html#operador-de-diferen%C3%A7a">Operador de diferença</a></li>
<li><a href="day-3/index.html#operador-de-maior-que">Operador de maior que</a></li>
<li><a href="day-3/index.html#operador-de-menor-que">Operador de menor que</a></li>
<li><a href="day-3/index.html#operador-de-maior-ou-igual-que">Operador de maior ou igual que</a></li>
<li><a href="day-3/index.html#operador-de-menor-ou-igual-que">Operador de menor ou igual que</a></li>
<li><a href="day-3/index.html#operador-de-multiplica%C3%A7%C3%A3o">Operador de multiplicação</a></li>
<li><a href="day-3/index.html#operador-de-divis%C3%A3o">Operador de divisão</a></li>
<li><a href="day-3/index.html#operador-de-adi%C3%A7%C3%A3o">Operador de adição</a></li>
<li><a href="day-3/index.html#operador-de-subtra%C3%A7%C3%A3o">Operador de subtração</a></li>
<li><a href="day-3/index.html#operador-de-modulo">Operador de modulo</a></li>
<li><a href="day-3/index.html#operador-de-potencia%C3%A7%C3%A3o">Operador de potenciação</a></li>
<li><a href="day-3/index.html#operador-de-agrupamento">Operador de agrupamento</a></li>
<li><a href="day-3/index.html#operador-de-concatena%C3%A7%C3%A3o">Operador de concatenação</a></li>
<li><a href="day-3/index.html#operador-de-compara%C3%A7%C3%A3o-de-strings">Operador de comparação de strings</a></li>
<li><a href="day-3/index.html#chega-de-operadores-por-hoje">Chega de operadores por hoje</a></li>
</ul>
</li>
<li><a href="day-3/index.html#o-node-exporter">O Node Exporter</a>
<ul>
<li><a href="day-3/index.html#os-collectors">Os Collectors</a></li>
<li><a href="day-3/index.html#instala%C3%A7%C3%A3o-do-node-exporter-no-linux">Instalação do Node Exporter no Linux</a></li>
<li><a href="day-3/index.html#adicionando-o-node-exporter-no-prometheus">Adicionando o Node Exporter no Prometheus</a></li>
</ul>
</li>
<li><a href="day-3/index.html#habilitando-novos-collectors-no-node-exporter">Habilitando novos collectors no Node Exporter</a></li>
<li><a href="day-3/index.html#algumas-queries-capturando-m%C3%A9tricas-do-node-exporter">Algumas queries capturando métricas do Node Exporter</a></li>
<li><a href="day-3/index.html#chega-por-hoje">Chega por hoje!</a></li>
<li><a href="day-3/index.html#li%C3%A7%C3%A3o-de-casa">Lição de casa</a></li>
<li><a href="day-3/index.html#refer%C3%AAncias">Referências</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</details>
<p> 
 </p>
<h3 id="criando-o-nosso-segundo-exporter"><a class="header" href="#criando-o-nosso-segundo-exporter">Criando o nosso segundo exporter</a></h3>
<p>Agora que já vimos como criar um exporter, vamos criar um segundo exporter para monitorar o consumo de memória do nosso servidor.</p>
<p>Hoje vamos criar um exporter em Go, então antes de mais nada temos que instalar o Go em nossa máquina.</p>
<p>Para instalar o Go no Ubuntu, basta executar o seguinte comando:</p>
<pre><code class="language-bash">sudo apt install golang
</code></pre>
<p> </p>
<p>Veja no site oficial do Go como instalar em outras distribuições.</p>
<h4 id="criando-o-nosso-exporter-usando-go"><a class="header" href="#criando-o-nosso-exporter-usando-go">Criando o nosso exporter usando Go</a></h4>
<p>Vamos criar um arquivo chamado <code>segundo-exporter.go</code> no diretório <code>segundo-exporter</code> e vamos adicionar o seguinte código:</p>
<pre><code class="language-GO">package main

import ( // importando as bibliotecas necessárias
	&quot;log&quot;      // log
	&quot;net/http&quot; // http

	&quot;github.com/pbnjay/memory&quot;                                // biblioteca para pegar informações de memória
	&quot;github.com/prometheus/client_golang/prometheus&quot;          // biblioteca para criar o nosso exporter
	&quot;github.com/prometheus/client_golang/prometheus/promhttp&quot; // biblioteca criar o servidor web
)

func memoriaLivre() float64 { // função para pegar a memória livre
	memoria_livre := memory.FreeMemory() // pegando a memória livre através da função FreeMemory() da biblioteca memory
	return float64(memoria_livre)        // retornando o valor da memória livre
}

func totalMemory() float64 { // função para pegar a memória total
	memoria_total := memory.TotalMemory() // pegando a memória total através da função TotalMemory() da biblioteca memory
	return float64(memoria_total)         // retornando o valor da memória total
}

var ( // variáveis para definir as nossas métricas do tipo Gauge
	memoriaLivreBytesGauge = prometheus.NewGauge(prometheus.GaugeOpts{ // métrica para pegar a memória livre em bytes
		Name: &quot;memoria_livre_bytes&quot;,                  // nome da métrica
		Help: &quot;Quantidade de memória livre em bytes&quot;, // descrição da métrica
	})

	memoriaLivreMegabytesGauge = prometheus.NewGauge(prometheus.GaugeOpts{ // métrica para pegar a memória livre em megabytes
		Name: &quot;memoria_livre_megabytes&quot;,                  // nome da métrica
		Help: &quot;Quantidade de memória livre em megabytes&quot;, // descrição da métrica
	})

	totalMemoryBytesGauge = prometheus.NewGauge(prometheus.GaugeOpts{ // métrica para pegar a memória total em bytes
		Name: &quot;total_memoria_bytes&quot;,                  // nome da métrica
		Help: &quot;Quantidade total de memória em bytes&quot;, // descrição da métrica
	})

	totalMemoryGigaBytesGauge = prometheus.NewGauge(prometheus.GaugeOpts{ // métrica para pegar a memória total em gigabytes
		Name: &quot;total_memoria_gigabytes&quot;,                  // nome da métrica
		Help: &quot;Quantidade total de memória em gigabytes&quot;, // descrição da métrica
	})
)

func init() { // função para registrar as métricas

	prometheus.MustRegister(memoriaLivreBytesGauge)     // registrando a métrica de memória livre em bytes
	prometheus.MustRegister(memoriaLivreMegabytesGauge) // registrando a métrica de memória livre em megabytes
	prometheus.MustRegister(totalMemoryBytesGauge)      // registrando a métrica de memória total em bytes
	prometheus.MustRegister(totalMemoryGigaBytesGauge)  // registrando a métrica de memória total em gigabytes
}

func main() { // função principal
	memoriaLivreBytesGauge.Set(memoriaLivre())                        // setando o valor da métrica de memória livre em bytes
	memoriaLivreMegabytesGauge.Set(memoriaLivre() / 1024 / 1024)      // setando o valor da métrica de memória livre em megabytes
	totalMemoryBytesGauge.Set(totalMemory())                          // setando o valor da métrica de memória total em bytes
	totalMemoryGigaBytesGauge.Set(totalMemory() / 1024 / 1024 / 1024) // setando o valor da métrica de memória total em gigabytes

	http.Handle(&quot;/metrics&quot;, promhttp.Handler()) // criando o servidor web para expor as métricas

	log.Fatal(http.ListenAndServe(&quot;:7788&quot;, nil)) // iniciando o servidor web na porta 7788
}
</code></pre>
<p> </p>
<p>O código acima está todo comentado explicando o que cada linha faz, então não vou me estender muito explicando o código.</p>
<p>Mas básicamente estamos criando um exporter que vai expor 4 métricas:</p>
<ul>
<li><code>memoria_livre_bytes</code> - métrica que vai retornar a quantidade de memória livre em bytes</li>
<li><code>memoria_livre_megabytes</code> - métrica que vai retornar a quantidade de memória livre em megabytes</li>
<li><code>total_memoria_bytes</code> - métrica que vai retornar a quantidade total de memória em bytes</li>
<li><code>total_memoria_gigabytes</code> - métrica que vai retornar a quantidade total de memória em gigabytes</li>
</ul>
<p> </p>
<p>Lembrando que estamos utilizando os pacotes <code>prometheus</code> para criar o nosso exporter e <code>promhttp</code> para expor as métricas através de um servidor web.
Também estamos utilizando o pacote <code>memory</code> para pegar as informações de memória do nosso servidor, valeu usuário do GitHub <em>pbnjay</em> por criar essa biblioteca.</p>
<p>Estamos utilizando o pacote <code>log</code> para logar os erros que possam acontecer e o pacote <code>net/http</code> para criar o webserver.</p>
<p> </p>
<p>Agora vamos compilar o nosso código e executar o nosso exporter, mas antes precisamos instalar as bibliotecas que utilizamos em nosso código.</p>
<pre><code class="language-BASH">go mod init segundo-exporter
go mod tidy
</code></pre>
<p>Agora sim já podemos compilar o nosso código conforme o exemplo abaixo:</p>
<pre><code class="language-BASH">go build segundo-exporter.go
</code></pre>
<p>Perceba que foi gerado um binário Go chamado <code>segundo-exporter</code>, vamos executa-lo:</p>
<pre><code class="language-BASH">./segundo-exporter
</code></pre>
<p> </p>
<p>Nós configuramos o web server do nosso exporter para rodar na porta 7788, vamos acessar a URL <code>http://localhost:7788/metrics</code> para ver as métricas que o nosso exporter está exportando.</p>
<p>Você pode verificar as métricas atráves do navegador ou utilizando o comando <code>curl</code>:</p>
<pre><code class="language-BASH">curl http://localhost:7788/metrics
</code></pre>
<p> </p>
<p>A saída deve ser algo parecido com o exemplo abaixo:</p>
<pre><code class="language-BASH"># HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile=&quot;0&quot;} 4.4072e-05
go_gc_duration_seconds{quantile=&quot;0.25&quot;} 4.4072e-05
go_gc_duration_seconds{quantile=&quot;0.5&quot;} 8.7174e-05
go_gc_duration_seconds{quantile=&quot;0.75&quot;} 8.7174e-05
go_gc_duration_seconds{quantile=&quot;1&quot;} 8.7174e-05
go_gc_duration_seconds_sum 0.000131246
go_gc_duration_seconds_count 2
# HELP go_goroutines Number of goroutines that currently exist.
# TYPE go_goroutines gauge
go_goroutines 8
# HELP go_info Information about the Go environment.
# TYPE go_info gauge
go_info{version=&quot;go1.18.1&quot;} 1
# HELP go_memstats_alloc_bytes Number of bytes allocated and still in use.
# TYPE go_memstats_alloc_bytes gauge
go_memstats_alloc_bytes 4.69292e+06
# HELP go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed.
# TYPE go_memstats_alloc_bytes_total counter
go_memstats_alloc_bytes_total 6.622168e+06
# HELP go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table.
# TYPE go_memstats_buck_hash_sys_bytes gauge
go_memstats_buck_hash_sys_bytes 4248
# HELP go_memstats_frees_total Total number of frees.
# TYPE go_memstats_frees_total counter
go_memstats_frees_total 6221
# HELP go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata.
# TYPE go_memstats_gc_sys_bytes gauge
go_memstats_gc_sys_bytes 4.709704e+06
# HELP go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use.
# TYPE go_memstats_heap_alloc_bytes gauge
go_memstats_heap_alloc_bytes 4.69292e+06
# HELP go_memstats_heap_idle_bytes Number of heap bytes waiting to be used.
# TYPE go_memstats_heap_idle_bytes gauge
go_memstats_heap_idle_bytes 2.392064e+06
# HELP go_memstats_heap_inuse_bytes Number of heap bytes that are in use.
# TYPE go_memstats_heap_inuse_bytes gauge
go_memstats_heap_inuse_bytes 5.24288e+06
# HELP go_memstats_heap_objects Number of allocated objects.
# TYPE go_memstats_heap_objects gauge
go_memstats_heap_objects 22935
# HELP go_memstats_heap_released_bytes Number of heap bytes released to OS.
# TYPE go_memstats_heap_released_bytes gauge
go_memstats_heap_released_bytes 1.662976e+06
# HELP go_memstats_heap_sys_bytes Number of heap bytes obtained from system.
# TYPE go_memstats_heap_sys_bytes gauge
go_memstats_heap_sys_bytes 7.634944e+06
# HELP go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection.
# TYPE go_memstats_last_gc_time_seconds gauge
go_memstats_last_gc_time_seconds 1.6623888726616032e+09
# HELP go_memstats_lookups_total Total number of pointer lookups.
# TYPE go_memstats_lookups_total counter
go_memstats_lookups_total 0
# HELP go_memstats_mallocs_total Total number of mallocs.
# TYPE go_memstats_mallocs_total counter
go_memstats_mallocs_total 29156
# HELP go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures.
# TYPE go_memstats_mcache_inuse_bytes gauge
go_memstats_mcache_inuse_bytes 38400
# HELP go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system.
# TYPE go_memstats_mcache_sys_bytes gauge
go_memstats_mcache_sys_bytes 46800
# HELP go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures.
# TYPE go_memstats_mspan_inuse_bytes gauge
go_memstats_mspan_inuse_bytes 107712
# HELP go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system.
# TYPE go_memstats_mspan_sys_bytes gauge
go_memstats_mspan_sys_bytes 114240
# HELP go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place.
# TYPE go_memstats_next_gc_bytes gauge
go_memstats_next_gc_bytes 5.281792e+06
# HELP go_memstats_other_sys_bytes Number of bytes used for other system allocations.
# TYPE go_memstats_other_sys_bytes gauge
go_memstats_other_sys_bytes 1.43568e+06
# HELP go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator.
# TYPE go_memstats_stack_inuse_bytes gauge
go_memstats_stack_inuse_bytes 688128
# HELP go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator.
# TYPE go_memstats_stack_sys_bytes gauge
go_memstats_stack_sys_bytes 688128
# HELP go_memstats_sys_bytes Number of bytes obtained from system.
# TYPE go_memstats_sys_bytes gauge
go_memstats_sys_bytes 1.4633744e+07
# HELP go_threads Number of OS threads created.
# TYPE go_threads gauge
go_threads 13
# HELP memoria_livre_bytes Quantidade de memória livre em bytes
# TYPE memoria_livre_bytes gauge
memoria_livre_bytes 5.0984931328e+10
# HELP memoria_livre_megabytes Quantidade de memória livre em megabytes
# TYPE memoria_livre_megabytes gauge
memoria_livre_megabytes 48623.01953125
# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.
# TYPE process_cpu_seconds_total counter
process_cpu_seconds_total 0.02
# HELP process_max_fds Maximum number of open file descriptors.
# TYPE process_max_fds gauge
process_max_fds 1.048576e+06
# HELP process_open_fds Number of open file descriptors.
# TYPE process_open_fds gauge
process_open_fds 35
# HELP process_resident_memory_bytes Resident memory size in bytes.
# TYPE process_resident_memory_bytes gauge
process_resident_memory_bytes 1.4884864e+07
# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.
# TYPE process_start_time_seconds gauge
process_start_time_seconds 1.66238886841e+09
# HELP process_virtual_memory_bytes Virtual memory size in bytes.
# TYPE process_virtual_memory_bytes gauge
process_virtual_memory_bytes 1.494904832e+09
# HELP process_virtual_memory_max_bytes Maximum amount of virtual memory available in bytes.
# TYPE process_virtual_memory_max_bytes gauge
process_virtual_memory_max_bytes 1.8446744073709552e+19
# HELP promhttp_metric_handler_requests_in_flight Current number of scrapes being served.
# TYPE promhttp_metric_handler_requests_in_flight gauge
promhttp_metric_handler_requests_in_flight 1
# HELP promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code.
# TYPE promhttp_metric_handler_requests_total counter
promhttp_metric_handler_requests_total{code=&quot;200&quot;} 6
promhttp_metric_handler_requests_total{code=&quot;500&quot;} 0
promhttp_metric_handler_requests_total{code=&quot;503&quot;} 0
# HELP total_memoria_bytes Quantidade total de memória em bytes
# TYPE total_memoria_bytes gauge
total_memoria_bytes 6.7332653056e+10
# HELP total_memoria_gigabytes Quantidade total de memória em gigabytes
# TYPE total_memoria_gigabytes gauge
total_memoria_gigabytes 62.70841979980469
</code></pre>
<p>Perceba que as nossas métricas estão lá, são elas:</p>
<ul>
<li><code>memoria_livre_bytes</code></li>
<li><code>memoria_livre_megabytes</code></li>
<li><code>total_memoria_bytes</code></li>
<li><code>total_memoria_gigabytes</code></li>
</ul>
<p>Está funcionando lindamente.</p>
<h4 id="adicionando-o-nosso-exporter-no-container"><a class="header" href="#adicionando-o-nosso-exporter-no-container">Adicionando o nosso exporter no container</a></h4>
<p>Agora vamos adicionar o nosso segundo exporter em um outro container, para isso vamos criar um arquivo chamado <code>Dockerfile</code> no diretório <code>segundo-exporter</code> com o seguinte conteúdo:</p>
<pre><code class="language-dockerfile">FROM golang:1.19.0-alpine3.16 AS buildando

WORKDIR /app
COPY . /app
RUN go build segundo-exporter.go

FROM alpine:3.16
LABEL maintainer Jeferson Fernando &lt;jeferson@linuxtips.com.br&gt;
LABEL description &quot;Executando o nosso segundo exporter&quot;
COPY --from=buildando /app/segundo-exporter /app/segundo-exporter
EXPOSE 7788
WORKDIR /app
CMD [&quot;./segundo-exporter&quot;]
</code></pre>
<p> </p>
<p>Agora vamos buildar a imagem do nosso segundo exporter, para isso vamos executar o seguinte comando:</p>
<pre><code class="language-bash">docker build -t segundo-exporter:1.0 .
</code></pre>
<p> </p>
<p>Vamos listar a nossa nova imagem de container com o nosso segundo exporter:</p>
<pre><code class="language-bash">docker images | grep segundo-exporter
</code></pre>
<p> </p>
<p>Muito bom, está lá, agora vamos executar o nosso segundo exporter:</p>
<pre><code class="language-bash">docker run -d --name segundo-exporter -p 7788:7788 segundo-exporter:1.0
</code></pre>
<p> </p>
<p>Agora vamos listar os nossos containers em execução:</p>
<pre><code class="language-bash">docker ps
</code></pre>
<p> </p>
<p>Ele está lá:</p>
<pre><code class="language-bash">CONTAINER ID   IMAGE                  COMMAND                CREATED         STATUS         PORTS                                       NAMES
e51e819c6069   segundo-exporter:1.0   &quot;./segundo-exporter&quot;   6 seconds ago   Up 5 seconds   0.0.0.0:7788-&gt;7788/tcp, :::7788-&gt;7788/tcp   segundo-exporter
</code></pre>
<p> </p>
<p>Vamos acessar as métricas do nosso segundo exporter:</p>
<pre><code class="language-bash">curl http://localhost:7788/metrics
</code></pre>
<p> </p>
<p>Tudo funcionando maravilhosamente bem!</p>
<h4 id="adicionando-o-novo-target-no-prometheus"><a class="header" href="#adicionando-o-novo-target-no-prometheus">Adicionando o novo Target no Prometheus</a></h4>
<p>Agora já podemos configurar o Prometheus para monitorar o nosso segundo exporter. Para isso temos que editar o arquivo <code>prometheus.yml</code> e adicionar o seguinte conteúdo:</p>
<pre><code class="language-yaml">global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
scrape_configs:
  - job_name: &quot;prometheus&quot;
    static_configs:
      - targets: [&quot;localhost:9090&quot;]

  - job_name: &quot;Meu Primeiro Exporter&quot;
    static_configs:
      - targets: [&quot;localhost:8899&quot;]
  
  - job_name: 'segundo-exporter'
    static_configs:
      - targets: ['localhost:7788']
</code></pre>
<p> </p>
<p>Pronto, agora vamos fazer o restart do Prometheus para que ele carregue as novas configurações:</p>
<pre><code class="language-bash">systemctl restart prometheus
</code></pre>
<p> </p>
<p>Vocês também pode fazer isso via comando kill, mas o restart é mais gostosinho de ai meu dels.</p>
<pre><code class="language-bash">kill -HUP $(pidof prometheus)
</code></pre>
<p> </p>
<p>Agora vamos acessar o Prometheus e verificar se o novo target e as nossas novas métricas estão por lá:</p>
<pre><code class="language-bash">http://localhost:9090
</code></pre>
<p> </p>
<p>O nosso novo target está lá:</p>
<p><img src="day-3/images/03-targets.png" alt="Prometheus com 03 targets" /></p>
<p> </p>
<p>E as nossa novas métricas também:</p>
<p><img src="day-3/images/03-metricas.png" alt="Prometheus com 03 targets" /></p>
<p> </p>
<p><img src="day-3/images/04-metricas.png" alt="Prometheus com 03 targets" /></p>
<p> 
 </p>
<h3 id="as-funções"><a class="header" href="#as-funções">As Funções</a></h3>
<p>Uma coisa muito importante é se sentir confortável com o uso da PromQL, pois é com ela que iremos extrair o máximo de nossas métricas e também do mundo sensacional das <code>time series</code>.</p>
<p>Vamos conhecer algumas funções para criação de queries mais efetivas. Vou listar algumas e outras funções vamos conhecendo conforme vamos avançando.</p>
<p> 
 </p>
<h4 id="a-função-rate"><a class="header" href="#a-função-rate">A função <em>rate</em></a></h4>
<p>A função <code>rate</code> representa a taxa de crescimento por segundo de uma determinada métrica como média, durante um intervalo de tempo.</p>
<pre><code class="language-PROMQL">rate(metrica)[5m]
</code></pre>
<p> 
Onde <code>metrica</code> é a métrica que você deseja calcular a taxa de crescimento durante um intervalo de tempo de 5 minutos. Você pode utilizar a função <code>rate</code> para trabalhar com métricas do tipo <code>gauge</code> e <code>counter</code>.</p>
<p>Vamos para um exemplo real:</p>
<pre><code class="language-PROMQL">rate(prometheus_http_requests_total{job=&quot;prometheus&quot;,handler=&quot;/api/v1/query&quot;}[5m])
</code></pre>
<p> </p>
<p>Aqui estou calculando a média da taxa de crescimento por segundo da métrica <code>prometheus_http_requests_total</code>, filtrando por <code>job</code> e <code>handler</code> e durante um intervalo de tempo de 5 minutos. Nesse caso eu quero saber o crescimento nas queries que estão sendo feitas no Prometheus.</p>
<p> 
 </p>
<h4 id="a-função-irate"><a class="header" href="#a-função-irate">A função <em>irate</em></a></h4>
<p>A função <code>irate</code> representa a taxa de crescimento por segundo de uma determinada métrica, mas diferentemente da função <code>rate</code>, a função <code>irate</code> não faz a média dos valores, ela pega os dois últimos pontos e calcula a taxa de crescimento. Quando representado em um gráfico, é possível ver a diferença entre a função <code>rate</code> e a função <code>irate</code>, enquanto o gráfico com o <code>rate</code> é mais suave, o gráfico com o <code>irate</code> é mais &quot;pontiagudo&quot;, você consegue ver quedas e subidas mais nítidas.</p>
<pre><code class="language-PROMQL">irate(metrica[5m])
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja calcular a taxa de crescimento, considerando somente os dois últimos pontos, durante um intervalo de tempo de 5 minutos.</p>
<p>Vamos para um exemplo real:</p>
<pre><code class="language-PROMQL">irate(prometheus_http_requests_total{job=&quot;prometheus&quot;,handler=&quot;/api/v1/query&quot;}[5m])
</code></pre>
<p> </p>
<p>Aqui estou calculando a taxa de crescimento por segundo da métrica <code>prometheus_http_requests_total</code>, considerando somente os dois últimos pontos, filtrando por <code>job</code> e <code>handler</code> e durante um intervalo de tempo de 5 minutos. Nesse caso eu quero saber o crescimento nas queries que estão sendo feitas no Prometheus.</p>
<p> 
 </p>
<h4 id="a-função-delta"><a class="header" href="#a-função-delta">A função <em>delta</em></a></h4>
<p>A função <code>delta</code> representa a diferença entre o valor atual e o valor anterior de uma métrica. Quando estamos falando de <code>delta</code> estamos falando por exemplo do consumo de um disco. Vamos imaginar que eu queira saber o quando eu usei de disco em um determinado intervalo de tempo, eu posso utilizar a função <code>delta</code> para calcular a diferença entre o valor atual e o valor anterior. </p>
<pre><code class="language-PROMQL">delta(metrica[5m])
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja calcular a diferença entre o valor atual e o valor anterior, durante um intervalo de tempo de 5 minutos.</p>
<p> </p>
<p>Vamos para um exemplo real:</p>
<pre><code class="language-PROMQL">delta(prometheus_http_response_size_bytes_count{job=&quot;prometheus&quot;,handler=&quot;/api/v1/query&quot;}[5m])
</code></pre>
<p>Agora estou calculando a diferença entre o valor atual e o valor anterior da métrica <code>prometheus_http_response_size_bytes_count</code>, filtrando por <code>job</code> e <code>handler</code> e durante um intervalo de tempo de 5 minutos. Nesse caso eu quero saber o quanto de bytes eu estou consumindo nas queries que estão sendo feitas no Prometheus.</p>
<p> 
 </p>
<h4 id="a-função-increase"><a class="header" href="#a-função-increase">A função <em>increase</em></a></h4>
<p>Da mesma forma que a função <code>delta</code>, a função <code>increase</code> representa a diferença entre o primeiro e último valor durante um intervalo de tempo, porém a diferença é que a função <code>increase</code> considera que o valor é um contador, ou seja, o valor é incrementado a cada vez que a métrica é atualizada.
Ela começa com o valor 0 e vai somando o valor da métrica a cada atualização.
Você já pode imaginar qual o tipo de métrica que ela trabalha, certo? 
Qual? Counter!</p>
<pre><code class="language-PROMQL">increase(metrica[5m])
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja calcular a diferença entre o primeiro e último valor durante um intervalo de tempo de 5 minutos.</p>
<p> </p>
<p>Vamos para um exemplo real:</p>
<pre><code class="language-PROMQL">increase(prometheus_http_requests_total{job=&quot;prometheus&quot;,handler=&quot;/api/v1/query&quot;}[5m])
</code></pre>
<p> </p>
<p>Aqui estou calculando a diferença entre o primeiro e último valor da métrica <code>prometheus_http_requests_total</code>, filtrando por <code>job</code> e <code>handler</code> e durante um intervalo de tempo de 5 minutos.</p>
<p>Você pode acompanhar o resultado dessa query clicando em <code>Graph</code> e depois em <code>Execute</code>, assim você vai ver o gráfico com o resultado da query fazendo mais sentindo.</p>
<p> 
 </p>
<h4 id="a-função-sum"><a class="header" href="#a-função-sum">A função <em>sum</em></a></h4>
<p>A função <code>sum</code> representa a soma de todos os valores de uma métrica. 
Você pode utilizar a função <code>sum</code> nos tipos de dados <code>counter</code>, <code>gauge</code>, <code>histogram</code> e <code>summary</code>.
Um exemplo de uso da função <code>sum</code> é quando você quer saber o quanto de memória está sendo utilizada por todos os seus containers, ou o quanto de memória está sendo utilizada por todos os seus pods.</p>
<pre><code class="language-PROMQL">sum(metrica)
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja somar.</p>
<p> </p>
<p>Vamos para um exemplo real:</p>
<pre><code class="language-PROMQL">sum(go_memstats_alloc_bytes{job=&quot;prometheus&quot;})
</code></pre>
<p> </p>
<p>Aqui estou somando todos os valores da métrica <code>go_memstats_alloc_bytes</code>, filtrando por <code>job</code> e durante um intervalo de tempo de 5 minutos.</p>
<p> 
 </p>
<h4 id="a-função-count"><a class="header" href="#a-função-count">A função <em>count</em></a></h4>
<p>Outra função bem utilizada é função <code>count</code> representa o contador de uma métrica.
Você pode utilizar a função <code>count</code> nos tipos de dados <code>counter</code>, <code>gauge</code>, <code>histogram</code> e <code>summary</code>.
Um exemplo de uso da função <code>count</code> é quando você quer saber quantos containers estão rodando em um determinado momento ou quantos de seus pods estão em execução.</p>
<pre><code class="language-PROMQL">count(metrica)
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja contar.</p>
<p> </p>
<p>Vamos para um exemplo real:</p>
<pre><code class="language-PROMQL">count(prometheus_http_requests_total)
</code></pre>
<p> </p>
<p>Teremos como resultado o número de valores que a métrica <code>prometheus_http_requests_total</code> possui.</p>
<p> 
 </p>
<h4 id="a-função-avg"><a class="header" href="#a-função-avg">A função <em>avg</em></a></h4>
<p>A função <code>avg</code> representa o valor médio de uma métrica.
Você pode utilizar a função <code>avg</code> nos tipos de dados <code>counter</code>, <code>gauge</code>, <code>histogram</code> e <code>summary</code>.
Essa é uma das funções mais utilizadas, pois é muito comum você querer saber o valor médio de uma métrica, por exemplo, o valor médio de memória utilizada por um container.</p>
<pre><code class="language-PROMQL">avg(metrica)
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja calcular a média.</p>
<p> 
 </p>
<h4 id="a-função-min"><a class="header" href="#a-função-min">A função <em>min</em></a></h4>
<p>A função <code>min</code> representa o valor mínimo de uma métrica.
Você pode utilizar a função <code>min</code> nos tipos de dados <code>counter</code>, <code>gauge</code>, <code>histogram</code> e <code>summary</code>.
Um exemplo de uso da função <code>min</code> é quando você quer saber qual o menor valor de memória utilizada por um container.</p>
<pre><code class="language-PROMQL">min(metrica)
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja calcular o mínimo.</p>
<p> 
 </p>
<h4 id="a-função-max"><a class="header" href="#a-função-max">A função <em>max</em></a></h4>
<p>A função <code>max</code> representa o valor máximo de uma métrica.
Um exemplo de uso da função <code>max</code> é quando você quer saber qual o maior valor de memória pelos nodes de um cluster Kubernetes.</p>
<pre><code class="language-PROMQL">max(metrica)
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja calcular o máximo.</p>
<p> 
 </p>
<h4 id="a-função-avg_over_time"><a class="header" href="#a-função-avg_over_time">A função <em>avg_over_time</em></a></h4>
<p>A função <code>avg_over_time</code> representa a média de uma métrica durante um intervalo de tempo.
Normalmente utilizada para calcular a média de uma métrica durante um intervalo de tempo, como por exemplo, a média de requisições por segundo durante um intervalo de tempo ou ainda as pessoas que estão no espaço durante o último ano. :D</p>
<pre><code class="language-PROMQL">avg_over_time(metrica[5m])
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja calcular a média durante um intervalo de tempo de 5 minutos.</p>
<p> </p>
<p>Vamos para um exemplo real:</p>
<pre><code class="language-PROMQL">avg_over_time(prometheus_http_requests_total{handler=&quot;/api/v1/query&quot;}[5m])
</code></pre>
<p> </p>
<p>Agora estou calculando a média da métrica <code>prometheus_http_requests_total</code>, filtrando por <code>handler</code> e durante um intervalo de tempo de 5 minutos.</p>
<p> 
 </p>
<h4 id="a-função-sum_over_time"><a class="header" href="#a-função-sum_over_time">A função <em>sum_over_time</em></a></h4>
<p>Também temos a função <code>sum_over_time</code>, que representa a soma de uma métrica durante um intervalo de tempo. Vimos a <code>avg_over_time</code> que representa a média, a <code>sum_over_time</code> representa a soma dos valores durante um intervalo de tempo.
Imagina calcular a soma de uma métrica durante um intervalo de tempo, como por exemplo, a soma de requisições por segundo durante um intervalo de tempo ou ainda a soma de pessoas que estão no espaço durante o último ano.</p>
<pre><code class="language-PROMQL">sum_over_time(metrica[5m])
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja calcular a soma durante um intervalo de tempo de 5 minutos.</p>
<p> </p>
<p>Vamos para um exemplo real:</p>
<pre><code class="language-PROMQL">sum_over_time(prometheus_http_requests_total{handler=&quot;/api/v1/query&quot;}[5m])
</code></pre>
<p> </p>
<p>Agora estou calculando a soma da métrica <code>prometheus_http_requests_total</code>, filtrando por <code>handler</code> e durante um intervalo de tempo de 5 minutos.</p>
<p> 
 </p>
<h4 id="a-função-max_over_time"><a class="header" href="#a-função-max_over_time">A função <em>max_over_time</em></a></h4>
<p>A função <code>max_over_time</code> representa o valor máximo de uma métrica durante um intervalo de tempo.</p>
<pre><code class="language-PROMQL">max_over_time(metrica[5m])
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja calcular o valor máximo durante um intervalo de tempo de 5 minutos.</p>
<p> </p>
<p>Vamos para um exemplo real:</p>
<pre><code class="language-PROMQL">max_over_time(prometheus_http_requests_total{handler=&quot;/api/v1/query&quot;}[5m])
</code></pre>
<p> </p>
<p>Agora estamos buscando o valor máximo da métrica <code>prometheus_http_requests_total</code>, filtrando por <code>handler</code> e durante um intervalo de tempo de 5 minutos.</p>
<p> 
 </p>
<h4 id="a-função-min_over_time"><a class="header" href="#a-função-min_over_time">A função <em>min_over_time</em></a></h4>
<p>A função <code>min_over_time</code> representa o valor mínimo de uma métrica durante um intervalo de tempo.</p>
<pre><code class="language-PROMQL">
min_over_time(metrica[5m])
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja calcular o valor mínimo durante um intervalo de tempo de 5 minutos.</p>
<p> </p>
<p>Vamos para um exemplo real:</p>
<pre><code class="language-PROMQL">min_over_time(prometheus_http_requests_total{handler=&quot;/api/v1/query&quot;}[5m])
</code></pre>
<p> </p>
<p>Agora estamos buscando o valor mínimo da métrica <code>prometheus_http_requests_total</code>, filtrando por <code>handler</code> e durante um intervalo de tempo de 5 minutos.</p>
<p> 
 </p>
<h4 id="a-função-stddev_over_time"><a class="header" href="#a-função-stddev_over_time">A função <em>stddev_over_time</em></a></h4>
<p>A função <code>stddev_over_time</code> representa o desvio padrão, que são os valores que estão mais distantes da média, de uma métrica durante um intervalo de tempo.
Um bom exemplo seria para o calculo de desvio padrão para saber se houve alguma anomalia no consumo de disco, por exemplo.</p>
<pre><code class="language-PROMQL">stddev_over_time(metrica[5m])
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja calcular o desvio padrão durante um intervalo de tempo de 5 minutos.</p>
<p> </p>
<p>Vamos para um exemplo real:</p>
<pre><code class="language-PROMQL">stddev_over_time(prometheus_http_requests_total{handler=&quot;/api/v1/query&quot;}[10m])
</code></pre>
<p> </p>
<p>Agora estamos buscando os desvios padrões da métrica <code>prometheus_http_requests_total</code>, filtrando por <code>handler</code> e durante um intervalo de tempo de 10 minutos. Vale a pena verificar o gráfico, pois facilita a visualização dos valores.</p>
<p> 
 </p>
<h4 id="a-função-by"><a class="header" href="#a-função-by">A função <em>by</em></a></h4>
<p>A sensacional e super utilizada função <code>by</code> é utilizada para agrupar métricas. Com ela é possível agrupar métricas por labels, por exemplo, se eu quiser agrupar todas as métricas que possuem o label <code>job</code> eu posso utilizar a função <code>by</code> da seguinte forma:</p>
<pre><code class="language-PROMQL">sum(metrica) by (job)
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja agrupar e <code>job</code> é o label que você deseja agrupar.</p>
<p> </p>
<p>Vamos para um exemplo real:</p>
<pre><code class="language-PROMQL">sum(prometheus_http_requests_total) by (code)
</code></pre>
<p> </p>
<p>Agora estamos somando a métrica <code>prometheus_http_requests_total</code> e agrupando por <code>code</code>, assim sabemos quantas requisições foram feitas por código de resposta.</p>
<p> 
 </p>
<h4 id="a-função-without"><a class="header" href="#a-função-without">A função <em>without</em></a></h4>
<p>A função <code>without</code> é utilizada para remover labels de uma métrica. 
Você pode utilizar a função <code>without</code> nos tipos de dados <code>counter</code>, <code>gauge</code>, <code>histogram</code> e <code>summary</code> e frequentemente usado em conjunto com a função <code>sum</code>.</p>
<pre><code class="language-PROMQL">Por exemplo, se eu quiser remover o label `job` de uma métrica, eu posso utilizar a função `without` da seguinte forma:


```PROMQL
sum(metrica) without (job)
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja remover o label <code>job</code>.</p>
<p> </p>
<p>Vamos para um exemplo real:</p>
<pre><code class="language-PROMQL">sum(prometheus_http_requests_total) without (handler)
</code></pre>
<p> </p>
<p>Agora estamos somando a métrica <code>prometheus_http_requests_total</code> e removendo o label <code>handler</code>, assim sabemos quantas requisições foram feitas por código de resposta, sem saber qual handler foi utilizado para ter uma visão mais geral e focado no código de resposta.</p>
<p> 
 </p>
<h4 id="a-função-histogram_quantile-e-quantile"><a class="header" href="#a-função-histogram_quantile-e-quantile">A função <em>histogram_quantile e quantile</em></a></h4>
<p>As funções <code>histogram_quantile</code> e <code>quantile</code> são muito parecidas, porém a <code>histogram_quantile</code> é utilizada para calcular o percentil de uma métrica do tipo <code>histogram</code> e a <code>quantile</code> é utilizada para calcular o percentil de uma métrica do tipo <code>summary</code>.
Basicamente utilizamos esses funções para saber qual é o valor de uma métrica em um determinado percentil.</p>
<pre><code class="language-PROMQL">quantile(0.95, metrica)
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica do tipo <code>histogram</code> que você deseja calcular o percentil e <code>0.95</code> é o percentil que você deseja calcular.</p>
<p> </p>
<p>Vamos para um exemplo real:</p>
<pre><code class="language-PROMQL">quantile(0.95, prometheus_http_request_duration_seconds_bucket)
</code></pre>
<p> </p>
<p>Agora estamos calculando o percentil de 95% da métrica <code>prometheus_http_request_duration_seconds_bucket</code>, assim sabemos qual é o tempo de resposta de 95% das requisições.</p>
<p> 
 </p>
<h3 id="praticando-e-usando-as-funções"><a class="header" href="#praticando-e-usando-as-funções">Praticando e usando as funções</a></h3>
<p>Agora que já vimos a descrição de algumas funções, vamos começar a praticar e criar algumas queries utilizando as funções.</p>
<p>Vamos criar uma query para saber o quanto de cpu está sendo utilizado no nosso primeiro exporter durante cada execução.</p>
<pre><code class="language-PROMQL">sum(rate(process_cpu_seconds_total{job=&quot;Primeiro Exporter&quot;}[1m])) by (instance)
</code></pre>
<p> </p>
<p>Vamos entender melhor a query acima, o que ela faz?</p>
<ul>
<li>Onde <code>sum(rate(process_cpu_seconds_total{job=&quot;Primeiro Exporter&quot;}[1m]))</code> é a métrica que você deseja extrair.</li>
<li>Onde <code>by (instance)</code> é o agrupamento que você deseja fazer.</li>
</ul>
<p>Ok, conseguimos dividir a query em duas partes, a primeira é a métrica e seus detalhes e a segunda é o agrupamento.</p>
<p>Agora vamos dividir a primeira um pouco mais.</p>
<pre><code class="language-PROMQL">process_cpu_seconds_total{job=&quot;Primeiro Exporter&quot;}[1m]
</code></pre>
<p> </p>
<p>Nessa primeira query, estamos pedindo o valor da métrica <code>process_cpu_seconds_total</code> no último 1 minuto.</p>
<p>O retorno são 04 valores, pois o scraping do Prometheus é feito em intervalos de 15 segundos.</p>
<p><img src="day-3/images/examinando-a-query-1.png" alt="Examinando a query - 1" /></p>
<p> </p>
<p>Maravilha, está rolando bem! 
Agora eu quero saber a média do consumo de cpu no nosso primeiro exporter durante o último 1 minuto.</p>
<pre><code class="language-PROMQL">avg(rate(process_cpu_seconds_total{job=&quot;Primeiro Exporter&quot;}[1m]))
</code></pre>
<p> </p>
<p><img src="day-3/images/examinando-a-query-2.png" alt="Examinando a query - 2" /></p>
<p> </p>
<p>Com isso nós temos a média do consumo de cpu no nosso primeiro exporter durante o último 1 minuto, e perceba que estamos utilizando a função <code>avg</code> para calcular a média, porém estamos também utilizando a função <code>rate</code>.
Precisamos do <code>rate</code> para calcular a taxa de aumento dos valores da métrica durante o último 1 minuto, conforme solicitado na query acima.</p>
<p>Agora vamos adicionar mais um detalhe a nossa query.</p>
<pre><code class="language-PROMQL">by (instance)
</code></pre>
<p> </p>
<p>Então ela ficará assim:</p>
<pre><code class="language-PROMQL">avg(rate(process_cpu_seconds_total{job=&quot;Primeiro Exporter&quot;}[1m])) by (instance)
</code></pre>
<p> </p>
<p><img src="day-3/images/examinando-a-query-3.png" alt="Examinando a query - 3" /></p>
<p> </p>
<p>Com a função <code>by</code> adicionada, é possível agrupar os valores da métrica por um determinado campo, no nosso caso estamos agrupando por <code>instance</code>.</p>
<p>Em nosso exemplo somente temos uma instância no job <code>Primeiro Exporter</code>, então o agrupamente não tem efeito.</p>
<p>Mas se retirarmos da query o label <code>job</code>, o resultado trará também a instância do job <code>prometheus</code>.</p>
<pre><code class="language-PROMQL">avg(rate(process_cpu_seconds_total[1m])) by (instance)
</code></pre>
<p> </p>
<p>Agora a saída trará também o valor da métrica para a instância do job <code>prometheus</code>.</p>
<p><img src="day-3/images/examinando-a-query-4.png" alt="Examinando a query - 4" />
 </p>
<p>Caso queira pegar o menor valor da métrica registrada no último 1 minuto, basta utilizar a função <code>min</code>.</p>
<pre><code class="language-PROMQL">min(rate(process_cpu_seconds_total[1m])) by (instance)
</code></pre>
<p> </p>
<p><img src="day-3/images/examinando-a-query-5.png" alt="Examinando a query - 5" />
 </p>
<p>Caso queira pegar o maior valor da métrica registrada no último 1 minuto, basta utilizar a função <code>max</code>.</p>
<pre><code class="language-PROMQL">max(rate(process_cpu_seconds_total[1m])) by (instance)
</code></pre>
<p> </p>
<p><img src="day-3/images/examinando-a-query-6.png" alt="Examinando a query - 6" />
 </p>
<p>Eu falei bastante sobre as queries e os valores que elas retornam, porém eu nem falei ainda para vocês clicarem na aba <code>Graph</code> e ver os gráficos que são gerados automaticamente.</p>
<p>Vamos ver o gráfico da média do consumo de cpu pelos jobs durante o último 1 minuto.</p>
<p><img src="day-3/images/examinando-a-query-7.png" alt="Examinando a query - 7" /></p>
<p> 
 </p>
<h3 id="operadores"><a class="header" href="#operadores">Operadores</a></h3>
<p>Precisamos falar sobre os operadores, super importante para que possamos trazer ainda mais poder ao nosso querido PromQL e obter resultados ainda mais interessantes.</p>
<p>Vamos conhecer alguns! </p>
<p> 
 </p>
<h4 id="operador-de-igualdade"><a class="header" href="#operador-de-igualdade">Operador de igualdade</a></h4>
<p>O operador de igualdade é utilizado para comparar se dois valores são iguais. </p>
<pre><code class="language-PROMQL">metrica == 1
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja comparar e <code>1</code> é o valor que você deseja comparar, logo se o valor da métrica for igual a 1, o resultado será verdadeiro.</p>
<p> 
 </p>
<h4 id="operador-de-diferença"><a class="header" href="#operador-de-diferença">Operador de diferença</a></h4>
<p>O operador de diferença é utilizado para comparar se dois valores são diferentes. </p>
<pre><code class="language-PROMQL">metrica != 1
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja comparar e <code>1</code> é o valor que você deseja comparar, logo se o valor da métrica for diferente de 1, o resultado será verdadeiro.</p>
<p> 
 </p>
<h4 id="operador-de-maior-que"><a class="header" href="#operador-de-maior-que">Operador de maior que</a></h4>
<p>O operador de maior que é utilizado para comparar se um valor é maior que outro. </p>
<pre><code class="language-PROMQL">metrica &gt; 1
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja comparar e <code>1</code> é o valor que você deseja comparar, logo se o valor da métrica for maior que 1, o resultado será verdadeiro.</p>
<p> 
 </p>
<h4 id="operador-de-menor-que"><a class="header" href="#operador-de-menor-que">Operador de menor que</a></h4>
<p>O operador de menor que é utilizado para comparar se um valor é menor que outro. </p>
<pre><code class="language-PROMQL">metrica &lt; 1
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja comparar e <code>1</code> é o valor que você deseja comparar, logo se o valor da métrica for menor que 1, o resultado será verdadeiro.</p>
<p> 
 </p>
<h4 id="operador-de-maior-ou-igual-que"><a class="header" href="#operador-de-maior-ou-igual-que">Operador de maior ou igual que</a></h4>
<p>O operador de maior ou igual que é utilizado para comparar se um valor é maior ou igual que outro. </p>
<pre><code class="language-PROMQL">metrica &gt;= 1
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja comparar e <code>1</code> é o valor que você deseja comparar, logo se o valor da métrica for maior ou igual a 1, o resultado será verdadeiro.</p>
<p> 
 </p>
<h4 id="operador-de-menor-ou-igual-que"><a class="header" href="#operador-de-menor-ou-igual-que">Operador de menor ou igual que</a></h4>
<p>O operador de menor ou igual que é utilizado para comparar se um valor é menor ou igual que outro. </p>
<pre><code class="language-PROMQL">metrica &lt;= 1
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja comparar e <code>1</code> é o valor que você deseja comparar, logo se o valor da métrica for menor ou igual a 1, o resultado será verdadeiro.</p>
<p> 
 </p>
<h4 id="operador-de-multiplicação"><a class="header" href="#operador-de-multiplicação">Operador de multiplicação</a></h4>
<p>O operador de multiplicação é utilizado para multiplicar dois valores. </p>
<pre><code class="language-PROMQL">metrica * 1
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja multiplicar e <code>1</code> é o valor que você deseja multiplicar, logo se o valor da métrica for multiplicado por 1, o resultado será o valor da métrica.</p>
<p> 
 </p>
<h4 id="operador-de-divisão"><a class="header" href="#operador-de-divisão">Operador de divisão</a></h4>
<p>O operador de divisão é utilizado para dividir dois valores. </p>
<pre><code class="language-PROMQL">metrica / 1
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja dividir e <code>1</code> é o valor pelo qual você deseja dividir a <code>metrica</code>. O resultado será o valor da métrica dividido pelo valor que você passou.</p>
<p> 
 </p>
<h4 id="operador-de-adição"><a class="header" href="#operador-de-adição">Operador de adição</a></h4>
<p>O operador de adição é utilizado para somar dois valores. </p>
<pre><code class="language-PROMQL">metrica + 1
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja somar e <code>1</code> é o valor que você deseja somar a <code>metrica</code>. O resultado será o valor da métrica somado ao valor que você passou.</p>
<p> 
 </p>
<h4 id="operador-de-subtração"><a class="header" href="#operador-de-subtração">Operador de subtração</a></h4>
<p>O operador de subtração é utilizado para subtrair dois valores. </p>
<pre><code class="language-PROMQL">metrica - 1
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja subtrair e <code>1</code> é o valor que você deseja subtrair da <code>metrica</code>. O resultado será o valor da métrica subtraído pelo valor que você passou.</p>
<p> 
 </p>
<h4 id="operador-de-modulo"><a class="header" href="#operador-de-modulo">Operador de modulo</a></h4>
<p>O operador de modulo é utilizado para obter o resto da divisão de dois valores. </p>
<pre><code class="language-PROMQL">metrica % 1
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja obter o resto da divisão e <code>1</code> é o valor pelo qual você deseja obter o resto da divisão da <code>metrica</code>. O resultado será o resto da divisão da métrica pelo valor que você passou.</p>
<p> 
 </p>
<h4 id="operador-de-potenciação"><a class="header" href="#operador-de-potenciação">Operador de potenciação</a></h4>
<p>O operador de potenciação é utilizado para elevar um valor a uma potência. </p>
<pre><code class="language-PROMQL">metrica ^ 1
</code></pre>
<p> </p>
<p>Onde <code>metrica</code> é a métrica que você deseja elevar a uma potência e <code>1</code> é o valor que você deseja elevar a <code>metrica</code>. O resultado será o valor da métrica elevado ao valor que você passou.</p>
<p> 
 </p>
<h4 id="operador-de-agrupamento"><a class="header" href="#operador-de-agrupamento">Operador de agrupamento</a></h4>
<p>O operador de agrupamento é utilizado para agrupar expressões. </p>
<pre><code class="language-PROMQL">(metrica + 1) / 2
</code></pre>
<p> </p>
<p>Perceba que o parenteses foi utilizado para agrupar a expressão <code>(metrica + 1)</code>. Onde <code>metrica</code> é a métrica que você deseja somar e <code>1</code> é o valor que você deseja somar a <code>metrica</code>. Essa parte da expressão será avaliada primeiro e o resultado será dividido por 2.</p>
<p> 
 </p>
<h4 id="operador-de-concatenação"><a class="header" href="#operador-de-concatenação">Operador de concatenação</a></h4>
<p>O operador de concatenação é utilizado para concatenar strings. </p>
<pre><code class="language-PROMQL">&quot;string_a&quot; + &quot;string_b&quot;
</code></pre>
<p> </p>
<p>Onde <code>string_a</code> é a primeira string que você deseja concatenar e <code>string_b</code> é a segunda string que você deseja concatenar. O resultado será a concatenação das duas strings, ou seja, a primeira string seguida da segunda string.</p>
<p> 
 </p>
<h4 id="operador-de-comparação-de-strings"><a class="header" href="#operador-de-comparação-de-strings">Operador de comparação de strings</a></h4>
<p>O operador de comparação de strings é utilizado para comparar se duas strings são iguais. </p>
<pre><code class="language-PROMQL">&quot;string_a&quot; == &quot;string_b&quot;
</code></pre>
<p> </p>
<p>Onde <code>string_a</code> é a primeira string que você deseja comparar e <code>string_b</code> é a segunda string que você deseja comparar. O resultado será verdadeiro se as duas strings forem iguais.</p>
<p> 
 </p>
<h4 id="chega-de-operadores-por-hoje"><a class="header" href="#chega-de-operadores-por-hoje">Chega de operadores por hoje</a></h4>
<p>Conforme você for avançando nos estudos, você irá perceber que esses operadores são muito úteis para criar expressões mais complexas e que podem ser utilizadas para criar alertas mais precisos. Ainda temos alguns operadores que não foram abordados aqui, mas que você pode encontrar na documentação oficial do Prometheus e tbm no decorrer do treinamento.</p>
<p> 
 </p>
<h3 id="o-node-exporter"><a class="header" href="#o-node-exporter">O Node Exporter	</a></h3>
<p>Precisamos falar do exporter mais famoso do universo Prometheus, o sensacional Node Exporter. Com o Node Exporter você consegue coletar métricas de um servidor Linux ou em computadores MacOS, como por exemplo, o uso de CPU, disco, memória, open files, etc.</p>
<p>O Node Exporter é um projeto open source e escrito em Go. Ele é executado no Linux como um serviço e coleta e expõe as métricas do sistema operacional.</p>
<p> 
 </p>
<h4 id="os-collectors"><a class="header" href="#os-collectors">Os Collectors</a></h4>
<p>O Node Exporter possui os <code>collectors</code> que são os responsáveis por capturar as métricas do sistema operacional. Por padrão, o Node Exporter vem com um monte de coletores habilitados, mas você pode habilitar outros, caso queira.</p>
<p>Para que você possa consultar a lista de <code>collectors</code> que vem habilitados por padrão, você pode acessar o link abaixo:</p>
<p><a href="https://github.com/prometheus/node_exporter#enabled-by-default">Lista dos Collectors habilitados por padrão</a></p>
<p> </p>
<p>Temos ainda a lista com os <code>collectors</code> que estão desabilitados por padrão:</p>
<p><a href="https://github.com/prometheus/node_exporter#disabled-by-default">Lista dos Collectors desabilitados por padrão</a></p>
<p> </p>
<p>Vou comentar de alguns <code>collectors</code> que são muito úteis:</p>
<ul>
<li><code>arp</code>: Coleta métricas de ARP (Address Resolution Protocol) como por exemplo, o número de entradas ARP, o número de resoluções ARP, etc.</li>
<li><code>bonding</code>: Coleta métricas de interfaces em modo bonding.</li>
<li><code>conntrack</code>: Coleta métricas de conexões via Netfilter como por exemplo, o número de conexões ativas, o número de conexões que estão sendo rastreadas, etc.</li>
<li><code>cpu</code>: Coleta métricas de CPU.</li>
<li><code>diskstats</code>: Coleta métricas de IO de disco como por exemplo o número de leituras e escritas.</li>
<li><code>filefd</code>: Coleta métricas de arquivos abertos.</li>
<li><code>filesystem</code>: Coleta métricas de sistema de arquivos, como tamanho, uso, etc.</li>
<li><code>hwmon</code>: Coleta métricas de hardware como por exemplo a temperatura.</li>
<li><code>ipvs</code>: Coleta métricas de IPVS.</li>
<li><code>loadavg</code>: Coleta métricas de carga do sistema operacional.</li>
<li><code>mdadm</code>: Coleta métricas de RAID como por exemplo o número de discos ativos.</li>
<li><code>meminfo</code>: Coleta métricas de memória como por exemplo o uso de memória, o número de buffers, caches, etc.</li>
<li><code>netdev</code>: Coleta métricas de rede como por exemplo o número de pacotes recebidos e enviados.</li>
<li><code>netstat</code>: Coleta métricas de rede como por exemplo o número de conexões TCP e UDP.</li>
<li><code>os</code>: Coleta métricas de sistema operacional.</li>
<li><code>selinux</code>: Coleta métricas de SELinux como estado e políticas.</li>
<li><code>sockstat</code>: Coleta métricas de sockets.</li>
<li><code>stat</code>: Coleta métricas de sistema como uptime, forks, etc.</li>
<li><code>time</code>: Coleta métricas de tempo como sincronização de relógio.</li>
<li><code>uname</code>: Coleta métricas de informações.</li>
<li><code>vmstat</code>: Coleta métricas de memória virtual.</li>
</ul>
<p> </p>
<p>Mais para frente vamos ver como habilitar ou desabilitar <code>collectors</code> no Node Exporter.</p>
<p> 
 </p>
<h4 id="instalação-do-node-exporter-no-linux"><a class="header" href="#instalação-do-node-exporter-no-linux">Instalação do Node Exporter no Linux</a></h4>
<p>Vamos instalar o Node Exporter para que possamos ter ainda mais métricas para brincar com o nosso Prometheus, e claro, conhecer esse exporter que é praticamente a escolha padrão da maioria dos ambientes quando estamos falando de métricas de um servidor Linux.</p>
<p>O Node Exporter é um arquivo binário e que precisamos baixar do site oficial do projeto.</p>
<p>Abaixo segue a URL para download do Node Exporter:</p>
<pre><code class="language-bash">https://prometheus.io/download/#node_exporter
</code></pre>
<p> </p>
<p>Acesse a URL e veja qual a última versão disponível para download. No momento em que escrevo esse mateira, a última versão disponível é a 1.3.1.</p>
<p>Vamos fazer o download do arquivo binário do Node Exporter:</p>
<pre><code class="language-bash">wget https://github.com/prometheus/node_exporter/releases/download/v1.3.1/node_exporter-1.3.1.linux-amd64.tar.gz
</code></pre>
<p> </p>
<p>Com o arquivo já em nossa máquina, vamos descompactar-lo:</p>
<pre><code class="language-bash">tar -xvzf node_exporter-1.3.1.linux-amd64.tar.gz
</code></pre>
<p> </p>
<p>Como falamos antes, o Node Exporter é apenas um binário Go, portanto é bem simples fazer a sua instalação em uma máquina Linux. Básicamente vamos seguir o mesmo processo que fizemos para instalar o Prometheus.</p>
<p>Bora mover o arquivo <code>node_exporter</code> para o diretório <code>/usr/local/bin</code>:</p>
<pre><code class="language-bash">sudo mv node_exporter-1.3.1.linux-amd64/node_exporter /usr/local/bin/
</code></pre>
<p> </p>
<p>Vamos ver se está tudo ok com o nosso Node Exporter:</p>
<pre><code class="language-bash">node_exporter --version
</code></pre>
<p> </p>
<p>A saída deve ser parecida com essa:</p>
<pre><code class="language-bash">node_exporter, version 1.3.1 (branch: HEAD, revision: a2321e7b940ddcff26873612bccdf7cd4c42b6b6)
  build user:       root@243aafa5525c
  build date:       20211205-11:09:49
  go version:       go1.17.3
  platform:         linux/amd64
</code></pre>
<p> </p>
<p>Tudo em paz, vamos seguir com a instalação.</p>
<p>Vamos criar o usuário <code>node_exporter</code> para ser o responsável pela execução do serviço:</p>
<pre><code class="language-bash">sudo addgroup --system node_exporter
sudo adduser --shell /sbin/nologin --system --group node_exporter
</code></pre>
<p> </p>
<p>Agora vamos criar o arquivo de configuração do serviço do Node Exporter para o Systemd:</p>
<pre><code class="language-bash">sudo vim /etc/systemd/system/node_exporter.service
</code></pre>
<p> </p>
<p>Vamos adicionar o seguinte conteúdo:</p>
<pre><code class="language-bash">[Unit] # Inicio do arquivo de configuração do serviço
Description=Node Exporter # Descrição do serviço
Wants=network-online.target # Define que o serviço depende da rede para iniciar
After=network-online.target # Define que o serviço deverá ser iniciado após a rede estar disponível

[Service] # Define as configurações do serviço
User=node_exporter # Define o usuário que irá executar o serviço
Group=node_exporter # Define o grupo que irá executar o serviço
Type=simple # Define o tipo de serviço
ExecStart=/usr/local/bin/node_exporter # Define o caminho do binário do serviço

[Install] # Define as configurações de instalação do serviço
WantedBy=multi-user.target # Define que o serviço será iniciado utilizando o target multi-user
</code></pre>
<p> </p>
<p><strong>Importante</strong>: Não esqueça de tirar os comentários do arquivo de configuração do serviço, inclusive tem o arquivo sem comentários no repositório do Github do projeto.
Combinado?</p>
<p> </p>
<p>Como você já sabe, toda vez que adicionamos um novo serviço no Systemd, precisamos dar um reload para que o serviço seja reconhecido:</p>
<pre><code class="language-bash">sudo systemctl daemon-reload
</code></pre>
<p> </p>
<p>E agora vamos iniciar o serviço:</p>
<pre><code class="language-bash">sudo systemctl start node_exporter
</code></pre>
<p> </p>
<p>Precisamos ver se está tudo em paz com o nosso serviço:</p>
<pre><code class="language-bash">sudo systemctl status node_exporter
</code></pre>
<p> </p>
<p>Como é bom ver essa saída sempre quando criamos e iniciamos um novo serviço:</p>
<pre><code class="language-bash">     Loaded: loaded (/etc/systemd/system/node_exporter.service; disabled; vendor preset: enabled)
     Active: active (running) since Wed 2022-09-07 15:15:00 CEST; 3s ago
   Main PID: 50853 (node_exporter)
      Tasks: 6 (limit: 76911)
     Memory: 2.9M
        CPU: 5ms
     CGroup: /system.slice/node_exporter.service
             └─50853 /usr/local/bin/node_exporter
</code></pre>
<p> </p>
<p>O nosso querido e idolatrado Node Exporter está rodando. Agora vamos habilitar o serviço para que ele seja iniciado sempre que o servidor for reiniciado:</p>
<pre><code class="language-bash">sudo systemctl enable node_exporter
</code></pre>
<p> </p>
<p>Importante mencionar que o nosso Node Exporter roda na porta 9100. Para acessar as métricas coletadas pelo Node Exporter, basta acessar a URL <code>http://&lt;IP_DA_MAQUINA&gt;:9100/metrics</code>.</p>
<p>Antes de ver as métricas, bora ver se o Node Exporter está utilizando a porta 9100.
Temos o comando <code>ss</code> que nos permite ver as conexões TCP e UDP que estão abertas em nossa máquina. Vamos usar esse comando para ver se o Node Exporter está escutando na porta 9100:</p>
<pre><code class="language-bash">ss -atunp | grep 9100
</code></pre>
<p> </p>
<p>A saída deve ser parecida com essa:</p>
<pre><code class="language-bash">tcp   LISTEN    0      4096                      *:9100                *:*                                       
</code></pre>
<p> </p>
<p>Muito bom! Está tudo certo com o nosso Node Exporter. Agora vamos ver as métricas coletadas por ele:</p>
<pre><code class="language-bash">curl http://localhost:9100/metrics
</code></pre>
<p> </p>
<p>Lembre-se de mudar o <code>localhost</code> para o IP da sua máquina, caso tenha feito a instalação em outra máquina.</p>
<p>Voltando as métricas coletadas pelo Node Exporter, a saída é gigantesca, são mais de 2 mil métricas, muita coisa. hahaha</p>
<h4 id="adicionando-o-node-exporter-no-prometheus"><a class="header" href="#adicionando-o-node-exporter-no-prometheus">Adicionando o Node Exporter no Prometheus</a></h4>
<p>Lembre-se que essas métricas ainda não estão no Prometheus. Para que elas estejam, precisamos configurar o Prometheus para coletar as métricas do Node Exporter, ou seja, configurar o Prometheus para fazer o <code>scrape</code> do Node Exporter, e para isso precisamos criar mais um <code>job</code> no arquivo de configuração do Prometheus para definir o nosso novo <code>target</code>.</p>
<p>Vamos adicionar o seguinte conteúdo no arquivo de configuração do Prometheus:</p>
<pre><code class="language-bash">  - job_name: 'node_exporter'
	static_configs:
	  - targets: ['localhost:9100']
</code></pre>
<p> </p>
<p><strong>Importante</strong>: Lembrando novamente para que você mude o <code>localhost</code> para o IP da sua máquina, caso tenha feito a instalação em outra máquina.</p>
<p>O arquivo deverá ficar assim:</p>
<pre><code class="language-bash">global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
scrape_configs:
  - job_name: &quot;prometheus&quot;
    static_configs:
      - targets: [&quot;localhost:9090&quot;]

  - job_name: &quot;Meu Primeiro Exporter&quot;
    static_configs:
      - targets: [&quot;localhost:8899&quot;]
  
  - job_name: 'segundo-exporter'
    static_configs:
      - targets: ['localhost:7788']

  - job_name: 'node_exporter'
	static_configs:
	  - targets: ['localhost:9100']
</code></pre>
<p> </p>
<p>Eu nem vou deixar o arquivo comentado aqui, pois você já sabe como funciona o arquivo de configuração do Prometheus, né? hahaha</p>
<p>Agora vamos reiniciar o Prometheus para que ele leia as novas configurações:</p>
<pre><code class="language-bash">sudo systemctl restart prometheus
</code></pre>
<p> </p>
<p>Vamos ver se o nosso novo <code>job</code> foi criado com sucesso:</p>
<pre><code class="language-bash">curl http://localhost:9090/targets
</code></pre>
<p> </p>
<p>Caso você queira ver o novo target via interface web do Prometheus, basta acessar a URL <code>http://localhost:9090/targets</code>. Se liga no print abaixo:</p>
<p><img src="day-3/images/prometheus-targets-day3.png" alt="Prometheus Targets" /></p>
<p>Está lá, o nosso novo <code>job</code> foi criado com sucesso. Agora vamos ver se o Prometheus está coletando as métricas do Node Exporter. Vamos passar o nome do <code>job</code> para o Prometheus, assim a nossa query ficará ainda mais específica:</p>
<pre><code class="language-bash">curl -GET http://localhost:9090/api/v1/query --data-urlencode &quot;query=node_cpu_seconds_total{job='node_exporter'}&quot; | jq .
</code></pre>
<p> </p>
<p>A saída também é bastante grande, e a máquina que eu estou testando tem 32 CPUs, então vou colocar aqui aqui somente uma pequena parte da saída:</p>
<pre><code class="language-json">{
  &quot;status&quot;: &quot;success&quot;,
  &quot;data&quot;: {
    &quot;resultType&quot;: &quot;vector&quot;,
    &quot;result&quot;: [
      {
        &quot;metric&quot;: {
          &quot;__name__&quot;: &quot;node_cpu_seconds_total&quot;,
          &quot;cpu&quot;: &quot;0&quot;,
          &quot;instance&quot;: &quot;localhost:9100&quot;,
          &quot;job&quot;: &quot;node_exporter&quot;,
          &quot;mode&quot;: &quot;idle&quot;
        },
        &quot;value&quot;: [
          1662558580.478,
          &quot;32077.95&quot;
        ]
      },
      {
        &quot;metric&quot;: {
          &quot;__name__&quot;: &quot;node_cpu_seconds_total&quot;,
          &quot;cpu&quot;: &quot;0&quot;,
          &quot;instance&quot;: &quot;localhost:9100&quot;,
          &quot;job&quot;: &quot;node_exporter&quot;,
          &quot;mode&quot;: &quot;iowait&quot;
        },
        &quot;value&quot;: [
          1662558580.478,
          &quot;2.28&quot;
        ]
      },
      {
</code></pre>
<p>Agora vamos fazer a mesma query, mas lá na interface web do Prometheus:</p>
<p><img src="day-3/images/prometheus-query-day3.png" alt="Prometheus Query" /></p>
<p> 
 </p>
<h3 id="habilitando-novos-collectors-no-node-exporter"><a class="header" href="#habilitando-novos-collectors-no-node-exporter">Habilitando novos collectors no Node Exporter</a></h3>
<p>Uma coisa bem interessante em relação ao Node Exporter é a quantidade de <code>collectors</code> que ele possui. Esses <code>collectors</code> são responsáveis por coletar as métricas de cada serviço que você quiser monitorar. Por exemplo, se você quiser monitorar os serviços que são gerenciados pelo <code>systemd</code>, você pode habilitar o <code>collector</code> do <code>systemd</code> no Node Exporter, vamos ver como fazer isso.</p>
<p> </p>
<p>Primeira coisa é criar um novo arquivo onde vamos colocar todas os <code>collectors</code> que queremos habilitar no Node Exporter, no nossa caso, somente o módulo do <code>systemd</code>. </p>
<p>Vamos criar o arquivo <code>/etc/node_exporter/node_exporter_options</code> e o diretório <code>/etc/node_exporter/</code> caso ele não exista:</p>
<pre><code class="language-bash">sudo mkdir /etc/node_exporter
sudo vim /etc/node_exporter/node_exporter_options
</code></pre>
<p> </p>
<p>Agora vamos adicionar a variável de ambiente <code>OPTIONS</code> no arquivo <code>/etc/node_exporter/node_exporter_options</code>:</p>
<pre><code class="language-bash">OPTIONS=&quot;--collector.systemd&quot;
</code></pre>
<p> </p>
<p>Vamos ajustar as permissões do arquivo <code>/etc/node_exporter/node_exporter_options</code>:</p>
<pre><code class="language-bash">sudo chown -R node_exporter:node_exporter /etc/node_exporter/
</code></pre>
<p> </p>
<p>E no arquivo de configuração do serviço do Node Exporter para o SystemD, vamos adicionar a variável de ambiente <code>OPTIONS</code> e o arquivo vai ficar assim:</p>
<pre><code class="language-bash">[Unit]
Description=Node Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=node_exporter
Group=node_exporter
Type=simple
EnvironmentFile=/etc/node_exporter/node_exporter_options
ExecStart=/usr/local/bin/node_exporter $OPTIONS

[Install]
WantedBy=multi-user.target
</code></pre>
<p> </p>
<p>Pronto, adicionamos o nosso novo arquivo que contém a variável de ambiente <code>OPTIONS</code> e agora vamos reiniciar o serviço do Node Exporter para que ele leia as novas configurações:</p>
<pre><code class="language-bash">sudo systemctl daemon-reload
sudo systemctl restart node_exporter
</code></pre>
<p> </p>
<p>Agora vamos ver se o Node Exporter está coletando as métricas do <code>systemd</code>:</p>
<pre><code class="language-bash">curl -GET http://localhost:9100/metrics | grep systemd
</code></pre>
<p> </p>
<p>A saída é bem grande, então vou colocar aqui somente uma pequena parte da saída:</p>
<pre><code class="language-bash">node_scrape_collector_success{collector=&quot;systemd&quot;} 1
# HELP node_systemd_socket_accepted_connections_total Total number of accepted socket connections
# TYPE node_systemd_socket_accepted_connections_total counter
node_systemd_socket_accepted_connections_total{name=&quot;acpid.socket&quot;} 0
node_systemd_socket_accepted_connections_total{name=&quot;apport-forward.socket&quot;} 0
node_systemd_socket_accepted_connections_total{name=&quot;avahi-daemon.socket&quot;} 0
node_systemd_socket_accepted_connections_total{name=&quot;cups.socket&quot;} 0
node_systemd_socket_accepted_connections_total{name=&quot;dbus.socket&quot;} 0
node_systemd_socket_accepted_connections_total{name=&quot;dm-event.socket&quot;} 0
node_systemd_socket_accepted_connections_total{name=&quot;docker.socket&quot;} 0
node_systemd_socket_accepted_connections_total{name=&quot;libvirtd-admin.socket&quot;} 0
node_systemd_socket_accepted_connections_total{name=&quot;libvirtd-ro.socket&quot;} 0
node_systemd_socket_accepted_connections_total{name=&quot;libvirtd.socket&quot;} 0
node_systemd_socket_accepted_connections_total{name=&quot;lvm2-lvmpolld.socket&quot;} 0
node_systemd_socket_accepted_connections_total{name=&quot;nordvpnd.socket&quot;} 0
node_systemd_socket_accepted_connections_total{name=&quot;snapd.socket&quot;} 0
node_systemd_socket_accepted_connections_total{name=&quot;syslog.socket&quot;} 0
node_systemd_socket_accepted_connections_total{name=&quot;systemd-fsckd.socket&quot;} 0

</code></pre>
<p> </p>
<p>Done! Tarefa concluída e super tranquilo de fazer. Agora você já sabe como habilitar novos <code>collectors</code> no Node Exporter e coletar novas métricas! \o/</p>
<p> 
 </p>
<h3 id="algumas-queries-capturando-métricas-do-node-exporter"><a class="header" href="#algumas-queries-capturando-métricas-do-node-exporter">Algumas queries capturando métricas do Node Exporter</a></h3>
<p>Agora que já sabemos como coletar as métricas do Node Exporter, vamos fazer algumas queries para capturar algumas métricas do Node Exporter.</p>
<p> </p>
<p><strong>1. Quantas CPU tem a minha máquina?</strong></p>
<pre><code class="language-bash">count(node_cpu_seconds_total{job='node_exporter', mode='idle'})
</code></pre>
<p> </p>
<p><img src="day-3/images/prometheus-query-day3-2.png" alt="Prometheus Query" /></p>
<p> </p>
<p>Estamos pedindo o Prometheus para contar quantas métricas temos com o nome <code>node_cpu_seconds_total</code>, que estão associadas ao <code>job</code> <code>node_exporter</code> e que o <code>mode</code> é <code>idle</code>. O resultado é 32, ou seja, a minha máquina tem 32 CPUs.</p>
<p>Utilizei o modo <code>idle</code> para contar as CPUs. Cada CPU possui alguns modos, como <code>idle</code>, <code>iowait</code>, <code>irq</code>, <code>nice</code>, <code>softirq</code>, <code>steal</code>, <code>system</code> e <code>user</code>. Se eu não passasse o <code>mode</code> na query, o resultado seria 256, pois teríamos 32 CPUs e cada uma delas possui 8 modos. </p>
<p> </p>
<p>Entendeu?</p>
<p>Você precisa ter criatividade no momento de criar as suas queries, e lembre-se, cada pessoa tem a sua lógica para criar as queries, mas o importante é você entender o que está fazendo e ter a busca constante da melhor e mais performática query, certo?</p>
<p> </p>
<p><strong>2. Qual a porcentagem de uso de CPU da minha máquina?</strong></p>
<pre><code class="language-bash">100 - avg by (cpu) (irate(node_cpu_seconds_total{job='node_exporter', mode='idle'}[5m])) * 100
</code></pre>
<p> </p>
<p><img src="day-3/images/prometheus-query-day3-3.png" alt="Prometheus Query" /></p>
<p> </p>
<p>Estamos pedindo o Prometheus para calcular a média <code>avg</code> por <code>by</code> CPU <code>node_cpu_seconds_total</code>, que estão associadas as labels <code>job</code> <code>node_exporter</code> e que o <code>mode</code> é <code>idle</code>. O resultado será <code>100</code> menos <code>-</code> a média por CPU <code>avg by (cpu)</code> do uso de CPU <code>node_cpu_seconds_total</code>, que é calculado pela taxa de variação <code>irate</code> de 5 minutos <code>5m</code>.</p>
<p>Parece confuso quando escrito, eu sei. Mas vamos quebrar essa query em partes:</p>
<p> </p>
<p>Primeiro, vamos calcular a média por CPU do uso de CPU, que é calculado pela taxa de variação de 5 minutos:</p>
<pre><code class="language-bash">avg by (cpu) (irate(node_cpu_seconds_total{job='node_exporter', mode='idle'}[5m]))
</code></pre>
<p> </p>
<p>Agora vamos multiplicar o resultado por 100, para que o resultado seja em porcentagem:</p>
<pre><code class="language-bash">avg by (cpu) (irate(node_cpu_seconds_total{job='node_exporter', mode='idle'}[5m])) * 100
</code></pre>
<p> </p>
<p>E por fim, vamos subtrair o resultado de 100 para que o resultado seja a porcentagem de uso de CPU, pois o modo <code>idle</code> é o tempo que a CPU ficou ociosa e o que precisamos é o tempo que a CPU ficou em uso, por isso a subtração.</p>
<p>Por exemplo, se eu tenho 30% <code>idle</code>, então eu tenho 70% de uso de CPU. Entendeu?
Então se eu pegar o 100 e subtrair o 30, eu tenho 70, que é a porcentagem de uso de CPU. Agora você entendeu, vai!</p>
<p>Pronto, agora a query já está completa e totalmente explicada! </p>
<p> </p>
<pre><code class="language-bash">100 - avg by (cpu) (irate(node_cpu_seconds_total{job='node_exporter', mode='idle'}[5m])) * 100
</code></pre>
<p> </p>
<p><strong>3. Qual a porcentagem de uso de memória da minha máquina?</strong></p>
<pre><code class="language-bash">100 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100
</code></pre>
<p> </p>
<p><img src="day-3/images/prometheus-query-day3-4.png" alt="Prometheus Query" /></p>
<p> </p>
<p>Estamos pedindo o Prometheus para calcular a porcentagem de uso de memória da minha máquina, que é calculado pela subtração de 100 menos a porcentagem de memória disponível <code>node_memory_MemAvailable_bytes</code> dividido pela memória total <code>node_memory_MemTotal_bytes</code> multiplicado por 100.</p>
<p>Parece confuso quando escrito, eu sei. Mas vamos quebrar essa query em partes:</p>
<p> </p>
<p>Primeiro é calculado o que está dentro dos parênteses, que é a porcentagem de memória disponível <code>node_memory_MemAvailable_bytes</code> dividido pela memória total <code>node_memory_MemTotal_bytes</code>:</p>
<pre><code class="language-bash">node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes
</code></pre>
<p> </p>
<p>Agora vamos multiplicar o resultado por 100, para que o resultado seja em porcentagem:</p>
<pre><code class="language-bash">(node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100
</code></pre>
<p> </p>
<p>E por fim, vamos subtrair o resultado de 100 para que o resultado seja a porcentagem de uso de memória, pois o que precisamos é o tempo que a memória ficou em uso, por isso a subtração.</p>
<p>Por exemplo, se eu tenho 30% <code>MemAvailable</code>, então eu tenho 70% de uso de memória. Mesmo esquema do exemplo anterior.</p>
<p> </p>
<pre><code class="language-bash">100 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100
</code></pre>
<p> </p>
<p><strong>4. Qual a porcentagem de uso de disco da minha máquina?</strong></p>
<pre><code class="language-bash">100 - (node_filesystem_avail_bytes{mountpoint=&quot;/&quot;} / node_filesystem_size_bytes{mountpoint=&quot;/&quot;}) * 100
</code></pre>
<p> </p>
<p><img src="day-3/images/prometheus-query-day3-5.png" alt="Prometheus Query" /></p>
<p> </p>
<p>Estamos pedindo o Prometheus para calcular a porcentagem de uso de disco da minha máquina, que é calculado pela subtração de 100 menos a porcentagem de disco disponível <code>node_filesystem_avail_bytes</code> dividido pelo tamanho total do disco <code>node_filesystem_size_bytes</code> multiplicado por 100.</p>
<p>Vamos deixar isso mais simples, vamos quebrar essa query:</p>
<p> </p>
<p>Primeiro é calculado o que está dentro dos parênteses, que é o espaço do disco disponível <code>node_filesystem_avail_bytes</code> dividido pelo tamanho total do disco <code>node_filesystem_size_bytes</code>:</p>
<pre><code class="language-bash">node_filesystem_avail_bytes{mountpoint=&quot;/&quot;} / node_filesystem_size_bytes{mountpoint=&quot;/&quot;}
</code></pre>
<p> </p>
<p>Agora vamos multiplicar o resultado por 100, para que o resultado seja em porcentagem:</p>
<pre><code class="language-bash">(node_filesystem_avail_bytes{mountpoint=&quot;/&quot;} / node_filesystem_size_bytes{mountpoint=&quot;/&quot;}) * 100
</code></pre>
<p> </p>
<p>E por fim, vamos subtrair o resultado de 100 para que o resultado seja a porcentagem de utilização do disco, por isso a subtração.</p>
<pre><code class="language-bash">100 - (node_filesystem_avail_bytes{mountpoint=&quot;/&quot;} / node_filesystem_size_bytes{mountpoint=&quot;/&quot;}) * 100
</code></pre>
<p> </p>
<p><strong>5. Quanto de espaço está em uso na partição / em gigas?</strong></p>
<pre><code class="language-bash">(node_filesystem_size_bytes{mountpoint=&quot;/&quot;} - node_filesystem_avail_bytes{mountpoint=&quot;/&quot;}) / 1024 / 1024 / 1024
</code></pre>
<p> </p>
<p><img src="day-3/images/prometheus-query-day3-6.png" alt="Prometheus Query" /></p>
<p> </p>
<p>Estamos pedindo o Prometheus para calcular o espaço em uso na partição <code>/</code> em gigas, que é calculado pela subtração do tamanho total do disco <code>node_filesystem_size_bytes</code> menos o espaço do disco disponível <code>node_filesystem_avail_bytes</code> dividido por 1024 (para converter para kilobytes), dividido por 1024 (para converter para megabytes) e dividido por 1024 (para converter para gigabytes), simples não?</p>
<p>Essa eu nem vou quebrar em partes, pois tenho certeza que você já entendeu como funciona.</p>
<p> 
 </p>
<h3 id="chega-por-hoje-1"><a class="header" href="#chega-por-hoje-1">Chega por hoje!</a></h3>
<p>Acho que já temos bastante conteúdo para hoje, então vamos parar por aqui. Já temos bastante conteúdo para você começar a brincar com o Prometheus e ter mais liberdade para criar as suas próprias queries e configurações.
Agora, precisamos muito que você pratique, que você olhe com carinho tudo o que você aprendeu hoje e que você coloque em prática, agora! Não deixe para amanhã o que você pode fazer hoje, não é mesmo? hahhahahah</p>
<p> 
 </p>
<h3 id="lição-de-casa-1"><a class="header" href="#lição-de-casa-1">Lição de casa</a></h3>
<p>Hoje a sua tarefa é praticar a criação de queries para extrair o máximo de informação do Node Exporter.
No final, você deve ter uma lista com as queries que você criou e que você entendeu como elas funcionam. A mesma coisa para as novas métricas que você conheceu, bora criar uma lista com as 5 mais legais que você encontrou e que você entendeu como elas funcionam.</p>
<p> 
 </p>
<h3 id="referências"><a class="header" href="#referências">Referências</a></h3>
<ul>
<li><a href="https://prometheus.io/docs/prometheus/latest/querying/basics/">Prometheus - Querying</a></li>
<li><a href="https://prometheus.io/docs/prometheus/latest/querying/functions/">Prometheus - Querying - Functions</a></li>
<li><a href="https://prometheus.io/docs/prometheus/latest/querying/operators/">Prometheus - Querying - Operators</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="descomplicando-o-prometheus-2"><a class="header" href="#descomplicando-o-prometheus-2">Descomplicando o Prometheus</a></h1>
<h2 id="day-4"><a class="header" href="#day-4">DAY-4</a></h2>
<h3 id="o-que-iremos-ver-hoje-3"><a class="header" href="#o-que-iremos-ver-hoje-3">O que iremos ver hoje?</a></h3>
<p>Uma das coisas mais sensacionais do Prometheus é a quantidade de integrações possíveis. Então hoje vai ser o dia onde nós iremos ver como fazer a integração do Prometheus com o Grafana e o Alertmanager.
Evidente, ainda vamos voltar nessas ferramentas muitas vezes no decorrer do treinamento, mas hoje é o dia de conhecermos como elas funcionam e como podemos integrar com o Prometheus.
 </p>
<h3 id="conteúdo-do-day-4"><a class="header" href="#conteúdo-do-day-4">Conteúdo do Day-4</a></h3>
<details>
<summary class="summary">DAY-4</summary>
<ul>
<li><a href="day-4/index.html#descomplicando-o-prometheus">Descomplicando o Prometheus</a>
<ul>
<li><a href="day-4/index.html#day-4">DAY-4</a>
<ul>
<li><a href="day-4/index.html#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="day-4/index.html#conte%C3%BAdo-do-day-4">Conteúdo do Day-4</a></li>
<li><a href="day-4/index.html#o-grafana">O Grafana</a>
<ul>
<li><a href="day-4/index.html#instalando-o-grafana">Instalando o Grafana</a></li>
<li><a href="day-4/index.html#adicionando-o-prometheus-como-data-source">Adicionando o Prometheus como Data Source</a></li>
<li><a href="day-4/index.html#criando-o-nosso-primeiro-dashboard">Criando o nosso primeiro Dashboard</a></li>
</ul>
</li>
<li><a href="day-4/index.html#alertmanager">Alertmanager</a>
<ul>
<li><a href="day-4/index.html#instalando-o-alertmanager">Instalando o Alertmanager</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</details>
<p> </p>
<h3 id="o-grafana"><a class="header" href="#o-grafana">O Grafana</a></h3>
<p>O Grafana é uma ferramenta sensacional demais, impossível alguém não conhecer, e mais impossível ainda alguém não gostar.</p>
<p>Mas o que é esse tal de Grafana?</p>
<p>Te explico agora!</p>
<p>O Grafana é um projeto open source, e é mantido pela empresa Grafana Labs, empresa sueca e que hoje já possuem diferentes produtos, como o Grafana Cloud, Loki, Tempo, etc.</p>
<p>O Grafana é uma poderosa aplicação web que nos permite visualizar, em tempo real e com dashboards incríveis, os dados de diversas fontes, como por exemplo o Prometheus.</p>
<p>Basicamente o Grafana permite que você crie queries super elaboradas para consultar os dados em TSDBs, como o Prometheus, e depois criar dashboards e alertas incríveis.</p>
<p>O Grafa é uma ferramenta que eu uso muito, e que eu recomendo muito, mesmo que você não tenha o Prometheus, o Grafana pode usar dados de diversas fontes, como por exemplo o MySQL, o PostgreSQL, o MongoDB, etc.</p>
<p>Como falei, o Grafana não utiliza somente o Prometheus como fonte, como <code>datasource</code>, ele possui suporte a diferentes fontes de dados, como por exemplo:</p>
<ul>
<li><a href="https://grafana.com/grafana/plugins/grafana-prometheus-datasource">Prometheus</a></li>
<li><a href="https://grafana.com/grafana/plugins/grafana-influxdb-datasource">InfluxDB</a></li>
<li><a href="https://grafana.com/grafana/plugins/grafana-mysql-datasource">MySQL</a></li>
<li><a href="https://grafana.com/grafana/plugins/grafana-postgres-datasource">Postgres</a></li>
<li><a href="https://grafana.com/grafana/plugins/grafana-elasticsearch-datasource">Elasticsearch</a></li>
<li><a href="https://grafana.com/grafana/plugins/grafana-google-cloud-monitoring-datasource">Google Cloud Monitoring</a></li>
<li><a href="https://grafana.com/grafana/plugins/grafana-azure-monitor-datasource">Azure Monitor</a></li>
<li><a href="https://grafana.com/grafana/plugins/grafana-aws-cloudwatch-datasource">AWS CloudWatch</a></li>
<li><a href="https://grafana.com/grafana/plugins/grafana-opentsdb-datasource">OpenTSDB</a></li>
</ul>
<p> </p>
<p>Essas fontes de dados são chamadas de <code>datasources</code>, e o Grafana consegue se conectar a elas e obter os dados que precisamos, e assim ter as métricas que precisamos para montar os nossos dashboards.</p>
<p>O melhor de tudo, o Grafana trata esses <code>datasources</code> como plugins, então você pode criar o seu próprio <code>datasource</code> e utilizar no Grafana, caso ele não tenha suporte a alguma fonte de dados que você precise, ou até mesmo se você quiser criar um <code>datasource</code> para uma fonte de dados que você mesmo criou, sensacional né?</p>
<p> 
 </p>
<h4 id="instalando-o-grafana"><a class="header" href="#instalando-o-grafana">Instalando o Grafana</a></h4>
<p>Vamos começar a nossa jornada na instalação do Grafana, nesse nosso primeiro exemplo vamos realizar a instalação do Grafana como um serviço no Linux, mas seguir a mesma lógica que usamos para instalar o nosso Prometheus.</p>
<p>Ainda vamos ver a instalação e configuração do Prometheus e do Grafana como containers rodando em nosso querido Kubernetes, pode ficar tranquila Pessoa_X!</p>
<p>Bem, vamos lá!</p>
<p>Primeira coisa que temos que fazer é visitar a documentação oficial do Grafana, e lá vamos encontrar a documentação para a sua instalação em diferentes sistemas operacionais, como por exemplo:</p>
<ul>
<li><a href="https://grafana.com/docs/grafana/latest/installation/debian/">Instalação no Linux</a></li>
<li><a href="https://grafana.com/docs/grafana/latest/installation/windows/">Instalação no Windows</a></li>
<li><a href="https://grafana.com/docs/grafana/latest/installation/mac/">Instalação no Mac</a></li>
</ul>
<p>Em nosso exemplo vamos instalar o Grafana no Linux, então vamos seguir a documentação para a instalação no Linux, que você pode acessar <a href="https://grafana.com/docs/grafana/latest/installation/debian/">aqui</a>.</p>
<p> </p>
<p>Para a nossa alegria, o Grafana disponibiliza um repositório para a instalação do Grafana no Linux, como por exemplo no Ubuntu, que estão utilizando desde o começo. :)</p>
<p>Primeira coisa, vamos garantir que alguns pacotes necessários para a instalação do Grafana estejam instalados em nosso sistema, para isso vamos executar o seguinte comando:</p>
<pre><code class="language-bash">sudo apt-get install -y apt-transport-https software-properties-common wget
</code></pre>
<p> </p>
<p>Onde estamos instalando os pacotes</p>
<ul>
<li><code>apt-transport-https</code> - para permitir que o apt use pacotes HTTPS</li>
<li><code>software-properties-common</code> - para permitir que o apt adicione repositórios de terceiros</li>
<li><code>wget</code> - ferramenta utilizada para baixar arquivos da internet</li>
</ul>
<p> </p>
<p>Antes de adicionar o repo do Grafana, precisamos adicionar a chave GPG do repo do Grafana:</p>
<pre><code class="language-bash">wget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -
</code></pre>
<p> </p>
<p>Pronto, agora vamos adicionar o repo do Grafana em nossa máquina, para isso vamos executar o seguinte comando:</p>
<pre><code class="language-bash">sudo add-apt-repository &quot;deb https://packages.grafana.com/oss/deb stable main&quot;
</code></pre>
<p> </p>
<p>Vamos executat o comando <code>apt-get update</code> para atualizar o nosso cache de pacotes e na sequência vamos instalar o Grafana:</p>
<pre><code class="language-bash">sudo apt-get update
sudo apt-get install grafana
</code></pre>
<p> </p>
<p>Se tudo rolou bem, agora o Grafana já está instalado em nossa máquina, vamos iniciar o serviço do Grafana e habilitar o mesmo para iniciar junto com o sistema operacional:</p>
<pre><code class="language-bash">sudo systemctl start grafana-server
sudo systemctl enable grafana-server
</code></pre>
<p> </p>
<p>Para verificar se o Grafana está rodando, execute:</p>
<pre><code class="language-bash">sudo systemctl status grafana-server
</code></pre>
<p> </p>
<p>Se a saída do comando for parecida com essa, então o Grafana está rodando:</p>
<pre><code class="language-bash">● grafana-server.service - Grafana instance
     Loaded: loaded (/lib/systemd/system/grafana-server.service; enabled; vendor preset: enabled)
     Active: active (running) since Wed 2022-09-07 19:34:32 CEST; 6s ago
       Docs: http://docs.grafana.org
   Main PID: 89168 (grafana-server)
      Tasks: 36 (limit: 76911)
     Memory: 43.7M
        CPU: 585ms
     CGroup: /system.slice/grafana-server.service
</code></pre>
<p> </p>
<p>Como falamos, o Grafana é uma aplicação web, sendo assim, precisamos acessar a aplicação através de um navegador, para isso vamos acessar a URL <code>http://localhost:3000</code>:</p>
<p><img src="day-4/images/grafana-login.png" alt="Grafana - Login" /></p>
<p> </p>
<p>Muito bem, estamos vendo a tela de login do Grafana, isso significa que temos que ter um usuário para conseguir acessar a aplicação. :D
O usuário padrão do Grafana é <code>admin</code> e a senha padrão é <code>admin</code>, quando não especificamos um usuário inicial durante a instalação do Grafana, então ele cria um usuário padrão e com a senha padrão.</p>
<p>Vamos logar utilizando o usuário <code>admin</code> e a senha <code>admin</code>:</p>
<p><img src="day-4/images/grafana-mudar-senha.png" alt="Grafana - Home" /></p>
<p> </p>
<p>Perceba que em seu primeiro login, ele pede para você mudar a senha do usuário <code>admin</code>, então vamos mudar a senha para <code>giropops</code>, no meu caso, no de seu, você que manda. hahaha</p>
<p><img src="day-4/images/grafana-home.png" alt="Grafana - Home" /></p>
<p> </p>
<p>Agora sim estamos logados e vendo a tela inicial do Grafana, por enquanto não temos nada de interessante para ver, mas vamos resolver isso em breve. :)</p>
<p> 
 </p>
<h4 id="adicionando-o-prometheus-como-data-source"><a class="header" href="#adicionando-o-prometheus-como-data-source">Adicionando o Prometheus como Data Source</a></h4>
<p>Nos ainda vamos ver mais detalhes do Grafana no Day-4, mas somente para não deixar você com agua na boca, vamos adicionar o Prometheus como Data Source no Grafana, para que possamos começar a criar nossos Dashboards.</p>
<p>Primeira coisa que precisamos fazer é acessar a página de configuração do Data Source, para isso vamos clicar no menu lateral esquerdo em <code>Configuration</code> e depois em <code>Data Sources</code>:</p>
<p><img src="day-4/images/grafana-data-sources.png" alt="Grafana - Data Sources" /></p>
<p> </p>
<p><img src="day-4/images/grafana-data-source-2.png" alt="Grafana - Add Data Source" /></p>
<p> </p>
<p>Agora vamos clicar no botão <code>Add data source</code> e selecionar o Prometheus:</p>
<p><img src="day-4/images/grafana-add-data-source.png" alt="Grafana - Add Data Source" /></p>
<p> </p>
<p><img src="day-4/images/grafana-add-data-source-2.png" alt="Grafana - Add Data Source" /></p>
<p> </p>
<p>Agora vamos preencher com as informações do nosso Prometheus, a primeira informação que precisamos preencher é o nome do Data Source, vamos colocar <code>Prometheus</code>.</p>
<p>Depois vamos preencher a URL do Prometheus, que no nosso caso é <code>http://localhost:9090</code>.</p>
<p>Por agora, não vamos adicionar nenhuma informação extra, como por exemplo tipos de autenticação, alertas, etc.</p>
<p>Agora é clicar no botão <code>Save &amp; Test</code> para salvar as configurações e testar a conexão com o Prometheus:</p>
<p><img src="day-4/images/grafana-add-data-source-3.png" alt="Grafana - Add Data Source" /></p>
<p> </p>
<p>Se tudo deu certo, vamos ver a seguinte mensagem:</p>
<p><img src="day-4/images/grafana-add-data-source-4.png" alt="Grafana - Add Data Source" /></p>
<p> </p>
<p><img src="day-4/images/grafana-add-data-source-5.png" alt="Grafana - Add Data Source" /></p>
<p> </p>
<p>Pronto, o Grafana já está configurado para se conectar com o Prometheus, agora vamos criar nosso primeiro Dashboard. :)</p>
<p> 
 </p>
<h4 id="criando-o-nosso-primeiro-dashboard"><a class="header" href="#criando-o-nosso-primeiro-dashboard">Criando o nosso primeiro Dashboard</a></h4>
<p>Muito bem! Chegou o grande momento de criarmos o nosso primeiro Dashboard no Grafana, bem simples ainda, afinal é o nosso primeiro Dashboard.</p>
<p>Primeiro passo, vamos clicar no menu lateral esquerdo em <code>Dashboard</code> e na sequência vamos clicar no botão <code>New Dashboard</code>:</p>
<p><img src="day-4/images/grafana-new-dashboard.png" alt="Grafana - New Dashboard" /></p>
<p> </p>
<p>Agora vamos escolher o tipo de Dashboard que queremos criar, vamos clicar em <code>Add new panel</code>:</p>
<p><img src="day-4/images/grafana-new-dashboard-2.png" alt="Grafana - New Dashboard" /></p>
<p> </p>
<p>Pronto, agora já podemos começar a criar o nosso primeiro dashboard. :D</p>
<p><img src="day-4/images/grafana-new-dashboard-3.png" alt="Grafana - New Dashboard" /></p>
<p> </p>
<p>Pra ficar mais fácil, vamos dividir essa tela em 3 zonas:</p>
<ol>
<li>
<p>A primeira zona é a zona de configuração do painel, onde podemos configurar o título do painel, o tipo de gráfico, etc.</p>
</li>
<li>
<p>A segunda zona é a zona de configuração do <code>Data Source</code>, onde podemos escolher qual <code>Data Source</code> queremos utilizar para alimentar o painel.</p>
</li>
<li>
<p>A terceira zona é a zona de configuração do <code>Query</code>, onde podemos escolher qual métrica queremos visualizar no painel.</p>
</li>
</ol>
<p><img src="day-4/images/grafana-new-dashboard-dividido.png" alt="Grafana - New Dashboard" /></p>
<p> </p>
<p>Vamos começar pela zona de configuração do painel, vamos clicar no botão <code>Panel Title</code> e vamos mudar o título do painel para <code>CPU Usage</code>:</p>
<p><img src="day-4/images/grafana-new-dashboard-4.png" alt="Grafana - New Dashboard" /></p>
<p> </p>
<p>Agora vamos definir o data source que queremos utilizar para alimentar o painel, por agora somente temos o do Prometheus, e ele já está selecionado, então vamos deixar assim mesmo.</p>
<p><img src="day-4/images/grafana-new-dashboard-5.png" alt="Grafana - New Dashboard" /></p>
<p> </p>
<p>Aqui nós temos dois modos de construção de queries, sim, nós iremos construir queries para o Grafana, mas não se preocupe, é bem simples. :D
O primeiro modo, que está se tornando o padrão, é o modo <code>Builder</code>, que facilita a criação de queries, uma vez que é possível selecionar campos, funções, etc, através de menus.</p>
<p>Vamos construir nessa primeira vez a query utilizando o modo <code>Builder</code>, então vamos clicar no botão <code>Builder</code>:</p>
<p><img src="day-4/images/grafana-new-dashboard-6.png" alt="Grafana - New Dashboard" /></p>
<p> </p>
<p>Agora vamos em <code>Metrics</code> e vamos selecionar a métrica <code>node_cpu_seconds_total</code>:</p>
<p><img src="day-4/images/grafana-new-dashboard-7.png" alt="Grafana - New Dashboard" /></p>
<p> </p>
<p>Vamos pedir para filtrar pelo label <code>mode</code> e vamos selecionar o valor <code>idle</code>:</p>
<p><img src="day-4/images/grafana-new-dashboard-8.png" alt="Grafana - New Dashboard" /></p>
<p> </p>
<p>Precisamos ainda utilizar a função <code>rate</code> para calcular a taxa de variação da métrica, então vamos clicar em <code>+ Operations</code>, depois em <code>Range functions</code> e por fim, selecionar a função <code>rate</code>, agora temos aque adicionar o intervalo de tempo que queremos utilizar no campo <code>Range</code>:</p>
<p><img src="day-4/images/grafana-new-dashboard-9.png" alt="Grafana - New Dashboard" /></p>
<p> </p>
<p><img src="day-4/images/grafana-new-dashboard-10.png" alt="Grafana - New Dashboard" /></p>
<p> </p>
<p>E finalizando, vamos adicionar uma legenda para o gráfico, vamos clicar em <code>Options</code> e depois em <code>Legend</code> e vamos adicionar a legenda <code>{{cpu}}</code>:</p>
<p><img src="day-4/images/grafana-new-dashboard-11.png" alt="Grafana - New Dashboard" /></p>
<p> </p>
<p>Agora vamos clicar no botão <code>Run queries</code> para executar a query e vermos o resultado:</p>
<p><img src="day-4/images/grafana-new-dashboard-12.png" alt="Grafana - New Dashboard" /></p>
<p> </p>
<p>Agora precisamos clicar em <code>Apply</code> para salvar as configurações do painel:</p>
<p><img src="day-4/images/grafana-new-dashboard-13.png" alt="Grafana - New Dashboard" /></p>
<p> </p>
<p>Pronto, nosso primeiro dashboard está pronto!
Ainda é bastante simples, mas já deu pra matar a vontade de conhecer o Grafana, né? :D</p>
<p>Ainda vamos voltar para o Grafana durante o dia de hoje para brincar um pouco mais, mas agora vamos colocar o nosso foco no Alertmanager por um momento. :)</p>
<p> 
 </p>
<h3 id="alertmanager"><a class="header" href="#alertmanager">Alertmanager</a></h3>
<p>O Alertmanager é o responsável por gerenciar os alertas que são criados pelo Prometheus, ele é um serviço que recebe os alertas do Prometheus, organiza e os encaminha para os serviços de notificação, como o Slack, e-mail, pagerduty, OpsGenie, etc.</p>
<p>O Alertmanager é um aplicação desenvolvida em Go, e é distribuído como um binário estático, ou seja, não é necessário instalar nenhuma dependência para utilizá-lo. O que vamos precisar fazer, evidemente, é criar um serviço no Systemd para gerencia-lo.</p>
<h4 id="instalando-o-alertmanager"><a class="header" href="#instalando-o-alertmanager">Instalando o Alertmanager</a></h4>
<p>Primeira coisa que precisamos fazer é baixar o binário do Alertmanager, vamos fazer isso através do comando <code>wget</code>. </p>
<p>O endereço do projeto do Alertmanager é o mesmo de onde fizemos o download do Prometheus e do Node Exporter. :D</p>
<p>https://prometheus.io/download/</p>
<p>Vamos baixar a versão mais recente do Alertmanager, no momento em que escrevo esse material, a versão mais recente é a <code>0.24.0</code>, então vamos baixar o binário com o seguinte comando:</p>
<pre><code class="language-bash">wget https://github.com/prometheus/alertmanager/releases/download/v0.24.0/alertmanager-0.24.0.linux-amd64.tar.gz
</code></pre>
<p> </p>
<p>Agora vamos descompactar o arquivo que baixamos, vamos utilizar o comando <code>tar</code> para isso:</p>
<pre><code class="language-bash">tar -xvzf alertmanager-0.24.0.linux-amd64.tar.gz
</code></pre>
<p> </p>
<p>Agora nós temos um diretório chamado <code>alertmanager-0.24.0.linux-amd64</code>, vamos entrar nesse diretório e copiar o binário do Alertmanager para o diretório <code>/usr/local/bin</code>:</p>
<pre><code class="language-bash">cd alertmanager-0.24.0.linux-amd64
cp alertmanager /usr/local/bin
</code></pre>
<p> </p>
<p>Agora vamos criar o diretório <code>/etc/alertmanager</code> e copiar o arquivo de configuração do Alertmanager para esse diretório:</p>
<pre><code class="language-bash">mkdir /etc/alertmanager
cp alertmanager.yml /etc/alertmanager
</code></pre>
<p> </p>
<p>Vamos dar uma olhada no arquivo de configuração do Alertmanager:</p>
<pre><code class="language-bash">cat /etc/alertmanager/alertmanager.yml
</code></pre>
<p> </p>
<pre><code class="language-yaml">route:
  group_by: ['alertname']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 1h
  receiver: 'web.hook'
receivers:
  - name: 'web.hook'
    webhook_configs:
      - url: 'http://127.0.0.1:5001/'
inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'dev', 'instance']
</code></pre>
<p> </p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="descomplicando-o-prometheus-3"><a class="header" href="#descomplicando-o-prometheus-3">Descomplicando o Prometheus</a></h1>
<h2 id="day-5"><a class="header" href="#day-5">DAY-5</a></h2>
<h3 id="o-que-iremos-ver-hoje-4"><a class="header" href="#o-que-iremos-ver-hoje-4">O que iremos ver hoje?</a></h3>
<details>
<summary class="summary">DAY-5</summary>
</details><div style="break-before: page; page-break-before: always;"></div><h1 id="descomplicando-o-prometheus-4"><a class="header" href="#descomplicando-o-prometheus-4">Descomplicando o Prometheus</a></h1>
<h2 id="day-6"><a class="header" href="#day-6">DAY-6</a></h2>
<h3 id="o-que-iremos-ver-hoje-5"><a class="header" href="#o-que-iremos-ver-hoje-5">O que iremos ver hoje</a></h3>
<p>Durante o dia de hoje iremos aprender sobre todas as possibilidades que temos com a utilização do Prometheus + Kubernetes!
Hoje é dia de conhecer o sensacional <a href="https://github.com/prometheus-operator/kube-prometheus">kube-prometheus</a>, projeto esse criado pelos mesmos criadores do <a href="https://github.com/prometheus-operator/prometheus-operator">Prometheus Operator</a>, que nos permite monitorar o nosso cluster de Kubernetes de forma simples e eficiente. Além disso, iremos aprender como utilizar o <a href="https://github.com/kubernetes-sigs/prometheus-adapter">Prometheus Adapter</a> para que possamos utilizar o nosso querido e lindo Prometheus como fonte de dados para o <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">Horizontal Pod Autoscaler</a>, ou seja, iremos aprender como utilizar o nosso querido e lindo Prometheus para escalar nossos pods de forma automática!
E ainda de quebra você vai aprender como instalar o Kubernetes, mais do que isso, você vai aprender como instalar um cluster EKS! Sim, você vai aprender como instalar um cluster EKS, o cluster de Kubernetes da AWS, através da ferramenta <a href="https://eksctl.io/">eksctl</a>, que é uma ferramenta de linha de comando que nos permite instalar um cluster EKS em minutos!</p>
<h3 id="conteúdo-do-day-6"><a class="header" href="#conteúdo-do-day-6">Conteúdo do Day-6</a></h3>
<details>
<summary>DAY-6</summary>
<ul>
<li><a href="day-6/index.html#descomplicando-o-prometheus">Descomplicando o Prometheus</a>
<ul>
<li><a href="day-6/index.html#day-6">DAY-6</a>
<ul>
<li><a href="day-6/index.html#o-que-iremos-ver-hoje">O que iremos ver hoje</a></li>
<li><a href="day-6/index.html#conte%C3%BAdo-do-day-6">Conteúdo do Day-6</a></li>
<li><a href="day-6/index.html#o-que-%C3%A9-o-kube-prometheus">O que é o kube-prometheus</a>
<ul>
<li><a href="day-6/index.html#instalando-o-nosso-cluster-kubernetes">Instalando o nosso cluster Kubernetes</a></li>
<li><a href="day-6/index.html#instalando-o-kube-prometheus">Instalando o Kube-Prometheus</a></li>
<li><a href="day-6/index.html#acessando-o-grafana">Acessando o Grafana</a></li>
<li><a href="day-6/index.html#acessando-o-prometheus">Acessando o Prometheus</a></li>
<li><a href="day-6/index.html#acessando-o-alertmanager">Acessando o AlertManager</a></li>
</ul>
</li>
<li><a href="day-6/index.html#chega-por-hoje">Chega por hoje!</a></li>
<li><a href="day-6/index.html#li%C3%A7%C3%A3o-de-casa">Lição de casa</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</details>
<h3 id="o-que-é-o-kube-prometheus"><a class="header" href="#o-que-é-o-kube-prometheus">O que é o kube-prometheus</a></h3>
<p>O kube-prometheus é um conjunto de manifestos do Kubernetes que nos permite ter o Prometheus Operator, Grafana, AlertManager, Node Exporter, Kube-State-Metrics, Prometheus-Adapter instalados e configurados de forma tranquila e com alta disponibilidade. Além disso, ele nos permite ter uma visão completa do nosso cluster de Kubernetes. Ele nos permite monitorar todos os componentes do nosso cluster de Kubernetes, como por exemplo: kube-scheduler, kube-controller-manager, kubelet, kube-proxy, etc.</p>
<h4 id="instalando-o-nosso-cluster-kubernetes"><a class="header" href="#instalando-o-nosso-cluster-kubernetes">Instalando o nosso cluster Kubernetes</a></h4>
<p>Como dissemos, para esse nosso exemplo iremos utilizar o cluster de Kubernetes da AWS, o EKS. Para instalar o nosso cluster EKS, iremos utilizar a ferramenta <a href="https://eksctl.io/">eksctl</a>, portanto precisamos instalá-la em nossa máquina. Para instalar a ferramenta, basta executar o seguinte comando:</p>
<pre><code class="language-bash">curl --silent --location &quot;https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz&quot; | tar xz -C /tmp
sudo mv /tmp/eksctl /usr/local/bin
</code></pre>
<p>Precisamos ter o CLI da aws instalado em nossa máquina, para isso, basta executar o seguinte comando:</p>
<pre><code class="language-bash">curl &quot;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip&quot; -o &quot;awscliv2.zip&quot;
unzip awscliv2.zip
sudo ./aws/install
</code></pre>
<p>Pronto, agora você já tem o <code>eksctl</code> e o <code>aws</code> instalados em sua máquina.</p>
<p>Para que possamos criar tudo o que precisamos na AWS, é importante que você tenha uma conta na AWS, e que tenha as credenciais de acesso configuradas em sua máquina. Para configurar as credenciais de acesso, basta executar o seguinte comando:</p>
<pre><code class="language-bash">aws configure
</code></pre>
<p>O comando acima irá solicitar que você informe a sua <code>AWS Access Key ID</code>, a sua <code>AWS Secret Access Key</code>, a sua <code>Default region name</code>, e o seu <code>Default output format</code>. Para saber mais sobre como configurar as credenciais de acesso, basta acessar a <a href="https://docs.aws.amazon.com/pt_br/cli/latest/userguide/cli-configure-quickstart.html">documentação oficial da AWS</a>.</p>
<p>No comando acima estamos baixando o binário do <code>eksctl</code> compactado e descompactando ele na pasta <code>/tmp</code>, e depois movendo o binário para a pasta <code>/usr/local/bin</code>.</p>
<p>Lembrando que estou instando em uma máquina Linux, caso que esteja utilizando uma máquina Mac ou Windows, basta acessar a página de releases do projeto e baixar a versão adequada para o seu sistema operacional.</p>
<p>E enquanto você faz a instalação, vale a pena mencionar que o <code>eksctl</code> é uma ferramenta criada pela WeaveWorks, empresa que criou o <a href="https://fluxcd.io/">Flux</a>, que é um projeto de GitOps para Kubernetes, além de ter o Weavenet, que é um CNI para Kubernetes, e o Weave Scope, que é uma ferramenta de visualização de clusters de Kubernetes e muito mais, recomendo que vocês dêem uma olhada nos projetos, é sensacional!</p>
<p>Bem, agora você já tem o <code>eksctl</code> instalado em sua máquina, então vamos criar o nosso cluster EKS! Para isso, basta executar o seguinte comando:</p>
<pre><code class="language-bash">eksctl create cluster --name=eks-cluster --version=1.24 --region=us-east-1 --nodegroup-name=eks-cluster-nodegroup --node-type=t3.medium --nodes=2 --nodes-min=1 --nodes-max=3 --managed
</code></pre>
<p>O comando acima irá criar um cluster EKS com o nome <code>eks-cluster</code>, na região <code>us-east-1</code>, com 2 nós do tipo <code>t3.medium</code>, e com um mínimo de 1 nó e um máximo de 3 nós. Além disso, o comando acima irá criar um nodegroup chamado <code>eks-cluster-nodegroup</code>. O <code>eksctl</code> irá cuidar de toda a infraestrutura necessária para o funcionamento do nosso cluster EKS. A versão do Kubernetes que será instalada no nosso cluster será a <code>1.24</code>.</p>
<p>Após a criação do nosso cluster EKS, precisamos instalar o <code>kubectl</code> em nossa máquina. Para instalar o <code>kubectl</code>, basta executar o seguinte comando:</p>
<pre><code class="language-bash">curl -LO &quot;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl&quot;
chmod +x ./kubectl
sudo mv ./kubectl /usr/local/bin/kubectl
</code></pre>
<p>O comando acima irá baixar o binário do <code>kubectl</code> e o colocar na pasta <code>/usr/local/bin</code>, e dar permissão de execução para o binário.</p>
<p>Agora que já temos o <code>kubectl</code> instalado em nossa máquina, precisamos configurar o <code>kubectl</code> para utilizar o nosso cluster EKS. Para isso, basta executar o seguinte comando:</p>
<pre><code class="language-bash">aws eks --region us-east-1 update-kubeconfig --name eks-cluster
</code></pre>
<p>Aonde <code>us-east-1</code> é a região do nosso cluster EKS, e <code>eks-cluster</code> é o nome do nosso cluster EKS. Esse comando é necessário para que o <code>kubectl</code> saiba qual cluster ele deve utilizar, ele irá pegar as credenciais do nosso cluster EKS e armazenar no arquivo <code>~/.kube/config</code>.</p>
<p><strong>LEMBRE-SE</strong>: Você não precisa ter o Kubernetes rodando no EKS, fique a vontade para escolher onde preferir para seguir o treinamento.</p>
<p>Vamos ver se o <code>kubectl</code> está funcionando corretamente? Para isso, basta executar o seguinte comando:</p>
<pre><code class="language-bash">kubectl get nodes
</code></pre>
<p>Se tudo estiver funcionando corretamente, você deverá ver uma lista com os nós do seu cluster EKS. :D</p>
<p>Antes de seguirmos em frente, vamos conhecer algums comandos do eksctl, para que possamos gerenciar o nosso cluster EKS. Para listar os clusters EKS que temos em nossa conta, basta executar o seguinte comando:</p>
<pre><code class="language-bash">eksctl get cluster -A
</code></pre>
<p>O parametro <code>-A</code> é para listar os clusters EKS de todas as regiões. Para listar os clusters EKS de uma região específica, basta executar o seguinte comando:</p>
<pre><code class="language-bash">eksctl get cluster -r us-east-1
</code></pre>
<p>Para aumentar o número de nós do nosso cluster EKS, basta executar o seguinte comando:</p>
<pre><code class="language-bash">eksctl scale nodegroup --cluster=eks-cluster --nodes=3 --nodes-min=1 --nodes-max=3 --name=eks-cluster-nodegroup -r us-east-1
</code></pre>
<p>Para diminuir o número de nós do nosso cluster EKS, basta executar o seguinte comando:</p>
<pre><code class="language-bash">eksctl scale nodegroup --cluster=eks-cluster --nodes=1 --nodes-min=1 --nodes-max=3 --name=eks-cluster-nodegroup -r us-east-1
</code></pre>
<p>Para deletar o nosso cluster EKS, basta executar o seguinte comando:</p>
<pre><code class="language-bash">eksctl delete cluster --name=eks-cluster -r us-east-1
</code></pre>
<p>Mas não delete o nosso cluster EKS, vamos utilizar ele para os próximos passos! hahahah</p>
<h4 id="instalando-o-kube-prometheus"><a class="header" href="#instalando-o-kube-prometheus">Instalando o Kube-Prometheus</a></h4>
<p>Agora que já temos o nosso cluster EKS criado, vamos instalar o Kube-Prometheus. Para isso, basta executar o seguinte comando:</p>
<pre><code class="language-bash">git clone https://github.com/prometheus-operator/kube-prometheus
cd kube-prometheus
kubectl create -f manifests/setup
</code></pre>
<p>Com o comando acima nós estamos clonando o repositório oficial do projeto, e aplicando os manifests necessários para a instalação do Kube-Prometheus. Após a execução do comando acima, você deverá ver uma mensagem parecida com a seguinte:</p>
<pre><code class="language-bash">customresourcedefinition.apiextensions.k8s.io/alertmanagerconfigs.monitoring.coreos.com created
customresourcedefinition.apiextensions.k8s.io/alertmanagers.monitoring.coreos.com created
customresourcedefinition.apiextensions.k8s.io/podmonitors.monitoring.coreos.com created
customresourcedefinition.apiextensions.k8s.io/probes.monitoring.coreos.com created
customresourcedefinition.apiextensions.k8s.io/prometheuses.monitoring.coreos.com created
customresourcedefinition.apiextensions.k8s.io/prometheusrules.monitoring.coreos.com created
customresourcedefinition.apiextensions.k8s.io/servicemonitors.monitoring.coreos.com created
customresourcedefinition.apiextensions.k8s.io/thanosrulers.monitoring.coreos.com created
namespace/monitoring created
</code></pre>
<p>Basicamente o que fizemos foi a instalação de alguns CRDs (Custom Resource Definitions) que são como extensões do Kubernetes, e que são utilizados pelo Kube-Prometheus e com isso o Kubernetes irá reconhecer esses novos recursos, como por exemplo o <code>PrometheusRule</code> e o <code>ServiceMonitor</code> que irei falar mais a frente.</p>
<p>O processo de instalação dos CRDs pode demorar alguns minutos, então vamos aguardar a instalação terminar. :D</p>
<p>Para verificar se a instalação dos CRDs foi concluída, o comando abaixo deverá funcionar,se ainda não funcionar, aguarde alguns minutos e tente novamente.</p>
<pre><code class="language-bash">kubectl get servicemonitors -A
</code></pre>
<p>Após a instalação dos CRDs, vamos instalar o Prometheus e o Alertmanager. Para isso, basta executar o seguinte comando:</p>
<pre><code class="language-bash">kubectl apply -f manifests/
</code></pre>
<p>Com o comando acima nós estamos aplicando os manifests necessários para a instalação do Prometheus e do Alertmanager. Após a execução do comando acima, você deverá ver uma mensagem parecida com a seguinte:</p>
<pre><code class="language-bash">alertmanager.monitoring.coreos.com/main created
networkpolicy.networking.k8s.io/alertmanager-main created
poddisruptionbudget.policy/alertmanager-main created
prometheusrule.monitoring.coreos.com/alertmanager-main-rules created
secret/alertmanager-main created
service/alertmanager-main created
serviceaccount/alertmanager-main created
servicemonitor.monitoring.coreos.com/alertmanager-main created
clusterrole.rbac.authorization.k8s.io/blackbox-exporter created
clusterrolebinding.rbac.authorization.k8s.io/blackbox-exporter created
configmap/blackbox-exporter-configuration created
deployment.apps/blackbox-exporter created
networkpolicy.networking.k8s.io/blackbox-exporter created
service/blackbox-exporter created
serviceaccount/blackbox-exporter created
servicemonitor.monitoring.coreos.com/blackbox-exporter created
secret/grafana-config created
secret/grafana-datasources created
configmap/grafana-dashboard-alertmanager-overview created
configmap/grafana-dashboard-apiserver created
configmap/grafana-dashboard-cluster-total created
configmap/grafana-dashboard-controller-manager created
configmap/grafana-dashboard-grafana-overview created
configmap/grafana-dashboard-k8s-resources-cluster created
configmap/grafana-dashboard-k8s-resources-namespace created
configmap/grafana-dashboard-k8s-resources-node created
configmap/grafana-dashboard-k8s-resources-pod created
configmap/grafana-dashboard-k8s-resources-workload created
configmap/grafana-dashboard-k8s-resources-workloads-namespace created
configmap/grafana-dashboard-kubelet created
configmap/grafana-dashboard-namespace-by-pod created
configmap/grafana-dashboard-namespace-by-workload created
configmap/grafana-dashboard-node-cluster-rsrc-use created
configmap/grafana-dashboard-node-rsrc-use created
configmap/grafana-dashboard-nodes-darwin created
configmap/grafana-dashboard-nodes created
configmap/grafana-dashboard-persistentvolumesusage created
configmap/grafana-dashboard-pod-total created
configmap/grafana-dashboard-prometheus-remote-write created
configmap/grafana-dashboard-prometheus created
configmap/grafana-dashboard-proxy created
configmap/grafana-dashboard-scheduler created
configmap/grafana-dashboard-workload-total created
configmap/grafana-dashboards created
deployment.apps/grafana created
networkpolicy.networking.k8s.io/grafana created
prometheusrule.monitoring.coreos.com/grafana-rules created
service/grafana created
serviceaccount/grafana created
servicemonitor.monitoring.coreos.com/grafana created
prometheusrule.monitoring.coreos.com/kube-prometheus-rules created
clusterrole.rbac.authorization.k8s.io/kube-state-metrics created
clusterrolebinding.rbac.authorization.k8s.io/kube-state-metrics created
deployment.apps/kube-state-metrics created
networkpolicy.networking.k8s.io/kube-state-metrics created
prometheusrule.monitoring.coreos.com/kube-state-metrics-rules created
service/kube-state-metrics created
serviceaccount/kube-state-metrics created
servicemonitor.monitoring.coreos.com/kube-state-metrics created
prometheusrule.monitoring.coreos.com/kubernetes-monitoring-rules created
servicemonitor.monitoring.coreos.com/kube-apiserver created
servicemonitor.monitoring.coreos.com/coredns created
servicemonitor.monitoring.coreos.com/kube-controller-manager created
servicemonitor.monitoring.coreos.com/kube-scheduler created
servicemonitor.monitoring.coreos.com/kubelet created
clusterrole.rbac.authorization.k8s.io/node-exporter created
clusterrolebinding.rbac.authorization.k8s.io/node-exporter created
daemonset.apps/node-exporter created
networkpolicy.networking.k8s.io/node-exporter created
prometheusrule.monitoring.coreos.com/node-exporter-rules created
service/node-exporter created
serviceaccount/node-exporter created
servicemonitor.monitoring.coreos.com/node-exporter created
clusterrole.rbac.authorization.k8s.io/prometheus-k8s created
clusterrolebinding.rbac.authorization.k8s.io/prometheus-k8s created
networkpolicy.networking.k8s.io/prometheus-k8s created
poddisruptionbudget.policy/prometheus-k8s created
prometheus.monitoring.coreos.com/k8s created
prometheusrule.monitoring.coreos.com/prometheus-k8s-prometheus-rules created
rolebinding.rbac.authorization.k8s.io/prometheus-k8s-config created
rolebinding.rbac.authorization.k8s.io/prometheus-k8s created
rolebinding.rbac.authorization.k8s.io/prometheus-k8s created
rolebinding.rbac.authorization.k8s.io/prometheus-k8s created
role.rbac.authorization.k8s.io/prometheus-k8s-config created
role.rbac.authorization.k8s.io/prometheus-k8s created
role.rbac.authorization.k8s.io/prometheus-k8s created
role.rbac.authorization.k8s.io/prometheus-k8s created
service/prometheus-k8s created
serviceaccount/prometheus-k8s created
servicemonitor.monitoring.coreos.com/prometheus-k8s created
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created
clusterrole.rbac.authorization.k8s.io/prometheus-adapter created
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
clusterrolebinding.rbac.authorization.k8s.io/prometheus-adapter created
clusterrolebinding.rbac.authorization.k8s.io/resource-metrics:system:auth-delegator created
clusterrole.rbac.authorization.k8s.io/resource-metrics-server-resources created
configmap/adapter-config created
deployment.apps/prometheus-adapter created
networkpolicy.networking.k8s.io/prometheus-adapter created
poddisruptionbudget.policy/prometheus-adapter created
rolebinding.rbac.authorization.k8s.io/resource-metrics-auth-reader created
service/prometheus-adapter created
serviceaccount/prometheus-adapter created
servicemonitor.monitoring.coreos.com/prometheus-adapter created
clusterrole.rbac.authorization.k8s.io/prometheus-operator created
clusterrolebinding.rbac.authorization.k8s.io/prometheus-operator created
deployment.apps/prometheus-operator created
networkpolicy.networking.k8s.io/prometheus-operator created
prometheusrule.monitoring.coreos.com/prometheus-operator-rules created
service/prometheus-operator created
serviceaccount/prometheus-operator created
servicemonitor.monitoring.coreos.com/prometheus-operator created
</code></pre>
<p>Com isso fizemos a instalação da Stack do nosso Kube-Prometheus, que é composta pelo Prometheus, pelo Alertmanager, Blackbox Exporter e Grafana. :D
Perceba que ele já está configurando um monte de outras coisas como os ConfigMaps, Secrets, ServiceAccounts, etc. </p>
<p>Para verificar se a instalação foi concluída, basta executar o seguinte comando:</p>
<pre><code class="language-bash">kubectl get pods -n monitoring
</code></pre>
<p>O resultado esperado é o seguinte:</p>
<pre><code class="language-bash">NAME                                  READY   STATUS    RESTARTS   AGE
alertmanager-main-0                   2/2     Running   0          57s
alertmanager-main-1                   2/2     Running   0          57s
alertmanager-main-2                   2/2     Running   0          57s
blackbox-exporter-cbb9c96b-t8z68      3/3     Running   0          94s
grafana-589787799d-pxsts              1/1     Running   0          80s
kube-state-metrics-557d857c5d-kt8dd   3/3     Running   0          78s
node-exporter-2n6sz                   2/2     Running   0          74s
node-exporter-mwq6b                   2/2     Running   0          74s
prometheus-adapter-758645c65b-54c7g   1/1     Running   0          64s
prometheus-adapter-758645c65b-cmjrv   1/1     Running   0          64s
prometheus-k8s-0                      2/2     Running   0          57s
prometheus-k8s-1                      2/2     Running   0          57s
prometheus-operator-c766b9756-vndp9   2/2     Running   0          63s
</code></pre>
<p>Pronto, já temos o Prometheus, Alertmanager, Blackbox Exporter, Node Exporter e Grafana instalados. :D
Nesse meu cluster, eu estou com dois nodes, por isso temos dois pods do Node Exporter e dois pods do Prometheus chamados de <code>prometheus-k8s-0</code> e <code>prometheus-k8s-1</code>.</p>
<h4 id="acessando-o-grafana"><a class="header" href="#acessando-o-grafana">Acessando o Grafana</a></h4>
<p>Agora que já temos o nosso Kube-Prometheus instalado, vamos acessar o nosso Grafana e verificar se está tudo funcionando corretamente. Para isso, vamos utilizar o <code>kubectl port-forward</code> para acessar o Grafana localmente. Para isso, basta executar o seguinte comando:</p>
<pre><code class="language-bash">kubectl port-forward -n monitoring svc/grafana 33000:3000
</code></pre>
<p>Agora que já temos o nosso Grafana rodando localmente, vamos acessar o nosso Grafana através do navegador. Para isso, basta acessar a seguinte URL: <code>http://localhost:33000</code>. Após acessar a URL, você deverá ver uma tela de login do Grafana, como na imagem abaixo:</p>
<p><img src="day-6/images/login-grafana.png" alt="Grafana Login" /></p>
<p>Para acessar o Grafana, vamos utilizar o usuário <code>admin</code> e a senha <code>admin</code>, e já no primeiro login ele irá pedir para você alterar a senha. Você já conhece o Grafana, não preciso mais apresenta-los, certo? :D</p>
<p><img src="day-6/images/muda-senha-grafana.png" alt="Grafana Senha Nova" /></p>
<p>O importante aqui é ver a quantidade de Dashboards criados pelo Kube-Prometheus. :D 
Temos Dashboards que mostram detalhes do API Server e de diversos componentes do Kubernetes, como Node, Pod, Deployment, etc.</p>
<p><img src="day-6/images/grafana-dashs.png" alt="Grafana Dashboards" /></p>
<p>Também temos Dashboards que mostram detalhes do nosso cluster EKS, como por exemplo o dashboard <code>Kubernetes / Compute Resources / Cluster</code>, que mostra detalhes de CPU e memória utilizados por todos os nós do nosso cluster EKS.</p>
<p><img src="day-6/images/grafana-cluster.png" alt="Grafana Clusters" /></p>
<p>Dashboards que mostram detalhes do nosso cluster EKS, como por exemplo o dashboard <code>Kubernetes / Compute Resources / Namespace (Pods)</code>, que mostra detalhes de CPU e memória utilizados por todos os pods de todos os namespaces do nosso cluster EKS.</p>
<p><img src="day-6/images/grafana-pods.png" alt="Grafana Dashboards" /></p>
<p>Ainda temos Dashboards que mostram detalhes do nosso cluster EKS, como por exemplo o dashboard <code>Kubernetes / Compute Resources / Namespace (Workloads)</code>, que mostra detalhes de CPU e memória utilizados por todos os deployments, statefulsets e daemonsets de todos os namespaces do nosso cluster EKS.</p>
<p><img src="day-6/images/grafana-workloads.png" alt="Grafana Dashboards" /></p>
<p>Também temos Dashboards que mostram detalhes do nosso cluster EKS, como por exemplo o dashboard <code>Kubernetes / Compute Resources / Node</code>, que mostra detalhes de CPU e memória utilizados por todos os nós do nosso cluster EKS.</p>
<p><img src="day-6/images/grafana-node.png" alt="Grafana Dashboards" /></p>
<p>Também temos Dashboards que mostram detalhes do nosso cluster EKS, como por exemplo o dashboard <code>Kubernetes / Compute Resources / Pod (Containers)</code>, que mostra detalhes de CPU e memória utilizados por todos os containers de todos os pods do nosso cluster EKS.</p>
<p><img src="day-6/images/grafana-pods-containers.png" alt="Grafana Dashboards" /></p>
<p>Eu não vou ficar aqui dando spoilers, vai lá você e confere a quantidade enorme de Dashboards que o Kube-Prometheus já vem com ele. \o/</p>
<h4 id="acessando-o-prometheus"><a class="header" href="#acessando-o-prometheus">Acessando o Prometheus</a></h4>
<p>Agora que já temos o nosso Kube-Prometheus instalado, vamos acessar o nosso Prometheus e verificar se está tudo funcionando corretamente. Para isso, vamos utilizar o <code>kubectl port-forward</code> para acessar o Prometheus localmente. Para isso, basta executar o seguinte comando:</p>
<pre><code class="language-bash">kubectl port-forward -n monitoring svc/prometheus-k8s 39090:9090
</code></pre>
<p>Pronto, agora já podemos fazer a mesma coisa que fizemos anteriormente para acessar o Grafana, a diferença aqui é que estamos utilizando uma porta diferente, a porta <code>39090</code> ao invés da porta <code>33000</code> que usamos para o Grafana.</p>
<p>Lembre-se que essa porta é local somente, a porta onde o serviço do Prometheus está rodando é a porta <code>9090</code>, e a do Grafana é a porta <code>3000</code>.</p>
<p><img src="day-6/images/prometheus.png" alt="Prometheus" /></p>
<h4 id="acessando-o-alertmanager"><a class="header" href="#acessando-o-alertmanager">Acessando o AlertManager</a></h4>
<p>Aqui basicamente repetimos o que fizemos para acessar o Prometheus, só que agora para acessar o AlertManager. Para isso, vamos utilizar o <code>kubectl port-forward</code> para acessar o AlertManager localmente. Para isso, basta executar o seguinte comando:</p>
<pre><code class="language-bash">kubectl port-forward -n monitoring svc/alertmanager-main 39093:9093
</code></pre>
<p>Pronto, agora você já pode acessar o seu serviço de forma simples e segura, sem precisar expor o serviço para o mundo externo. :D</p>
<p>E claro, caso você queira, fique a vontado para criar um ingress para o seu serviço, ou até mesmo um LoadBalancer, caso você esteja utilizando o AWS EKS. :D</p>
<p><img src="day-6/images/alertmanager.png" alt="AlertManager" /></p>
<h3 id="chega-por-hoje-2"><a class="header" href="#chega-por-hoje-2">Chega por hoje!</a></h3>
<p>Hoje foi o dia de ver o que é o kube-prometheus e como podemos instalar ele no nosso cluster Kubernetes. De quebra, vimos como criar um cluster EKS através do eksctl e como instalar o kube-prometheus no nosso cluster.</p>
<p>Vimos ainda como acessar o nosso Prometheus, AlertManager e Grafana. Vimos as diversas opções de dashboards disponíveis no Grafana.</p>
<p>Vimos o que é um ServiceMonitor e criamos o nosso primeiro, bem simples, mas somente como exemplo, afinal ainda vamos ver muita coisa sobre ele. :D</p>
<h3 id="lição-de-casa-2"><a class="header" href="#lição-de-casa-2">Lição de casa</a></h3>
<p>Você precisa ter o seu cluster criado e o nosso kube-prometheus instalado. :D
Eu não vou ficar pedindo muito hoje, somente que você tenha certeza que seu cluster e seu kube-prometheus estão funcionando corretamente, portanto, acesse as interfaces do Prometheus, AlertManager e Grafana e veja se tudo está tudo lindo! :D</p>
<p>Se divirta! #VAIIII</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="descomplicando-o-prometheus-5"><a class="header" href="#descomplicando-o-prometheus-5">Descomplicando o Prometheus</a></h1>
<h2 id="day-7"><a class="header" href="#day-7">DAY-7</a></h2>
<h3 id="o-que-iremos-ver-hoje-6"><a class="header" href="#o-que-iremos-ver-hoje-6">O que iremos ver hoje?</a></h3>
<p>Hoje o nosso objetivo é continuar avançando na utilização do Prometheus juntamente com o nosso cluster Kubernetes.</p>
<p>Já vimos como fazer a instalação do kube-prometheus, peça super importante nesse momento. Porém precisamos começar a explorar além de sua instalação, precisamos começar a entender como ele funciona e como nós podemos interagir com ele.</p>
<p>Agora já estamos prontos para começar a explorar um pouco mais o Prometheus e tudo que o Prometheus Operator pode nos oferecer.</p>
<p>Entre essa coisas que o Prometheus Operator pode nos oferecer, temos o ServiceMonitor e o PodMonitor. Vamos entender o que são esses recursos e como podemos utilizá-los, e claro, criar exemplos para que você entenda de uma maneira ainda mais prática.</p>
<p>E o que adianta a gente criar recursos para monitorar o nosso cluster se não temos nenhuma forma de ser notificado quando algo acontecer? Por isso, vamos criar alertas, e para isso precisamos conhecer mais um recurso mágico do Prometheus Operator, o PrometheusRule.</p>
<p>Enfim, sem mais spoilers, vamos começar a explorar o Prometheus, Kube-Prometheus e o Prometheus Operator.</p>
<h3 id="conteúdo-do-day-7"><a class="header" href="#conteúdo-do-day-7">Conteúdo do Day-7</a></h3>
<details>
<summary class="summary">DAY-7</summary>
<ul>
<li><a href="day-7/index.html#descomplicando-o-prometheus">Descomplicando o Prometheus</a>
<ul>
<li><a href="day-7/index.html#day-7">DAY-7</a>
<ul>
<li><a href="day-7/index.html#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="day-7/index.html#conte%C3%BAdo-do-day-7">Conteúdo do Day-7</a>
<ul>
<li><a href="day-7/index.html#os-servicemonitors">Os ServiceMonitors</a></li>
<li><a href="day-7/index.html#criando-um-servicemonitor">Criando um ServiceMonitor</a></li>
<li><a href="day-7/index.html#os-podmonitors">Os PodMonitors</a></li>
<li><a href="day-7/index.html#criando-um-podmonitor">Criando um PodMonitor</a></li>
<li><a href="day-7/index.html#criando-nosso-primeiro-alerta">Criando nosso primeiro alerta</a></li>
<li><a href="day-7/index.html#criando-um-novo-alerta">Criando um novo alerta</a></li>
<li><a href="day-7/index.html#o-que-%C3%A9-um-prometheusrule">O que é um PrometheusRule?</a>
<ul>
<li><a href="day-7/index.html#criando-um-prometheusrule">Criando um PrometheusRule</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="day-7/index.html#chega-por-hoje">Chega por hoje!</a></li>
<li><a href="day-7/index.html#li%C3%A7%C3%A3o-de-casa">Lição de casa</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</details>
<h4 id="os-servicemonitors"><a class="header" href="#os-servicemonitors">Os ServiceMonitors</a></h4>
<p>Um dos principais recursos que o Kube-Prometheus utiliza é o ServiceMonitor. O ServiceMonitor é um recurso do Prometheus Operator que permite que você configure o Prometheus para monitorar um serviço. Para isso, você precisa criar um ServiceMonitor para cada serviço que você deseja monitorar. </p>
<p>O ServiceMonitor define o conjunto de endpoints a serem monitorados pelo Prometheus e também fornece informações adicionais, como o caminho e a porta de um endpoint, além de permitir a definição de rótulos personalizados. Ele pode ser usado para monitorar os endpoints de um aplicativo ou de um serviço específico em um cluster Kubernetes.</p>
<p>Você consegue criar algumas regras com o objetivo de filtrar quais serão os targets que o Prometheus irá monitorar. Por exemplo, você pode criar uma regra para monitorar apenas os pods que estão com o label <code>app=nginx</code> ou ainda capturar as métricas somente de endpoints que estejam com alguma label que você definiu.</p>
<p>O Kube-Prometheus já vem com vários ServiceMonitors configurados, como por exemplo o ServiceMonitor do API Server, do Node Exporter, do Blackbox Exporter, etc.</p>
<pre><code class="language-bash">kubectl get servicemonitors -n monitoring
NAME                      AGE
alertmanager              17m
blackbox-exporter         17m
coredns                   17m
grafana                   17m
kube-apiserver            17m
kube-controller-manager   17m
kube-scheduler            17m
kube-state-metrics        17m
kubelet                   17m
node-exporter             17m
prometheus-adapter        17m
prometheus-k8s            17m
prometheus-operator       17m
</code></pre>
<p>Para ver o conteúdo de um ServiceMonitor, basta executar o seguinte comando:</p>
<pre><code class="language-bash">kubectl get servicemonitor prometheus-k8s -n monitoring -o yaml
</code></pre>
<p>Nesse caso estamos pegando o ServiceMonitor do Prometheus, mas você pode pegar o ServiceMonitor de qualquer outro serviço.</p>
<pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {&quot;apiVersion&quot;:&quot;monitoring.coreos.com/v1&quot;,&quot;kind&quot;:&quot;ServiceMonitor&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;labels&quot;:{&quot;app.kubernetes.io/component&quot;:&quot;prometheus&quot;,&quot;app.kubernetes.io/instance&quot;:&quot;k8s&quot;,&quot;app.kubernetes.io/name&quot;:&quot;prometheus&quot;,&quot;app.kubernetes.io/part-of&quot;:&quot;kube-prometheus&quot;,&quot;app.kubernetes.io/version&quot;:&quot;2.41.0&quot;},&quot;name&quot;:&quot;prometheus-k8s&quot;,&quot;namespace&quot;:&quot;monitoring&quot;},&quot;spec&quot;:{&quot;endpoints&quot;:[{&quot;interval&quot;:&quot;30s&quot;,&quot;port&quot;:&quot;web&quot;},{&quot;interval&quot;:&quot;30s&quot;,&quot;port&quot;:&quot;reloader-web&quot;}],&quot;selector&quot;:{&quot;matchLabels&quot;:{&quot;app.kubernetes.io/component&quot;:&quot;prometheus&quot;,&quot;app.kubernetes.io/instance&quot;:&quot;k8s&quot;,&quot;app.kubernetes.io/name&quot;:&quot;prometheus&quot;,&quot;app.kubernetes.io/part-of&quot;:&quot;kube-prometheus&quot;}}}}
  creationTimestamp: &quot;2023-01-23T19:08:26Z&quot;
  generation: 1
  labels:
    app.kubernetes.io/component: prometheus
    app.kubernetes.io/instance: k8s
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: kube-prometheus
    app.kubernetes.io/version: 2.41.0
  name: prometheus-k8s
  namespace: monitoring
  resourceVersion: &quot;4100&quot;
  uid: 6042e08c-cf18-4622-9860-3ff43e696f7c
spec:
  endpoints:
  - interval: 30s
    port: web
  - interval: 30s
    port: reloader-web
  selector:
    matchLabels:
      app.kubernetes.io/component: prometheus
      app.kubernetes.io/instance: k8s
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: kube-prometheus
</code></pre>
<p>Eu vou dar uma limpada nessa saída para ficar mais fácil de entender:</p>
<pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  annotations:
  labels:
    app.kubernetes.io/component: prometheus
    app.kubernetes.io/instance: k8s
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: kube-prometheus
    app.kubernetes.io/version: 2.41.0
  name: prometheus-k8s
  namespace: monitoring
spec:
  endpoints:
  - interval: 30s
    port: web
  - interval: 30s
    port: reloader-web
  selector:
    matchLabels:
      app.kubernetes.io/component: prometheus
      app.kubernetes.io/instance: k8s
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: kube-prometheus
</code></pre>
<p>Pronto, eu tirei algumas informações que não são importantes para a criação do ServiceMonitor, elas apenas trazer as informações do service monitor que foi criado e que pegamos a saída.</p>
<p>Com o arquivo limpo, podemos entender melhor o que está acontecendo.</p>
<ul>
<li><code>apiVersion</code>: Versão da API do Kubernetes que estamos utilizando.</li>
<li><code>kind</code>: Tipo de objeto que estamos criando.</li>
<li><code>metadata</code>: Informações sobre o objeto que estamos criando.</li>
<li><code>metadata.annotations</code>: Anotações que podemos adicionar ao nosso objeto.</li>
<li><code>metadata.labels</code>: Labels que podemos adicionar ao nosso objeto.</li>
<li><code>metadata.name</code>: Nome do nosso objeto.</li>
<li><code>metadata.namespace</code>: Namespace onde o nosso objeto será criado.</li>
<li><code>spec</code>: Especificações do nosso objeto.</li>
<li><code>spec.endpoints</code>: Endpoints que o nosso ServiceMonitor irá monitorar.</li>
<li><code>spec.endpoints.interval</code>: Intervalo de tempo que o Prometheus irá fazer a coleta de métricas.</li>
<li><code>spec.endpoints.port</code>: Porta que o Prometheus irá utilizar para coletar as métricas.</li>
<li><code>spec.selector</code>: Selector que o ServiceMonitor irá utilizar para encontrar os serviços que ele irá monitorar.</li>
</ul>
<p>Com isso, sabemos que o ServiceMonitor do Prometheus irá monitorar os serviços que possuem as labels <code>app.kubernetes.io/component: prometheus</code>, <code>app.kubernetes.io/instance: k8s</code>, <code>app.kubernetes.io/name: prometheus</code> e <code>app.kubernetes.io/part-of: kube-prometheus</code>, e que ele irá monitorar as portas <code>web</code> e <code>reloader-web</code> com um intervalo de 30 segundos. É fácil ou não é?</p>
<p>Então sempre que precisarmos criar um ServiceMonitor para monitorar algum serviço, basta criarmos um arquivo YAML com as informações que precisamos e aplicarmos em nosso cluster.</p>
<h4 id="criando-um-servicemonitor"><a class="header" href="#criando-um-servicemonitor">Criando um ServiceMonitor</a></h4>
<p>Bem, chegou a hora de criarmos o nosso primeiro ServiceMonitor, mas antes precisamos ter uma aplicação para monitorarmos. Para isso, vamos criar uma aplicação com Nginx e utilizar o exporter do Nginx para monitorarmos o nosso serviço.
Vamos criar ainda um outro pod para que possamos criar um teste de carga para a nossa aplicação, realizando assim uma carga de até 1000 requisições por segundo.</p>
<p>Antes de mais nada, precisamos criar um ConfigMap onde terá a configuração que queremos para o nosso Nginx. Nada demais, somente a criação do nosso ConfigMap com o arquivo de configuração do Nginx, onde vamos definir a rota <code>/nginx_status</code> para expor as métricas do Nginx, além de expor a rota <code>/metrics</code> para expor as métricas do Nginx Exporter.</p>
<p>Vamos criar o nosso ConfigMap com o seguinte arquivo YAML:</p>
<pre><code class="language-yaml">apiVersion: v1 # versão da API
kind: ConfigMap # tipo de recurso, no caso, um ConfigMap
metadata: # metadados do recurso
  name: nginx-config # nome do recurso
data: # dados do recurso
  nginx.conf: | # inicio da definição do arquivo de configuração do Nginx
    server {
      listen 80;
      location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
      }
      location /metrics {
        stub_status on;
        access_log off;
      }
    }
</code></pre>
<p>Agora vamos entender o que está acontecendo no nosso arquivo YAML.</p>
<ul>
<li><code>apiVersion</code>: Versão da API do Kubernetes que estamos utilizando.</li>
<li><code>kind</code>: Tipo de objeto que estamos criando.</li>
<li><code>metadata</code>: Informações sobre o objeto que estamos criando.</li>
<li><code>metadata.name</code>: Nome do nosso objeto.</li>
<li><code>data</code>: Dados que serão utilizados no nosso ConfigMap.</li>
<li><code>data.nginx.conf</code>: A configuração do Nginx.</li>
</ul>
<p>Vamos criar o nosso ConfigMap com o seguinte comando:</p>
<pre><code class="language-bash">kubectl apply -f nginx-config.yaml
</code></pre>
<p>Após o nosso ConfigMap ser criado, vamos verificar se o nosso ConfigMap está rodando:</p>
<pre><code class="language-bash">kubectl get configmaps
</code></pre>
<p>Para criar a nossa aplicação, vamos utilizar o seguinte arquivo YAML:</p>
<pre><code class="language-yaml">apiVersion: apps/v1 # versão da API
kind: Deployment # tipo de recurso, no caso, um Deployment
metadata: # metadados do recurso 
  name: nginx-server # nome do recurso
spec: # especificação do recurso
  selector: # seletor para identificar os pods que serão gerenciados pelo deployment
    matchLabels: # labels que identificam os pods que serão gerenciados pelo deployment
      app: nginx # label que identifica o app que será gerenciado pelo deployment
  replicas: 3 # quantidade de réplicas do deployment
  template: # template do deployment
    metadata: # metadados do template
      labels: # labels do template
        app: nginx # label que identifica o app
      annotations: # annotations do template
        prometheus.io/scrape: 'true' # habilita o scraping do Prometheus
        prometheus.io/port: '9113' # porta do target
    spec: # especificação do template
      containers: # containers do template 
        - name: nginx # nome do container
          image: nginx # imagem do container do Nginx
          ports: # portas do container
            - containerPort: 80 # porta do container
              name: http # nome da porta
          volumeMounts: # volumes que serão montados no container
            - name: nginx-config # nome do volume
              mountPath: /etc/nginx/conf.d/default.conf # caminho de montagem do volume
              subPath: nginx.conf # subpath do volume
        - name: nginx-exporter # nome do container que será o exporter
          image: 'nginx/nginx-prometheus-exporter:0.11.0' # imagem do container do exporter
          args: # argumentos do container
            - '-nginx.scrape-uri=http://localhost/metrics' # argumento para definir a URI de scraping
          resources: # recursos do container
            limits: # limites de recursos
              memory: 128Mi # limite de memória
              cpu: 0.3 # limite de CPU
          ports: # portas do container
            - containerPort: 9113 # porta do container que será exposta
              name: metrics # nome da porta
      volumes: # volumes do template
        - configMap: # configmap do volume, nós iremos criar esse volume através de um configmap
            defaultMode: 420 # modo padrão do volume
            name: nginx-config # nome do configmap
          name: nginx-config # nome do volume
</code></pre>
<p>Agora vamos entender o que está acontecendo no nosso arquivo YAML.</p>
<ul>
<li><code>apiVersion</code>: Versão da API do Kubernetes que estamos utilizando.</li>
<li><code>kind</code>: Tipo de objeto que estamos criando.</li>
<li><code>metadata</code>: Informações sobre o objeto que estamos criando.</li>
<li><code>metadata.name</code>: Nome do nosso objeto.</li>
<li><code>spec</code>: Especificações do nosso objeto.</li>
<li><code>spec.selector</code>: Selector que o ServiceMonitor irá utilizar para encontrar os serviços que ele irá monitorar.</li>
<li><code>spec.selector.matchLabels</code>: Labels que o ServiceMonitor irá utilizar para encontrar os serviços que ele irá monitorar.</li>
<li><code>spec.selector.matchLabels.app</code>: Label que o ServiceMonitor irá utilizar para encontrar os serviços que ele irá monitorar.</li>
<li><code>spec.replicas</code>: Quantidade de réplicas que o nosso Deployment irá criar.</li>
<li><code>spec.template</code>: Template que o nosso Deployment irá utilizar para criar os pods.</li>
<li><code>spec.template.metadata</code>: Informações sobre o nosso pod.</li>
<li><code>spec.template.metadata.labels</code>: Labels que serão adicionadas ao nosso pod.</li>
<li><code>spec.template.metadata.labels.app</code>: Label que será adicionada ao nosso pod.</li>
<li><code>spec.template.metadata.annotations</code>: Annotations que serão adicionadas ao nosso pod.</li>
<li><code>spec.template.metadata.annotations.prometheus.io/scrape</code>: Annotation que será adicionada ao nosso pod.</li>
<li><code>spec.template.metadata.annotations.prometheus.io/port</code>: Annotation que será adicionada ao nosso pod.</li>
<li><code>spec.template.spec</code>: Especificações do nosso pod.</li>
<li><code>spec.template.spec.containers</code>: Containers que serão criados no nosso pod.</li>
<li><code>spec.template.spec.containers.name</code>: Nome do nosso container.</li>
<li><code>spec.template.spec.containers.image</code>: Imagem que será utilizada no nosso container.</li>
<li><code>spec.template.spec.containers.ports</code>: Portas que serão expostas no nosso container.</li>
<li><code>spec.template.spec.containers.ports.containerPort</code>: Porta que será exposta no nosso container.</li>
<li><code>spec.template.spec.containers.volumeMounts</code>: Volumes que serão montados no nosso container.</li>
<li><code>spec.template.spec.containers.volumeMounts.name</code>: Nome do volume que será montado no nosso container.</li>
<li><code>spec.template.spec.containers.volumeMounts.mountPath</code>: Caminho que o volume será montado no nosso container.</li>
<li><code>spec.template.spec.containers.volumeMounts.subPath.nginx.conf</code>: Subpath que o volume será montado no nosso container.</li>
<li><code>spec.template.spec.volumes</code>: Volumes que serão criados no nosso pod.</li>
<li><code>spec.template.spec.volumes.configMap</code>: ConfigMap que será utilizado no nosso volume.</li>
<li><code>spec.template.spec.volumes.configMap.defaultMode</code>: Modo de permissão que o volume será criado.</li>
<li><code>spec.template.spec.volumes.configMap.name</code>: Nome do ConfigMap que será utilizado no nosso volume.</li>
<li><code>spec.template.spec.volumes.name</code>: Nome do nosso volume.</li>
</ul>
<p>Agora que já sabemos o que está acontecendo no nosso arquivo YAML, vamos criar o nosso Deployment com o seguinte comando:</p>
<pre><code class="language-bash">kubectl apply -f nginx-deployment.yaml
</code></pre>
<p>Após o nosso Deployment ser criado, vamos verificar se o nosso pod está rodando:</p>
<pre><code class="language-bash">kubectl get pods
</code></pre>
<p>Podemos ver o deployment que acabamos de criar através do comando:</p>
<pre><code class="language-bash">kubectl get deployments
</code></pre>
<p>Agora o que precisamos é criar um Service para expor o nosso deployment. Vamos criar o nosso Service com o seguinte arquivo YAML:</p>
<pre><code class="language-yaml">apiVersion: v1 # versão da API
kind: Service # tipo de recurso, no caso, um Service
metadata: # metadados do recurso
  name: nginx-svc # nome do recurso
  labels: # labels do recurso
    app: nginx # label para identificar o svc
spec: # especificação do recurso
  ports: # definição da porta do svc 
  - port: 9113 # porta do svc
    name: metrics # nome da porta
  selector: # seletor para identificar os pods/deployment que esse svc irá expor
    app: nginx # label que identifica o pod/deployment que será exposto
</code></pre>
<p>Agora vamos entender o que está acontecendo no nosso arquivo YAML.</p>
<ul>
<li><code>apiVersion</code>: Versão da API do Kubernetes que estamos utilizando.</li>
<li><code>kind</code>: Tipo de objeto que estamos criando.</li>
<li><code>metadata</code>: Informações sobre o objeto que estamos criando.</li>
<li><code>metadata.name</code>: Nome do nosso objeto.</li>
<li><code>spec</code>: Especificações do nosso objeto.</li>
<li><code>spec.selector</code>: Selector que o Service irá utilizar para encontrar os pods que ele irá expor.</li>
<li><code>spec.selector.app</code>: Label que o Service irá utilizar para encontrar os pods que ele irá expor.</li>
<li><code>spec.ports</code>: Configurações das portas que serão expostas no nosso Service.</li>
<li><code>spec.ports.protocol</code>: Protocolo que será utilizado na porta que será exposta.</li>
<li><code>spec.ports.port</code>: Porta que será exposta no nosso Service.</li>
<li><code>spec.ports.name</code>: Nome da porta que será exposta no nosso Service.</li>
</ul>
<p>Vamos criar o Service com o seguinte comando:</p>
<pre><code class="language-bash">kubectl apply -f nginx-service.yaml
</code></pre>
<p>Após o nosso Service ser criado, vamos verificar se o nosso Service está rodando:</p>
<pre><code class="language-bash">kubectl get services
</code></pre>
<p>Pronto, tudo criado! </p>
<p>Acho que já temos tudo criado, agora vamos verificar se o nosso Nginx está rodando e se as métricas estão sendo expostas.</p>
<p>Vamos verificar se o nosso Nginx está rodando com o seguinte comando:</p>
<pre><code class="language-bash">curl http://&lt;EXTERNAL-IP-DO-SERVICE&gt;:80
</code></pre>
<p>Vamos verificar se as métricas do Nginx estão sendo expostas com o seguinte comando:</p>
<pre><code class="language-bash">curl http://&lt;EXTERNAL-IP-DO-SERVICE&gt;:80/nginx_status
</code></pre>
<p>Vamos verificar se as métricas do Nginx Exporter estão sendo expostas com o seguinte comando:</p>
<pre><code class="language-bash">curl http://&lt;EXTERNAL-IP-DO-SERVICE&gt;:80/metrics
</code></pre>
<p>Ótimo, agora você já sabe como que faz para criar um Service no Kubernetes e expor as métricas do Nginx e do Nginx Exporter. :D</p>
<p>Mais ainda não acabou, vamos criar um ServiceMonitor para o nosso Service, para que o Prometheus consiga capturar as métricas do Nginx e do Nginx Exporter.</p>
<p>Vamos criar o nosso ServiceMonitor com o seguinte arquivo YAML:</p>
<pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1 # versão da API
kind: ServiceMonitor # tipo de recurso, no caso, um ServiceMonitor do Prometheus Operator
metadata: # metadados do recurso
  name: nginx-servicemonitor # nome do recurso
  labels: # labels do recurso
    app: nginx # label que identifica o app
spec: # especificação do recurso
  selector: # seletor para identificar os pods que serão monitorados
    matchLabels: # labels que identificam os pods que serão monitorados
      app: nginx # label que identifica o app que será monitorado
  endpoints: # endpoints que serão monitorados
    - interval: 10s # intervalo de tempo entre as requisições
      path: /metrics # caminho para a requisição
      targetPort: 9113 # porta do target
</code></pre>
<p>Agora vamos entender o que está acontecendo no nosso arquivo YAML.</p>
<ul>
<li><code>apiVersion</code>: Versão da API do Kubernetes que estamos utilizando.</li>
<li><code>kind</code>: Tipo de objeto que estamos criando, no nosso caso, um ServiceMonitor.</li>
<li><code>metadata</code>: Informações sobre o objeto que estamos criando.</li>
<li><code>metadata.name</code>: Nome do nosso objeto.</li>
<li><code>metadata.labels</code>: Labels que serão utilizadas para identificar o nosso objeto.</li>
<li><code>spec</code>: Especificações do nosso objeto.</li>
<li><code>spec.selector</code>: Seletor que será utilizado para identificar o nosso Service.</li>
<li><code>spec.selector.matchLabels</code>: Labels que serão utilizadas para identificar o nosso Service, no nosso caso, o Service que tem a label <code>app: nginx</code>.</li>
<li><code>spec.endpoints</code>: Endpoints que serão monitorados pelo Prometheus.</li>
<li><code>spec.endpoints.interval</code>: Intervalo de tempo que o Prometheus irá capturar as métricas, no nosso caso, 15 segundos.</li>
<li><code>spec.endpoints.path</code>: Caminho que o Prometheus irá fazer a requisição para capturar as métricas, no nosso caso, <code>/metrics</code>.</li>
<li><code>spec.endpoints.targetPort</code>: Porta que o Prometheus irá fazer a requisição para capturar as métricas, no nosso caso, <code>9113</code>.</li>
</ul>
<p>Vamos criar o nosso ServiceMonitor com o seguinte comando:</p>
<pre><code class="language-bash">kubectl apply -f nginx-service-monitor.yaml
</code></pre>
<p>Após o nosso ServiceMonitor ser criado, vamos verificar se o nosso ServiceMonitor está rodando:</p>
<pre><code class="language-bash">kubectl get servicemonitors
</code></pre>
<p>Maravilha! Agora que já temos o nosso Nginx rodando e as métricas sendo expostas, vamos verificar se o Prometheus está capturando as métricas do Nginx e do Nginx Exporter.</p>
<p>Vamos fazer o port-forward do Prometheus para acessar o Prometheus localmente:</p>
<pre><code class="language-bash">kubectl port-forward -n monitoring svc/prometheus-k8s 39090:9090
</code></pre>
<p>E agora vamos usar o curl para verificar se o Prometheus está capturando as métricas do Nginx e do Nginx Exporter:</p>
<pre><code class="language-bash">curl http://localhost:39090/api/v1/targets
</code></pre>
<p>Pronto, agora você já sabe como que faz para criar um Service no Kubernetes, expor as métricas do Nginx e do Nginx Exporter e ainda criar um ServiceMonitor para o seu Service ficar monitorado pelo Prometheus. \o/</p>
<p>É muito importante que você saiba que o Prometheus não captura as métricas automaticamente, ele precisa de um ServiceMonitor para capturar as métricas. :D</p>
<h4 id="os-podmonitors"><a class="header" href="#os-podmonitors">Os PodMonitors</a></h4>
<p>E quando o nosso workload não é um Service? E quando o nosso workload é um Pod? Como que faz para monitorar o Pod? 
Tem situações que não temos um service na frente de nossos pods, por exemplo, quando temos CronJobs, Jobs, DaemonSets, etc. Eu já vi situações onde o pessoal estavam utilizando o PodMonitor para monitorar pods não HTTP, por exemplo, pods que expõem métricas do RabbitMQ, do Redis, Kafka, etc.</p>
<h4 id="criando-um-podmonitor"><a class="header" href="#criando-um-podmonitor">Criando um PodMonitor</a></h4>
<p>Para criar um PodMonitor, quase não teremos muitas mudanças do que aprendemos para criar um ServiceMonitor. Vamos criar o nosso PodMonitor com o seguinte arquivo YAML chamado <code>nginx-pod-monitor.yaml</code>:</p>
<pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1 # versão da API
kind: PodMonitor # tipo de recurso, no caso, um PodMonitor do Prometheus Operator
metadata: # metadados do recurso
  name: nginx-podmonitor # nome do recurso
  labels: # labels do recurso
    app: nginx-pod # label que identifica o app
spec:
  namespaceSelector: # seletor de namespaces
    matchNames: # namespaces que serão monitorados
      - default # namespace que será monitorado
  selector: # seletor para identificar os pods que serão monitorados
    matchLabels: # labels que identificam os pods que serão monitorados
      app: nginx-pod # label que identifica o app que será monitorado
  podMetricsEndpoints: # endpoints que serão monitorados
    - interval: 10s # intervalo de tempo entre as requisições
      path: /metrics # caminho para a requisição
      targetPort: 9113 # porta do target
</code></pre>
<p>Veja que usamos quase que as mesmas opções do ServiceMonitor, a única diferença é que usamos o <code>podMetricsEndpoints</code> para definir os endpoints que serão monitorados.
Outra novidade para nós é o <code>namespaceSelector</code>, que é utilizado para selecionar os namespaces que serão monitorados. No nosso caso, estamos monitorando o namespace <code>default</code>, onde estará em execução o nosso Pod do Nginx.</p>
<p>Antes de deployar o nosso PodMonitor, vamos criar o nosso Pod do Nginx com o seguinte arquivo YAML chamado <code>nginx-pod.yaml</code>:</p>
<pre><code class="language-yaml">apiVersion: v1 # versão da API
kind: Pod # tipo de recurso, no caso, um Pod
metadata: # metadados do recurso
  name: nginx-pod # nome do recurso
  labels: # labels do recurso
    app: nginx-pod # label que identifica o app
spec: # especificações do recursos
  containers: # containers do template 
    - name: nginx-container # nome do container
      image: nginx # imagem do container do Nginx
      ports: # portas do container
        - containerPort: 80 # porta do container
          name: http # nome da porta
      volumeMounts: # volumes que serão montados no container
        - name: nginx-config # nome do volume
          mountPath: /etc/nginx/conf.d/default.conf # caminho de montagem do volume
          subPath: nginx.conf # subpath do volume
    - name: nginx-exporter # nome do container que será o exporter
      image: 'nginx/nginx-prometheus-exporter:0.11.0' # imagem do container do exporter
      args: # argumentos do container
        - '-nginx.scrape-uri=http://localhost/metrics' # argumento para definir a URI de scraping
      resources: # recursos do container
        limits: # limites de recursos
          memory: 128Mi # limite de memória
          cpu: 0.3 # limite de CPU
      ports: # portas do container
        - containerPort: 9113 # porta do container que será exposta
          name: metrics # nome da porta
  volumes: # volumes do template
    - configMap: # configmap do volume, nós iremos criar esse volume através de um configmap
        defaultMode: 420 # modo padrão do volume
        name: nginx-config # nome do configmap
      name: nginx-config # nome do volume
</code></pre>
<p>Pronto, com o nosso Pod criado, vamos criar o nosso PodMonitor utilizando o arquivo YAML chamado <code>nginx-pod-monitor.yaml</code>, que criamos anteriormente:</p>
<pre><code class="language-bash">kubectl apply -f nginx-pod-monitor.yaml
</code></pre>
<p>Vamos verificar os PodMonitors que estão criados em nosso cluster:</p>
<pre><code class="language-bash">kubectl get podmonitors
</code></pre>
<p>Caso você queira ver os PodMonitors em detalhes, basta executar o seguinte comando:</p>
<pre><code class="language-bash">kubectl describe podmonitors nginx-podmonitor
</code></pre>
<p>E claro, você pode fazer o mesmo com o ServiceMonitor, basta executar o seguinte comando:</p>
<pre><code class="language-bash">kubectl describe servicemonitors nginx-servicemonitor
</code></pre>
<p>Vamos ver a saida do describe para o nosso PodMonitor:</p>
<pre><code class="language-bash">Name:         nginx-podmonitor
Namespace:    default
Labels:       app=nginx
Annotations:  &lt;none&gt;
API Version:  monitoring.coreos.com/v1
Kind:         PodMonitor
Metadata:
  Creation Timestamp:  2023-03-01T17:17:13Z
  Generation:          1
  Managed Fields:
    API Version:  monitoring.coreos.com/v1
    Fields Type:  FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .:
          f:kubectl.kubernetes.io/last-applied-configuration:
        f:labels:
          .:
          f:app:
      f:spec:
        .:
        f:namespaceSelector:
          .:
          f:matchNames:
        f:podMetricsEndpoints:
        f:selector:
    Manager:         kubectl-client-side-apply
    Operation:       Update
    Time:            2023-03-01T17:17:13Z
  Resource Version:  9473
  UID:               8c1bb91c-7285-4184-90e7-dcffcb143b92
Spec:
  Namespace Selector:
    Match Names:
      default
  Pod Metrics Endpoints:
    Interval:  10s
    Path:      /metrics
    Port:      9113
  Selector:
    Match Labels:
      App:  nginx
Events:     &lt;none&gt;
</code></pre>
<p>Como podemos ver, o nosso PodMonitor foi criado com sucesso. :D</p>
<p>Agora vamos ver se ele está aparecendo como um target no Prometheus. Para isso, vamos acessar o Prometheus localmente através do <code>kubectl port-forward</code>:</p>
<pre><code class="language-bash">kubectl port-forward -n monitoring svc/prometheus-k8s 39090:9090
</code></pre>
<p>Pronto, corre lá conferir o seu mais novo target e as métricas que estão sendo coletadas. :D</p>
<p>Uma coisa que vale a pena lembrar, é que você pode acessar o container com o <code>kubectl exec</code> e verificar se o seu exporter está funcionando corretamente ou somente para conferir quais são as métricas que ele está expondo para o Prometheus. Para isso, basta executar o seguinte comando:</p>
<pre><code class="language-bash">kubectl exec -it nginx-pod -c nginx-exporter -- bash
</code></pre>
<p>Agora vamos utilizar o <code>curl</code> para verificar se o nosso exporter está funcionando corretamente:</p>
<pre><code class="language-bash">curl localhost:9113/metrics
</code></pre>
<p>Se tudo está funcionando corretamente, você deve ver uma saída parecida com a seguinte:</p>
<pre><code class="language-bash"># HELP nginx_connections_accepted Accepted client connections
# TYPE nginx_connections_accepted counter
nginx_connections_accepted 1
# HELP nginx_connections_active Active client connections
# TYPE nginx_connections_active gauge
nginx_connections_active 1
# HELP nginx_connections_handled Handled client connections
# TYPE nginx_connections_handled counter
nginx_connections_handled 1
# HELP nginx_connections_reading Connections where NGINX is reading the request header
# TYPE nginx_connections_reading gauge
nginx_connections_reading 0
# HELP nginx_connections_waiting Idle client connections
# TYPE nginx_connections_waiting gauge
nginx_connections_waiting 0
# HELP nginx_connections_writing Connections where NGINX is writing the response back to the client
# TYPE nginx_connections_writing gauge
nginx_connections_writing 1
# HELP nginx_http_requests_total Total http requests
# TYPE nginx_http_requests_total counter
nginx_http_requests_total 61
# HELP nginx_up Status of the last metric scrape
# TYPE nginx_up gauge
nginx_up 1
# HELP nginxexporter_build_info Exporter build information
# TYPE nginxexporter_build_info gauge
nginxexporter_build_info{arch=&quot;linux/amd64&quot;,commit=&quot;e4a6810d4f0b776f7fde37fea1d84e4c7284b72a&quot;,date=&quot;2022-09-07T21:09:51Z&quot;,dirty=&quot;false&quot;,go=&quot;go1.19&quot;,version=&quot;0.11.0&quot;} 1
</code></pre>
<p>Lembrando que você pode consultar todas essas métricas lá no seu Prometheus. :D</p>
<p>Bora mudar um pouco de assunto? Vamos falar sobre alertas! :D</p>
<h4 id="criando-nosso-primeiro-alerta"><a class="header" href="#criando-nosso-primeiro-alerta">Criando nosso primeiro alerta</a></h4>
<p>Agora que já temos o nosso Kube-Prometheus instalado, vamos configurar o Prometheus para monitorar o nosso cluster EKS. Para isso, vamos utilizar o <code>kubectl port-forward</code> para acessar o Prometheus localmente. Para isso, basta executar o seguinte comando:</p>
<pre><code class="language-bash">kubectl port-forward -n monitoring svc/prometheus-k8s 39090:9090
</code></pre>
<p>Se você quiser acessar o Alertmanager, basta executar o seguinte comando:</p>
<pre><code class="language-bash">kubectl port-forward -n monitoring svc/alertmanager-main 39093:9093
</code></pre>
<p>Pronto, agora você já sabe como que faz para acessar o Prometheus, AlertManager e o Grafana localmente. :D</p>
<p>Lembrando que você pode acessar o Prometheus e o AlertManager através do seu navegador, basta acessar as seguintes URLs:</p>
<ul>
<li>Prometheus: <code>http://localhost:39090</code></li>
<li>AlertManager: <code>http://localhost:39093</code></li>
</ul>
<p>Simples assim!</p>
<p>Evidentemente, você pode expor esses serviços para a internet ou para um VPC privado, mas isso é assunto para você discutir com seu time.</p>
<p>Antes sair definindo um novo alerta, precisamos entender como faze-lo, uma vez que nós não temos mais o arquivo de alertas, igual tínhamos quando instalamos o Prometheus em nosso servidor Linux.</p>
<p>Agora, precisamos entender que boa parte da configuração do Prometheus está dentro de configmaps, que são recursos do Kubernetes que armazenam dados em formato de chave e valor e são muito utilizados para armazenar configurações de aplicações.</p>
<p>Para listar os configmaps do nosso cluster, basta executar o seguinte comando:</p>
<pre><code class="language-bash">kubectl get configmaps -n monitoring
</code></pre>
<p>O resultado do comando acima deverá ser parecido com o seguinte:</p>
<pre><code class="language-bash">NAME                                                  DATA   AGE
adapter-config                                        1      7m20s
blackbox-exporter-configuration                       1      7m49s
grafana-dashboard-alertmanager-overview               1      7m46s
grafana-dashboard-apiserver                           1      7m46s
grafana-dashboard-cluster-total                       1      7m46s
grafana-dashboard-controller-manager                  1      7m45s
grafana-dashboard-grafana-overview                    1      7m44s
grafana-dashboard-k8s-resources-cluster               1      7m44s
grafana-dashboard-k8s-resources-namespace             1      7m44s
grafana-dashboard-k8s-resources-node                  1      7m43s
grafana-dashboard-k8s-resources-pod                   1      7m42s
grafana-dashboard-k8s-resources-workload              1      7m42s
grafana-dashboard-k8s-resources-workloads-namespace   1      7m41s
grafana-dashboard-kubelet                             1      7m41s
grafana-dashboard-namespace-by-pod                    1      7m41s
grafana-dashboard-namespace-by-workload               1      7m40s
grafana-dashboard-node-cluster-rsrc-use               1      7m40s
grafana-dashboard-node-rsrc-use                       1      7m39s
grafana-dashboard-nodes                               1      7m39s
grafana-dashboard-nodes-darwin                        1      7m39s
grafana-dashboard-persistentvolumesusage              1      7m38s
grafana-dashboard-pod-total                           1      7m38s
grafana-dashboard-prometheus                          1      7m37s
grafana-dashboard-prometheus-remote-write             1      7m37s
grafana-dashboard-proxy                               1      7m37s
grafana-dashboard-scheduler                           1      7m36s
grafana-dashboard-workload-total                      1      7m36s
grafana-dashboards                                    1      7m35s
kube-root-ca.crt                                      1      11m
prometheus-k8s-rulefiles-0                            8      7m10s
</code></pre>
<p>Como você pode ver, temos diversos configmaps que contém configurações do Prometheus, AlertManager e do Grafana. Vamos focar no configmap <code>prometheus-k8s-rulefiles-0</code>, que é o configmap que contém os alertas do Prometheus.</p>
<p>Para visualizar o conteúdo do configmap, basta executar o seguinte comando:</p>
<pre><code class="language-bash">kubectl get configmap prometheus-k8s-rulefiles-0 -n monitoring -o yaml
</code></pre>
<p>Eu não vou colar a saída inteira aqui porque ela é enorme, mas vou colar um pedaço com um exemplo de alerta:</p>
<pre><code class="language-yaml">- alert: KubeMemoryOvercommit
    annotations:
        description: Cluster has overcommitted memory resource requests for Pods by
        {{ $value | humanize }} bytes and cannot tolerate node failure.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubememoryovercommit
        summary: Cluster has overcommitted memory resource requests.
    expr: |
        sum(namespace_memory:kube_pod_container_resource_requests:sum{}) - (sum(kube_node_status_allocatable{resource=&quot;memory&quot;}) - max(kube_node_status_allocatable{resource=&quot;memory&quot;})) &gt; 0
        and
        (sum(kube_node_status_allocatable{resource=&quot;memory&quot;}) - max(kube_node_status_allocatable{resource=&quot;memory&quot;})) &gt; 0
    for: 10m
    labels:
        severity: warning
</code></pre>
<p>Como você pode ver, o alerta acima é chamado de <code>KubeMemoryOvercommit</code> e ele é disparado quando o cluster tem mais memória alocada para os pods do que a memória disponível nos nós. A sua definição é a mesma que usamos quando criamos o arquivo de alertas no nosso servidor Linux.</p>
<h4 id="criando-um-novo-alerta"><a class="header" href="#criando-um-novo-alerta">Criando um novo alerta</a></h4>
<p>Muito bom, já sabemos que temos algumas regras já definidas, e que elas estão dentro de um configmap. Agora, vamos criar um novo alerta para monitorar o nosso Nginx.</p>
<p>Mas antes, precisamos entender o que é um recurso chamado PrometheusRule.</p>
<h4 id="o-que-é-um-prometheusrule"><a class="header" href="#o-que-é-um-prometheusrule">O que é um PrometheusRule?</a></h4>
<p>O PrometheusRule é um recurso do Kubernetes que foi instalado no momento que realizamos a instalação dos CRDs do kube-prometheus. O PrometheusRule permite que você defina alertas para o Prometheus. Ele é muito parecido com o arquivo de alertas que criamos no nosso servidor Linux, porém nesse momento vamos fazer a mesma definição de alerta, mas usando o PrometheusRule.</p>
<h5 id="criando-um-prometheusrule"><a class="header" href="#criando-um-prometheusrule">Criando um PrometheusRule</a></h5>
<p>Vamos criar um arquivo chamado <code>nginx-prometheus-rule.yaml</code> e vamos colocar o seguinte conteúdo:</p>
<pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1 # Versão da api do PrometheusRule
kind: PrometheusRule # Tipo do recurso
metadata: # Metadados do recurso (nome, namespace, labels)
  name: nginx-prometheus-rule
  namespace: monitoring
  labels: # Labels do recurso
    prometheus: k8s # Label que indica que o PrometheusRule será utilizado pelo Prometheus do Kubernetes
    role: alert-rules # Label que indica que o PrometheusRule contém regras de alerta
    app.kubernetes.io/name: kube-prometheus # Label que indica que o PrometheusRule faz parte do kube-prometheus
    app.kubernetes.io/part-of: kube-prometheus # Label que indica que o PrometheusRule faz parte do kube-prometheus
spec: # Especificação do recurso
  groups: # Lista de grupos de regras
  - name: nginx-prometheus-rule # Nome do grupo de regras
    rules: # Lista de regras
    - alert: NginxDown # Nome do alerta
      expr: up{job=&quot;nginx&quot;} == 0 # Expressão que será utilizada para disparar o alerta
      for: 1m # Tempo que a expressão deve ser verdadeira para que o alerta seja disparado
      labels: # Labels do alerta
        severity: critical # Label que indica a severidade do alerta
      annotations: # Anotações do alerta
        summary: &quot;Nginx is down&quot; # Título do alerta
        description: &quot;Nginx is down for more than 1 minute. Pod name: {{ $labels.pod }}&quot; # Descrição do alerta
</code></pre>
<p>Agora, vamos criar o PrometheusRule no nosso cluster:</p>
<pre><code class="language-bash">kubectl apply -f nginx-prometheus-rule.yaml
</code></pre>
<p>Agora, vamos verificar se o PrometheusRule foi criado com sucesso:</p>
<pre><code class="language-bash">kubectl get prometheusrules -n monitoring
</code></pre>
<p>A saída deve ser parecida com essa:</p>
<pre><code class="language-bash">NAME                              AGE
alertmanager-main-rules           92m
grafana-rules                     92m
kube-prometheus-rules             92m
kube-state-metrics-rules          92m
kubernetes-monitoring-rules       92m
nginx-prometheus-rule             20s
node-exporter-rules               91m
prometheus-k8s-prometheus-rules   91m
prometheus-operator-rules         91m
</code></pre>
<p>Agora nós já temos um novo alerta configurado em nosso Prometheus. Lembrando que temos a integração com o AlertManager, então, quando o alerta for disparado, ele será enviado para o AlertManager e o AlertManager vai enviar uma notificação, por exemplo, para o nosso Slack ou e-mail.</p>
<p>Você pode acessar o nosso alerta tanto no Prometheus quanto no AlertManager.</p>
<p>Vamos imaginar que você precisa criar um novo alerta para monitorar a quantidade de requisições simultâneas que o seu Nginx está recebendo. Para isso, você precisa criar uma nova regra no PrometheusRule. Podemos utilizar o mesmo arquivo <code>nginx-prometheus-rule.yaml</code> e adicionar a nova regra no final do arquivo:</p>
<pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1 # Versão da api do PrometheusRule
kind: PrometheusRule # Tipo do recurso
metadata: # Metadados do recurso (nome, namespace, labels)
  name: nginx-prometheus-rule
  namespace: monitoring
  labels: # Labels do recurso
    prometheus: k8s # Label que indica que o PrometheusRule será utilizado pelo Prometheus do Kubernetes
    role: alert-rules # Label que indica que o PrometheusRule contém regras de alerta
    app.kubernetes.io/name: kube-prometheus # Label que indica que o PrometheusRule faz parte do kube-prometheus
    app.kubernetes.io/part-of: kube-prometheus # Label que indica que o PrometheusRule faz parte do kube-prometheus
spec: # Especificação do recurso
  groups: # Lista de grupos de regras
  - name: nginx-prometheus-rule # Nome do grupo de regras
    rules: # Lista de regras
    - alert: NginxDown # Nome do alerta
      expr: up{job=&quot;nginx&quot;} == 0 # Expressão que será utilizada para disparar o alerta
      for: 1m # Tempo que a expressão deve ser verdadeira para que o alerta seja disparado
      labels: # Labels do alerta
        severity: critical # Label que indica a severidade do alerta
      annotations: # Anotações do alerta
        summary: &quot;Nginx is down&quot; # Título do alerta
        description: &quot;Nginx is down for more than 1 minute. Pod name: {{ $labels.pod }}&quot; # Descrição do alerta

    - alert: NginxHighRequestRate # Nome do alerta
        expr: rate(nginx_http_requests_total{job=&quot;nginx&quot;}[5m]) &gt; 10 # Expressão que será utilizada para disparar o alerta
        for: 1m # Tempo que a expressão deve ser verdadeira para que o alerta seja disparado
        labels: # Labels do alerta
            severity: warning # Label que indica a severidade do alerta
        annotations: # Anotações do alerta
            summary: &quot;Nginx is receiving high request rate&quot; # Título do alerta
            description: &quot;Nginx is receiving high request rate for more than 1 minute. Pod name: {{ $labels.pod }}&quot; # Descrição do alerta
</code></pre>
<p>Pronto, adicionamos uma nova definição de alerta em nosso PrometheusRule. Agora vamos atualizar o nosso PrometheusRule:</p>
<pre><code class="language-bash">kubectl apply -f nginx-prometheus-rule.yaml
</code></pre>
<p>Agora, vamos verificar se o PrometheusRule foi atualizado com sucesso:</p>
<pre><code class="language-bash">kubectl get prometheusrules -n monitoring nginx-prometheus-rule -o yaml
</code></pre>
<p>A saída deve ser parecida com essa:</p>
<pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {&quot;apiVersion&quot;:&quot;monitoring.coreos.com/v1&quot;,&quot;kind&quot;:&quot;PrometheusRule&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;labels&quot;:{&quot;app.kubernetes.io/name&quot;:&quot;kube-prometheus&quot;,&quot;app.kubernetes.io/part-of&quot;:&quot;kube-prometheus&quot;,&quot;prometheus&quot;:&quot;k8s&quot;,&quot;role&quot;:&quot;alert-rules&quot;},&quot;name&quot;:&quot;nginx-prometheus-rule&quot;,&quot;namespace&quot;:&quot;monitoring&quot;},&quot;spec&quot;:{&quot;groups&quot;:[{&quot;name&quot;:&quot;nginx-prometheus-rule&quot;,&quot;rules&quot;:[{&quot;alert&quot;:&quot;NginxDown&quot;,&quot;annotations&quot;:{&quot;description&quot;:&quot;Nginx is down for more than 1 minute. Pod name: {{ $labels.pod }}&quot;,&quot;summary&quot;:&quot;Nginx is down&quot;},&quot;expr&quot;:&quot;up{job=\&quot;nginx\&quot;} == 0&quot;,&quot;for&quot;:&quot;1m&quot;,&quot;labels&quot;:{&quot;severity&quot;:&quot;critical&quot;}},{&quot;alert&quot;:&quot;NginxHighRequestRate&quot;,&quot;annotations&quot;:{&quot;description&quot;:&quot;Nginx is receiving high request rate for more than 1 minute. Pod name: {{ $labels.pod }}&quot;,&quot;summary&quot;:&quot;Nginx is receiving high request rate&quot;},&quot;expr&quot;:&quot;rate(nginx_http_requests_total{job=\&quot;nginx\&quot;}[5m]) \u003e 10&quot;,&quot;for&quot;:&quot;1m&quot;,&quot;labels&quot;:{&quot;severity&quot;:&quot;warning&quot;}}]}]}}
  creationTimestamp: &quot;2023-03-01T14:14:00Z&quot;
  generation: 2
  labels:
    app.kubernetes.io/name: kube-prometheus
    app.kubernetes.io/part-of: kube-prometheus
    prometheus: k8s
    role: alert-rules
  name: nginx-prometheus-rule
  namespace: monitoring
  resourceVersion: &quot;24923&quot;
  uid: c0a6914d-9a54-4083-bdf8-ebfb5c19077d
spec:
  groups:
  - name: nginx-prometheus-rule
    rules:
    - alert: NginxDown
      annotations:
        description: 'Nginx is down for more than 1 minute. Pod name: {{ $labels.pod
          }}'
        summary: Nginx is down
      expr: up{job=&quot;nginx&quot;} == 0
      for: 1m
      labels:
        severity: critical
    - alert: NginxHighRequestRate
      annotations:
        description: 'Nginx is receiving high request rate for more than 1 minute.
          Pod name: {{ $labels.pod }}'
        summary: Nginx is receiving high request rate
      expr: rate(nginx_http_requests_total{job=&quot;nginx&quot;}[5m]) &gt; 10
      for: 1m
      labels:
        severity: warning
</code></pre>
<p>Pronto, o alerta foi criado com sucesso e você pode conferir no Prometheus ou no AlertManager.</p>
<p>Com o novo alerta, caso o Nginx esteja recebendo mais de 10 requisições por minuto, o alerta será disparado e você receberá uma notificação no Slack ou e-mail, claro, dependendo da configuração que você fez no AlertManager.</p>
<p>Acho que já podemos chamar o dia de hoje de sucesso absoluto, pois entendemos como funciona para criar um novo target para o Prometheus, bem como criar um novo alerta para o AlertManager/Prometheus.</p>
<p>Agora você precisa dar asas para a sua imaginação e sair criando tudo que é exemplo de de alerta que você bem entender, e claro, coloque mais serviços no seu cluster Kubernetes para que você possa monitorar tudo que é possível através do ServiceMonitor e PrometheusRule do Prometheus Operator, e claro, não esqueça de compartilhar com a gente o que você criou.</p>
<h3 id="chega-por-hoje-3"><a class="header" href="#chega-por-hoje-3">Chega por hoje!</a></h3>
<p>Acho que já vimos bastante coisa no dia de hoje, já podemos parar de adicionar conteúdo novo em sua caixola, mas isso não quer dizer que você tenha que parar de estudar! Bora rever todo o dia de hoje e colocar em prática tudo que você aprendeu.
Hoje podemos ver como adicionar novos targets e criar alertas nesse novo mundo, que é o Prometheus rodando no Kubernetes em alta disponibilidade, com o Prometheus Operator.</p>
<p>Ainda temos muito mais coisa para ver, então chega de falatório e nos vemos no próximo day!</p>
<h3 id="lição-de-casa-3"><a class="header" href="#lição-de-casa-3">Lição de casa</a></h3>
<p>Você precisa criar pelo menos um serviço novo, seja criativo e busque na internet algum coisa legal para usar, ou se quiser, crie um serviço e não esqueça de compartilhar conosco!</p>
<p>Além do serviço, você precisa criar um ServiceMonitor e alguns alertas no PrometheusRule para esse novo serviço.</p>
<p>Acho que é o suficiente para você se divertir e aprender bastante. #VAIIII</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="descomplicando-o-prometheus-6"><a class="header" href="#descomplicando-o-prometheus-6">Descomplicando o Prometheus</a></h1>
<h2 id="day-8"><a class="header" href="#day-8">DAY-8</a></h2>
<h3 id="o-que-iremos-ver-hoje-7"><a class="header" href="#o-que-iremos-ver-hoje-7">O que iremos ver hoje?</a></h3>
<p>Durante o dia de hoje, nós iremos passear um pouco pelas métricas que estamos coletando do nosso cluster Kubernetes. A ideia hoje é brincar um pouco mais com PromQL para extrair o máximo de valor das métricas que estamos coletando.</p>
<p>Quando estamos utilizando o Kube-Prometheus, temos que saber que já temos dezenas de novas métricas que nos mostram detalhes do comportamento do nosso cluster.</p>
<p>Outro ponto importante do dia de hoje será conhecer um pouco mais no detalhe, onde e como podemos mudar as características do nosso Prometheus e do nosso AlertManager.</p>
<p>Quando instalamos o Kube-Prometheus, e por consequência o Prometheus Operator, nós estamos expandindo o Kubernetes, dando maiores poderes e funções que antes ele não tinha. Entre os novos poderes que o Kubernetes agora possui estão os recursos que já vimos, como o PodMonitor, ServiceMonitor e o PrometheusRule.</p>
<p>Hoje ainda iremos conhecer mais dois recursos que o Prometheus Operator nos dá, um recurso chamado Prometheus e outro chamado AlertManager. Mas não vou dar detalhes agora, somente durante o dia de hoje.</p>
<h3 id="conteúdo-do-day-8"><a class="header" href="#conteúdo-do-day-8">Conteúdo do Day-8</a></h3>
<details>
<summary class="summary">DAY-8</summary>
<ul>
<li><a href="day-8/index.html#descomplicando-o-prometheus">Descomplicando o Prometheus</a>
<ul>
<li><a href="day-8/index.html#day-8">DAY-8</a>
<ul>
<li><a href="day-8/index.html#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="day-8/index.html#conte%C3%BAdo-do-day-8">Conteúdo do Day-8</a>
<ul>
<li><a href="day-8/index.html#vamos-brincar-com-as-m%C3%A9tricas-do-kubernetes">Vamos brincar com as métricas do Kubernetes</a>
<ul>
<li><a href="day-8/index.html#o-que-podemos-saber-sobre-os-nodes-do-nosso-cluster">O que podemos saber sobre os nodes do nosso cluster?</a>
<ul>
<li><a href="day-8/index.html#quantos-n%C3%B3s-temos-no-nosso-cluster">Quantos nós temos no nosso cluster?</a></li>
<li><a href="day-8/index.html#qual-a-quantidade-de-cpu-e-mem%C3%B3ria-que-cada-n%C3%B3-tem">Qual a quantidade de CPU e memória que cada nó tem?</a></li>
<li><a href="day-8/index.html#o-n%C3%B3-est%C3%A1-dispon%C3%ADvel-para-receber-novos-pods">O nó está disponível para receber novos pods?</a></li>
<li><a href="day-8/index.html#qual-a-quantidade-de-informa%C3%A7%C3%A3o-que-cada-n%C3%B3-est%C3%A1-recebendo-e-enviando">Qual a quantidade de informação que cada nó está recebendo e enviando?</a></li>
</ul>
</li>
<li><a href="day-8/index.html#quantos-pods-est%C3%A3o-rodando-em-cada-n%C3%B3">Quantos pods estão rodando em cada nó?</a></li>
</ul>
</li>
<li><a href="day-8/index.html#agora-vamos-saber-se-o-nosso-cluster-est%C3%A1-com-problemas">Agora vamos saber se o nosso cluster está com problemas</a>
<ul>
<li><a href="day-8/index.html#o-que-podemos-saber-sobre-os-pods-do-nosso-cluster">O que podemos saber sobre os pods do nosso cluster?</a>
<ul>
<li><a href="day-8/index.html#quantos-pods-est%C3%A3o-rodando-no-nosso-cluster">Quantos pods estão rodando no nosso cluster?</a></li>
<li><a href="day-8/index.html#quantos-pods-est%C3%A3o-com-problemas">Quantos pods estão com problemas?</a></li>
<li><a href="day-8/index.html#verificar-os-pods-e-os-limites-de-mem%C3%B3ria-e-cpu-configurados">Verificar os pods e os limites de memória e CPU configurados</a></li>
<li><a href="day-8/index.html#verificar-se-o-cluster-est%C3%A1-com-problemas-relacionados-ao-disco">Verificar se o cluster está com problemas relacionados ao disco</a></li>
<li><a href="day-8/index.html#verificar-se-o-cluster-est%C3%A1-com-problemas-relacionados-a-mem%C3%B3ria">Verificar se o cluster está com problemas relacionados a memória</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="day-8/index.html#e-como-saber-se-meus-deployments-est%C3%A3o-com-problemas">E como saber se meus deployments estão com problemas?</a>
<ul>
<li><a href="day-8/index.html#quantos-deployments-est%C3%A3o-rodando-no-meu-cluster">Quantos deployments estão rodando no meu cluster?</a></li>
<li><a href="day-8/index.html#quantos-deployments-est%C3%A3o-com-problemas">Quantos deployments estão com problemas?</a></li>
<li><a href="day-8/index.html#qual-o-status-dos-meus-deployments">Qual o status dos meus deployments?</a></li>
</ul>
</li>
<li><a href="day-8/index.html#e-como-saber-se-meus-servi%C3%A7os-est%C3%A3o-com-problemas">E como saber se meus serviços estão com problemas?</a>
<ul>
<li><a href="day-8/index.html#quantos-servi%C3%A7os-est%C3%A3o-rodando-no-meu-cluster">Quantos serviços estão rodando no meu cluster?</a></li>
<li><a href="day-8/index.html#todos-os-meus-servi%C3%A7os-est%C3%A3o-com-endpoints">Todos os meus serviços estão com endpoints?</a></li>
<li><a href="day-8/index.html#todos-os-meus-servi%C3%A7os-est%C3%A3o-com-endpoints-ativos">Todos os meus serviços estão com endpoints ativos?</a></li>
</ul>
</li>
<li><a href="day-8/index.html#como-eu-posso-modificar-as-configura%C3%A7%C3%B5es-do-meu-prometheus">Como eu posso modificar as configurações do meu Prometheus?</a>
<ul>
<li><a href="day-8/index.html#definindo-o-nosso-prometheus">Definindo o nosso Prometheus</a></li>
<li><a href="day-8/index.html#definindo-o-nosso-alertmanager">Definindo o nosso Alertmanager</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</details>
<h4 id="vamos-brincar-com-as-métricas-do-kubernetes"><a class="header" href="#vamos-brincar-com-as-métricas-do-kubernetes">Vamos brincar com as métricas do Kubernetes</a></h4>
<p>Muito bem, chegamos naquele momento que não precisaremos instalar mais nada, pelo menos por agora, pois já temos o nosso cluster Kubernetes com o Kube-Prometheus instalado.</p>
<p>O que vamos fazer agora é usufruir de todo o conhecimento já adquirido e também por todo o trabalho que já fizemos até esse momento.</p>
<p>Então agora é a hora de começar a brincar com as métricas e assim extrair informações sobre a saúde e performance do nosso cluster Kubernetes.</p>
<h5 id="o-que-podemos-saber-sobre-os-nodes-do-nosso-cluster"><a class="header" href="#o-que-podemos-saber-sobre-os-nodes-do-nosso-cluster">O que podemos saber sobre os nodes do nosso cluster?</a></h5>
<p>Algumas métricas que podemos extrair sobre os nodes do nosso cluster são:</p>
<ul>
<li>Quantos nós temos no nosso cluster?</li>
<li>Qual a quantidade de CPU e memória que cada nó tem?</li>
<li>O nó está disponível para receber novos pods?</li>
<li>Qual a quantidade de informação que cada nó está recebendo e enviando?</li>
<li>Quantos pods estão rodando em cada nó?</li>
</ul>
<p>Vamos responder essas quatro perguntas utilizando o PromQL e as métricas que estamos coletando do nosso cluster Kubernetes.</p>
<h6 id="quantos-nós-temos-no-nosso-cluster"><a class="header" href="#quantos-nós-temos-no-nosso-cluster">Quantos nós temos no nosso cluster?</a></h6>
<p>Para responder essa pergunta, vamos utilizar a métrica <code>kube_node_info</code> que nos mostra informações sobre os nós do nosso cluster. Podemos utilizar a função <code>count</code> para contar quantas vezes a métrica <code>kube_node_info</code> aparece no nosso cluster.</p>
<pre><code class="language-promql">count(kube_node_info)
</code></pre>
<p>No nosso cluster, temos 2  nós, então a resposta para essa pergunta é 2.</p>
<h6 id="qual-a-quantidade-de-cpu-e-memória-que-cada-nó-tem"><a class="header" href="#qual-a-quantidade-de-cpu-e-memória-que-cada-nó-tem">Qual a quantidade de CPU e memória que cada nó tem?</a></h6>
<p>Para responder essa pergunta, vamos utilizar a métrica <code>kube_node_status_allocatable</code> que nos mostra a quantidade de CPU e memória que cada nó tem disponível para ser utilizado.</p>
<pre><code class="language-promql">kube_node_status_allocatable
</code></pre>
<p>Aqui ele vai te trazer todas as informações sobre CPU, memória, pods, etc. Mas nós só queremos saber sobre CPU e memória, então vamos filtrar a nossa consulta para trazer apenas essas informações.</p>
<pre><code class="language-promql">kube_node_status_allocatable{resource=&quot;cpu&quot;}
kube_node_status_allocatable{resource=&quot;memory&quot;}
</code></pre>
<p>Fácil, agora precisamos somente de um pouco de matemática para converter os valores referente a memória para gigabytes.</p>
<pre><code class="language-promql">kube_node_status_allocatable{resource=&quot;memory&quot;} / 1024 / 1024 / 1024
</code></pre>
<p>Pronto, agora ficou um pouco mais fácil de ler a quantidade de memória que temos em cada nó.</p>
<h6 id="o-nó-está-disponível-para-receber-novos-pods"><a class="header" href="#o-nó-está-disponível-para-receber-novos-pods">O nó está disponível para receber novos pods?</a></h6>
<p>Para responder essa pergunta, vamos utilizar a métrica <code>kube_node_status_condition</code> que nos mostra o status de cada nó do nosso cluster.</p>
<pre><code class="language-promql">kube_node_status_condition{condition=&quot;Ready&quot;, status=&quot;true&quot;}
</code></pre>
<p>Com a consulta acima, estamos perguntando para métrica <code>kube_node_status_condition</code> se o nó está pronto para receber novos pods. Se o nó estiver pronto, ele vai retornar o valor 1, caso contrário, ele vai retornar o valor 0.</p>
<p>Isso porque estamos perguntando para a métrica <code>kube_node_status_condition</code> se o nó está com a condição <code>Ready</code> e se o status dessa condição é <code>true</code>, se mudassemos o status para <code>false</code>, ele iria retornar o valor 0. Simplão demais!</p>
<h6 id="qual-a-quantidade-de-informação-que-cada-nó-está-recebendo-e-enviando"><a class="header" href="#qual-a-quantidade-de-informação-que-cada-nó-está-recebendo-e-enviando">Qual a quantidade de informação que cada nó está recebendo e enviando?</a></h6>
<p>Aqui vamos levar em consideração que estamos falando de trafego de rede, o quanto o nosso nó está recebendo e enviando de dados pela rede.</p>
<p>Para isso vamos utilizar a métrica <code>node_network_receive_bytes_total</code> e <code>node_network_transmit_bytes_total</code> que nos mostra a quantidade de bytes que o nó está recebendo e enviando.</p>
<pre><code class="language-promql">node_network_receive_bytes_total
node_network_transmit_bytes_total
</code></pre>
<p>Perceba que a saída dessa consulta ela traz a quantidade de bytes por pod, mas nós queremos saber a quantidade de bytes por nó, então vamos utilizar a função <code>sum</code> para somar a quantidade de bytes que cada pod está recebendo e enviando.</p>
<pre><code class="language-promql">sum by (instance) (node_network_receive_bytes_total)
sum by (instance) (node_network_transmit_bytes_total)
</code></pre>
<p>Pronto, dessa forma teriamos a quantidade de bytes que cada nó está recebendo e enviando. No meu caso, como somente tenho dois nodes, o resultado foram duas linhas, uma para cada nó, mostrando a quantidade de bytes que cada nó está recebendo e enviando.</p>
<p>Agora vamos converter esses bytes para megabytes, para ficar mais fácil de ler.</p>
<pre><code class="language-promql">sum by (instance) (node_network_receive_bytes_total) / 1024 / 1024
sum by (instance) (node_network_transmit_bytes_total) / 1024 / 1024
</code></pre>
<p>Vamos para a próxima pergunta.</p>
<h5 id="quantos-pods-estão-rodando-em-cada-nó"><a class="header" href="#quantos-pods-estão-rodando-em-cada-nó">Quantos pods estão rodando em cada nó?</a></h5>
<p>Para responder essa pergunta, vamos utilizar a métrica <code>kube_pod_info</code> que nos mostra informações sobre os pods que estão rodando no nosso cluster.</p>
<pre><code class="language-promql">kube_pod_info
</code></pre>
<p>Caso eu queria saber o número de pods que estão rodando em cada nó, eu poderia utilizar a função <code>count</code> para contar quantas vezes a métrica <code>kube_pod_info</code> aparece em cada nó.</p>
<pre><code class="language-promql">count by (node) (kube_pod_info)
</code></pre>
<p>Pronto, agora eu sei quantos pods estão rodando em cada nó. No meu caso o meu cluster está bem sussa, somente 9 pods em um nó e 10 no outro, um dia de alegriaaaaa!</p>
<h4 id="agora-vamos-saber-se-o-nosso-cluster-está-com-problemas"><a class="header" href="#agora-vamos-saber-se-o-nosso-cluster-está-com-problemas">Agora vamos saber se o nosso cluster está com problemas</a></h4>
<p>Agora que já sabemos como extrair informações sobre a saúde e performance do nosso cluster Kubernetes, vamos aprender como podemos ser notificados caso o nosso cluster esteja com algum problema.</p>
<h5 id="o-que-podemos-saber-sobre-os-pods-do-nosso-cluster"><a class="header" href="#o-que-podemos-saber-sobre-os-pods-do-nosso-cluster">O que podemos saber sobre os pods do nosso cluster?</a></h5>
<p>Algumas métricas que podemos extrair sobre os pods do nosso cluster são:</p>
<ul>
<li>Quantos pods estão rodando no nosso cluster?</li>
<li>Quantos pods estão com problemas?</li>
<li>Verificar os pods e os limites de memória e CPU configurados</li>
<li>Verificar se o cluster está com problemas de espaço em disco</li>
<li>Verificar se o cluster está com problemas de consumo de memória</li>
</ul>
<h6 id="quantos-pods-estão-rodando-no-nosso-cluster"><a class="header" href="#quantos-pods-estão-rodando-no-nosso-cluster">Quantos pods estão rodando no nosso cluster?</a></h6>
<p>Essa é fácil e já sabemos qual a métrica que vai nos ajudar a responder essa pergunta.</p>
<pre><code class="language-promql">count(kube_pod_info)
</code></pre>
<p>Simples assim.</p>
<h6 id="quantos-pods-estão-com-problemas"><a class="header" href="#quantos-pods-estão-com-problemas">Quantos pods estão com problemas?</a></h6>
<p>Para responder essa pergunta, vamos utilizar a métrica <code>kube_pod_status_phase</code> que nos mostra o status de cada pod do nosso cluster.</p>
<pre><code class="language-promql">kube_pod_status_phase
</code></pre>
<p>Essa métrica irá nos mostrar o status de cada pod, se o pod está rodando, se ele está em erro, se ele está em execução, etc. Mas nós só queremos saber se o pod está em erro, então vamos filtrar a nossa consulta para trazer apenas os pods que estão em erro.</p>
<pre><code class="language-promql">kube_pod_status_phase{phase=&quot;Failed&quot;}
</code></pre>
<p>E se eu quiser saber o número de pods que estão em erro?</p>
<pre><code class="language-promql">count(kube_pod_status_phase{phase=&quot;Failed&quot;})
</code></pre>
<p>Vamos melhorar, eu quero saber o número de pods que estão em erro por namespace.</p>
<pre><code class="language-promql">count by (namespace) (kube_pod_status_phase{phase=&quot;Failed&quot;})
</code></pre>
<p>Ou ainda por nó.</p>
<pre><code class="language-promql">count by (node) (kube_pod_status_phase{phase=&quot;Failed&quot;})
</code></pre>
<p>Simples assim.</p>
<p>Os status que podemos utilizar são:</p>
<ul>
<li><code>Pending</code>: Pod está aguardando para ser executado</li>
<li><code>Running</code>: Pod está sendo executado</li>
<li><code>Succeeded</code>: Pod foi executado com sucesso</li>
<li><code>Unknown</code>: Pod está em um estado desconhecido</li>
<li><code>Failed</code>: Pod foi executado e falhou</li>
</ul>
<p>Agora é só escolher o que você quer saber e sair testando.</p>
<h6 id="verificar-os-pods-e-os-limites-de-memória-e-cpu-configurados"><a class="header" href="#verificar-os-pods-e-os-limites-de-memória-e-cpu-configurados">Verificar os pods e os limites de memória e CPU configurados</a></h6>
<p>Para responder essa pergunta, vamos utilizar a métrica <code>kube_pod_container_resource_limits</code> que nos mostra os limites de memória e CPU que cada pod está utilizando.</p>
<pre><code class="language-promql">kube_pod_container_resource_limits
</code></pre>
<p>Agora vamos filtrar a nossa consulta para trazer apenas os pods e os limites de memória e CPU configurados.</p>
<pre><code class="language-promql">kube_pod_container_resource_limits{resource=&quot;memory&quot;}
kube_pod_container_resource_limits{resource=&quot;cpu&quot;}
</code></pre>
<p>Assim você consegue saber quais os limites de memória e CPU que cada pod está utilizando.</p>
<h6 id="verificar-se-o-cluster-está-com-problemas-relacionados-ao-disco"><a class="header" href="#verificar-se-o-cluster-está-com-problemas-relacionados-ao-disco">Verificar se o cluster está com problemas relacionados ao disco</a></h6>
<p>Tem um status de node que é o <code>DiskPressure</code>, que significa que o nó está com problemas relacionados ao disco. Para saber se o nó está com esse status, vamos utilizar a métrica <code>kube_node_status_condition</code> que nos mostra o status de cada nó.</p>
<pre><code class="language-promql">kube_node_status_condition{condition=&quot;DiskPressure&quot;, status=&quot;true&quot;}
</code></pre>
<p>Se o valor retornado for 1, significa que o nó está com problemas relacionados ao disco, agora, se o valor for 0, significa que o nó está ok e você não precisa se preocupar.</p>
<h6 id="verificar-se-o-cluster-está-com-problemas-relacionados-a-memória"><a class="header" href="#verificar-se-o-cluster-está-com-problemas-relacionados-a-memória">Verificar se o cluster está com problemas relacionados a memória</a></h6>
<p>Tem um status de node que é o <code>MemoryPressure</code>, que significa que o nó está com problemas relacionados a memória. Para saber se o nó está com esse status, vamos utilizar a métrica <code>kube_node_status_condition</code> que nos mostra o status de cada nó.</p>
<pre><code class="language-promql">kube_node_status_condition{condition=&quot;MemoryPressure&quot;, status=&quot;true&quot;}
</code></pre>
<p>Se o valor retornado for 1, se prepare, pois você vai precisar entender o que está pegando com o seu nó, ou seja, terá um dia de trabalho pela frente. :D</p>
<h4 id="e-como-saber-se-meus-deployments-estão-com-problemas"><a class="header" href="#e-como-saber-se-meus-deployments-estão-com-problemas">E como saber se meus deployments estão com problemas?</a></h4>
<p>Algumas perguntas que podemos responder sobre os deployments do nosso cluster são:</p>
<ul>
<li>Quantos deployments estão rodando no meu cluster?</li>
<li>Quantos deployments estão com problemas?</li>
<li>Qual o status dos meus deployments?</li>
</ul>
<h6 id="quantos-deployments-estão-rodando-no-meu-cluster"><a class="header" href="#quantos-deployments-estão-rodando-no-meu-cluster">Quantos deployments estão rodando no meu cluster?</a></h6>
<p>Para responder essa pergunta, vamos utilizar a métrica <code>kube_deployment_status_replicas</code> que nos mostra o número de replicas que cada deployment está rodando.</p>
<pre><code class="language-promql">kube_deployment_status_replicas
</code></pre>
<p>Assim ele traz a lista de todos os deployments e o número de replicas que cada um está rodando.</p>
<h6 id="quantos-deployments-estão-com-problemas"><a class="header" href="#quantos-deployments-estão-com-problemas">Quantos deployments estão com problemas?</a></h6>
<p>Para responder essa pergunta, vamos utilizar a métrica <code>kube_deployment_status_replicas_unavailable</code> que nos mostra o número de replicas indisponíveis que cada deployment está rodando.</p>
<pre><code class="language-promql">kube_deployment_status_replicas_unavailable
</code></pre>
<p>Se tudo estiver bem, o valor retornado será 0, caso contrário, o valor retornado será o número de replicas indisponíveis.</p>
<h6 id="qual-o-status-dos-meus-deployments"><a class="header" href="#qual-o-status-dos-meus-deployments">Qual o status dos meus deployments?</a></h6>
<p>Para responder essa pergunta, vamos utilizar a métrica <code>kube_deployment_status_condition</code> que nos mostra o status de cada deployment.</p>
<pre><code class="language-promql">kube_deployment_status_condition
</code></pre>
<p>Com a consulta acima, você consegue saber o status de cada deployment, se ele está ok, se ele está com problemas, etc.</p>
<p>Se quisermos saber a lista de deployments com problemas, podemos utilizar a seguinte consulta.</p>
<pre><code class="language-promql">kube_deployment_status_condition{condition=&quot;Available&quot;, status=&quot;false&quot;}
</code></pre>
<p>Assim, se o valor retornado for 1, significa que o deployment está com problemas, caso contrário, significa que o deployment está ok.</p>
<h4 id="e-como-saber-se-meus-serviços-estão-com-problemas"><a class="header" href="#e-como-saber-se-meus-serviços-estão-com-problemas">E como saber se meus serviços estão com problemas?</a></h4>
<p>Algumas perguntas que podemos responder sobre os serviços do nosso cluster são:</p>
<ul>
<li>Quantos serviços estão rodando no meu cluster?</li>
<li>Todos os meus serviços estão com endpoints?</li>
<li>Todos os meus serviços estão com endpoints ativos?</li>
</ul>
<p>Vamos responder cada uma delas.</p>
<h6 id="quantos-serviços-estão-rodando-no-meu-cluster"><a class="header" href="#quantos-serviços-estão-rodando-no-meu-cluster">Quantos serviços estão rodando no meu cluster?</a></h6>
<p>Para responder essa pergunta, vamos utilizar a métrica <code>kube_service_info</code> que nos mostra o número de serviços que estão rodando no nosso cluster.</p>
<pre><code class="language-promql">kube_service_info
</code></pre>
<p>Assim ele traz a lista de todos os serviços que estão rodando no nosso cluster, com o valor 1.</p>
<h6 id="todos-os-meus-serviços-estão-com-endpoints"><a class="header" href="#todos-os-meus-serviços-estão-com-endpoints">Todos os meus serviços estão com endpoints?</a></h6>
<p>Para responder essa pergunta, vamos utilizar a métrica <code>kube_endpoint_address</code> que nos traz a lista de endpoints de cada serviço.</p>
<pre><code class="language-promql">kube_endpoint_address
</code></pre>
<p>Agora para saber os endpoints para um determinado serviço, vamos utilizar a seguinte consulta.</p>
<pre><code class="language-promql">kube_endpoint_address{endpoint=&quot;kube-dns&quot;}
</code></pre>
<h6 id="todos-os-meus-serviços-estão-com-endpoints-ativos"><a class="header" href="#todos-os-meus-serviços-estão-com-endpoints-ativos">Todos os meus serviços estão com endpoints ativos?</a></h6>
<p>Podemos ainda buscar por endpoints com o status <code>ready</code> igual a <code>false</code>, o que significa que o endpoint não está ativo.</p>
<pre><code class="language-promql">kube_endpoint_address{ready=&quot;false&quot;}
</code></pre>
<p>Se a lista for vazia, significa que todos os endpoints estão ativos!</p>
<p>Acho que já deu para brincar um pouco sobre as nossas métricas que estão vindo do Kubernetes! :D</p>
<p>Vamos brincar com algo novo agora!</p>
<h4 id="como-eu-posso-modificar-as-configurações-do-meu-prometheus"><a class="header" href="#como-eu-posso-modificar-as-configurações-do-meu-prometheus">Como eu posso modificar as configurações do meu Prometheus?</a></h4>
<p>Quando fizemos a instalação do nosso kube-prometheus, nós criamos alguns Custom Resource Definitions (CRDs) em nosso cluster. Nós já vimos alguns deles como o <code>ServiceMonitor</code> e o <code>PrometheusRule</code>, porém o nosso foco agora será em dois outros CRDs que são o <code>Prometheus</code> e o <code>Alertmanager</code>.</p>
<p>O <code>Prometheus</code> é o nosso recurso que vai nos permitir configurar o Prometheus que está rodando em nosso cluster. Já o <code>Alertmanager</code> é o nosso recurso que vai nos permitir configurar o Alertmanager.</p>
<p>Vamos focar nessa primeira parte no <code>Prometheus</code>.</p>
<h5 id="definindo-o-nosso-prometheus"><a class="header" href="#definindo-o-nosso-prometheus">Definindo o nosso Prometheus</a></h5>
<p>Como eu disse, o recurso <code>Prometheus</code> é o nosso recurso que vai nos permitir configurar o Prometheus, e assim customiza-lo para as nossas necessidades.</p>
<p>Esse arquivo é o arquivo que vem por padrão quando instalamos o kube-prometheus, ele fica dentro do diretório <code>manifests/</code> do nosso repositório do kube-prometheus e ele se chama <code>prometheus-prometheus.yaml</code>.</p>
<pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1 # Versão da API
kind: Prometheus # Tipo do recurso, no caso, Prometheus
metadata: # Informações sobre o recurso
  labels: # Labels que serão adicionadas ao nosso Prometheus
    app.kubernetes.io/component: prometheus # Label que indica que o recurso é um Prometheus
    app.kubernetes.io/instance: k8s # Label que indica que o recurso é o Prometheus do nosso cluster
    app.kubernetes.io/name: prometheus # Label que indica que o recurso é um Prometheus
    app.kubernetes.io/part-of: kube-prometheus # Label que indica que o recurso é parte do kube-prometheus
    app.kubernetes.io/version: 2.42.0 # Label que indica a versão do Prometheus
  name: k8s # Nome do nosso Prometheus
  namespace: monitoring # Namespace onde o Prometheus vai ser criado
spec: # Especificações do nosso Prometheus
  alerting: # Configurações de alerta 
    alertmanagers: # Lista de alertmanagers que o Prometheus vai utilizar
    - apiVersion: v2 # Versão da API do Alertmanager
      name: alertmanager-main # Nome do Alertmanager
      namespace: monitoring # Namespace onde o Alertmanager está rodando
      port: web # Porta que o Alertmanager está rodando
  enableFeatures: [] # Lista de features que serão habilitadas no Prometheus, no caso, nenhuma
  externalLabels: {} # Labels que serão adicionadas a todas as métricas que o Prometheus coletar
  image: quay.io/prometheus/prometheus:v2.42.0 # Imagem do Prometheus
  nodeSelector: # Node selector que será utilizado para definir em qual node o Prometheus vai rodar
    kubernetes.io/os: linux # Node selector que indica que o Prometheus vai rodar em nodes com o sistema operacional Linux
  podMetadata: # Metadata que será adicionada aos pods do Prometheus
    labels: # Labels que serão adicionadas aos pods do Prometheus
      app.kubernetes.io/component: prometheus # Label que indica que o pod é um Prometheus
      app.kubernetes.io/instance: k8s # Label que indica que o pod é o Prometheus do nosso cluster
      app.kubernetes.io/name: prometheus # Label que indica que o pod é um Prometheus
      app.kubernetes.io/part-of: kube-prometheus # Label que indica que o pod é parte do kube-prometheus
      app.kubernetes.io/version: 2.42.0 # Label que indica a versão do Prometheus
  podMonitorNamespaceSelector: {} # Namespace selector que será utilizado para selecionar os pods que serão monitorados pelo Prometheus
  podMonitorSelector: {} # Selector que será utilizado para selecionar os pods que serão monitorados pelo Prometheus
  probeNamespaceSelector: {} # Namespace selector que será utilizado para selecionar os pods que serão monitorados pelo Prometheus
  probeSelector: {} # Selector que será utilizado para selecionar os pods que serão monitorados pelo Prometheus
  replicas: 2 # Número de réplicas que o Prometheus vai ter
  resources: # Recursos que serão utilizados pelo Prometheus
    requests: # Recursos mínimos que serão utilizados pelo Prometheus
      memory: 400Mi # Memória mínima que será utilizada pelo Prometheus
  ruleNamespaceSelector: {} # Namespace selector que será utilizado para selecionar as regras que serão utilizadas pelo Prometheus
  ruleSelector: {} # Selector que será utilizado para selecionar as regras que serão utilizadas pelo Prometheus
  securityContext: # Security context que será utilizado pelo Prometheus
    fsGroup: 2000 # ID do grupo que será utilizado pelo Prometheus
    runAsNonRoot: true # Indica que o Prometheus vai rodar como um usuário não root
    runAsUser: 1000 # ID do usuário que será utilizado pelo Prometheus
  serviceAccountName: prometheus-k8s # Nome da service account que será utilizada pelo Prometheus
  serviceMonitorNamespaceSelector: {} # Namespace selector que será utilizado para selecionar os serviços que serão monitorados pelo Prometheus
  serviceMonitorSelector: {} # Selector que será utilizado para selecionar os serviços que serão monitorados pelo Prometheus
  version: 2.42.0 # Versão do Prometheus
</code></pre>
<p>Esse arquivo é o arquivo que vem por padrão quando instalamos o kube-prometheus, ele fica dentro do diretório <code>manifests/</code> do nosso repositório do kube-prometheus.</p>
<p>No arquivo acima, eu já adicionei comentários para explicar o que cada parte do arquivo faz, espero que tenha ajudado no entendimento.</p>
<p>Caso você queira fazer alguma alteração no Prometheus que já está rodando, basta alterar esse arquivo e aplicar as alterações no cluster.</p>
<p>Vamos imaginar que você queira adicionar limites de utilização de memória e CPU no Prometheus, para isso, basta adicionar as seguintes linhas no arquivo.</p>
<pre><code class="language-yaml">  resources: # Recursos que serão utilizados pelo Prometheus
    requests: # Recursos mínimos que serão utilizados pelo Prometheus
      memory: 400Mi # Memória mínima que será utilizada pelo Prometheus
      cpu: 500m # CPU mínima que será utilizada pelo Prometheus
    limits: # Recursos máximos que serão utilizados pelo Prometheus
      memory: 1Gi # Memória máxima que será utilizada pelo Prometheus
      cpu: 900m # CPU máxima que será utilizada pelo Prometheus
</code></pre>
<p>Preste atenção para adicionar esse conteúdo dentro do bloco <code>spec:</code> e com a mesma indentação.</p>
<p>Agora, vamos aplicar as alterações no cluster.</p>
<pre><code class="language-bash">$ kubectl apply -f prometheus.yaml
</code></pre>
<p>Agora, vamos verificar se o Prometheus foi atualizado.</p>
<pre><code class="language-bash">$ kubectl get pods -n monitoring prometheus-k8s-0 -o yaml | grep -A 10 resources:
  resources:
    limits:
      cpu: 900m
      memory: 1Gi
    requests:
      cpu: 500m
      memory: 400Mi
</code></pre>
<p>Como podemos ver, o Prometheus foi atualizado com os novos recursos.</p>
<p>Tem diversas outras configurações que podemos fazer no Prometheus, como por exemplo, adicionar regras para alertas, selectors para selecionar os pods que serão monitorados, etc.</p>
<p>Mas eu sugiro que você comece a testar e achar a melhor configuração para a sua necessidade. Mas lembre-se sempre, você precisa testar, você precisa explorar, você precisa aprender! Bora pra cima! </p>
<h5 id="definindo-o-nosso-alertmanager"><a class="header" href="#definindo-o-nosso-alertmanager">Definindo o nosso Alertmanager</a></h5>
<p>Da mesma forma como fizemos com o Prometheus, vamos conhecer o arquivo responsável por definir o nosso Alertmanager.</p>
<p>O arquivo abaixo é o arquivo que vem por padrão quando instalamos o kube-prometheus, ele fica dentro do diretório <code>manifests/</code> do nosso repositório do kube-prometheus, o nome dele é <code>alertmanager-alertmanager.yaml</code>.</p>
<pre><code class="language-yaml">
```yaml
apiVersion: monitoring.coreos.com/v1 # Versão da API do Alertmanager
kind: Alertmanager # Tipo do objeto que estamos criando
metadata: # Metadata do objeto que estamos criando
  labels: # Labels que serão adicionadas ao objeto que estamos criando
    app.kubernetes.io/component: alert-router # Label que indica que o objeto é um Alertmanager
    app.kubernetes.io/instance: main # Label que indica que o objeto é o Alertmanager principal
    app.kubernetes.io/name: alertmanager # Label que indica que o objeto é um Alertmanager
    app.kubernetes.io/part-of: kube-prometheus # Label que indica que o objeto é parte do kube-prometheus
    app.kubernetes.io/version: 0.25.0 # Label que indica a versão do Alertmanager
  name: main # Nome do objeto que estamos criando
  namespace: monitoring # Namespace onde o objeto que estamos criando será criado
spec: # Especificações do objeto que estamos criando
  image: quay.io/prometheus/alertmanager:v0.25.0 # Imagem que será utilizada pelo Alertmanager
  nodeSelector: # Selector que será utilizado para selecionar os nós que o Alertmanager vai rodar
    kubernetes.io/os: linux # Selector que indica que o Alertmanager vai rodar em nós Linux
  podMetadata: # Metadata que será adicionada aos pods do Alertmanager
    labels: # Labels que serão adicionadas aos pods do Alertmanager
      app.kubernetes.io/component: alert-router # Label que indica que o pod é um Alertmanager
      app.kubernetes.io/instance: main # Label que indica que o pod é o Alertmanager principal
      app.kubernetes.io/name: alertmanager # Label que indica que o pod é um Alertmanager
      app.kubernetes.io/part-of: kube-prometheus # Label que indica que o pod é parte do kube-prometheus
      app.kubernetes.io/version: 0.25.0 # Label que indica a versão do Alertmanager
  replicas: 3 # Número de réplicas que o Alertmanager vai ter
  resources: # Recursos que serão utilizados pelo Alertmanager
    limits: # Recursos máximos que serão utilizados pelo Alertmanager
      cpu: 100m # CPU máxima que será utilizada pelo Alertmanager
      memory: 100Mi # Memória máxima que será utilizada pelo Alertmanager
    requests: # Recursos mínimos que serão utilizados pelo Alertmanager
      cpu: 4m # CPU mínima que será utilizada pelo Alertmanager
      memory: 100Mi # Memória mínima que será utilizada pelo Alertmanager
  securityContext: # Security context que será utilizado pelo Alertmanager
    fsGroup: 2000 # ID do grupo que será utilizado pelo Alertmanager
    runAsNonRoot: true # Indica que o Alertmanager vai rodar como um usuário não root
    runAsUser: 1000 # ID do usuário que será utilizado pelo Alertmanager
  serviceAccountName: alertmanager-main # Nome da service account que será utilizada pelo Alertmanager
  version: 0.25.0 # Versão do Alertmanager
</code></pre>
<p>Adicionei também comentários para explicar o que cada parte do arquivo faz, assim fica fácil de você entender o que está acontecendo.
Sempre lembrando, veja sempre a documentação oficial para entender melhor o que cada configuração faz e todas as opções que você tem.</p>
<p>Caso você queira fazer alguma alteração no Alertmanager que já está rodando, basta alterar esse arquivo e aplicar as alterações no cluster com o comando abaixo.</p>
<pre><code class="language-bash">$ kubectl apply -f alertmanager-alertmanager.yaml
</code></pre>
<p>Pronto, seu Alertmanager foi atualizado com as novas configurações, caso você tenha feito alguma alteração. hahah :D</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="descomplicando-o-prometheus-7"><a class="header" href="#descomplicando-o-prometheus-7">Descomplicando o Prometheus</a></h1>
<h2 id="day-9"><a class="header" href="#day-9">DAY-9</a></h2>
<h3 id="o-que-iremos-ver-hoje-8"><a class="header" href="#o-que-iremos-ver-hoje-8">O que iremos ver hoje?</a></h3>
<p>Hoje é dia de falar sobre o relabeling, uma sensacional técnica para deixar as suas métricas ainda mais organizadas e fáceis de serem consultadas.</p>
<p>Com o relabeling você consegue adicionar novas labels, remover labels, juntar labels, e muito mais.</p>
<p>Tenho certeza que depois do dia de hoje você irá ver com outros olhos as métricas e como elas podem ser organizadas.</p>
<p>Basicamente hoje vamos brincar com o nosso ServiceMonitor/PodMonitor  e brincar com as labels, regras e relabelings... Relabeling tudo que é lugar. hahaha :D</p>
<p>Bora lá! </p>
<h3 id="conteúdo-do-day-9"><a class="header" href="#conteúdo-do-day-9">Conteúdo do Day-9</a></h3>
<details>
<summary class="summary">DAY-9</summary>
<ul>
<li><a href="day-9/index.html#descomplicando-o-prometheus">Descomplicando o Prometheus</a>
<ul>
<li><a href="day-9/index.html#day-9">DAY-9</a>
<ul>
<li><a href="day-9/index.html#o-que-iremos-ver-hoje">O que iremos ver hoje?</a></li>
<li><a href="day-9/index.html#conte%C3%BAdo-do-day-9">Conteúdo do Day-9</a></li>
<li><a href="day-9/index.html#o-que-%C3%A9-relabeling">O que é Relabeling?</a>
<ul>
<li><a href="day-9/index.html#como-funciona-o-relabeling">Como funciona o Relabeling?</a></li>
<li><a href="day-9/index.html#exemplos-de-uso-do-relabeling">Exemplos de uso do Relabeling</a>
<ul>
<li><a href="day-9/index.html#removendo-uma-m%C3%A9trica-baseado-em-uma-label"> Removendo uma métrica baseado em uma label</a></li>
<li><a href="day-9/index.html#junta-duas-labels-em-uma-s%C3%B3">Junta duas labels em uma só</a></li>
<li><a href="day-9/index.html#adicionando-uma-nova-label">Adicionando uma nova label</a></li>
<li><a href="day-9/index.html#armazenando-somente-m%C3%A9tricas-espec%C3%ADficas">Armazenando somente métricas específicas</a></li>
<li><a href="day-9/index.html#mapeando-todas-as-labels-do-kubernetes">Mapeando todas as labels do Kubernetes</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="day-9/index.html#as-meta-labels-do-prometheus">As meta labels do Prometheus</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</details>
<h4 id="o-que-é-relabeling"><a class="header" href="#o-que-é-relabeling">O que é Relabeling?</a></h4>
<p>Hoje iremos falar sobre o relabeling, que é uma das funcionalidades mais poderosas do Prometheus. O relabeling é uma funcionalidade que permite que você faça alterações nos metadados de seus targets, como por exemplo, adicionar labels, remover labels, modificar labels, etc.</p>
<p>Por exemplo, você pode usar o relabel para renomear uma label ou removê-la completamente, ou para adicionar uma nova label com um valor específico. O relabel também pode ser usado para filtrar métricas com base em suas labels ou para ajustar seus valores.</p>
<h5 id="como-funciona-o-relabeling"><a class="header" href="#como-funciona-o-relabeling">Como funciona o Relabeling?</a></h5>
<p>O relabeling é feito através de regras que são aplicadas a cada target. Essas regras são definidas no arquivo de configuração do Prometheus, no bloco <code>relabelings</code> conforme o exemplo abaixo:</p>
<pre><code class="language-yaml">      relabelings: # regras de relabeling
        - sourceLabels: [__meta_kubernetes_service_label_team] # label original que será usada como base para a regra
          regex: '(.*)' # regex que será aplicada na label original
          targetLabel: team # label que será criada
          replacement: '${1}' # valor que será atribuído a label criada, neste caso, o valor da label original
</code></pre>
<p>Somente para ficar mais claro, vou colocar abaixo todo o nosso arquivo de configuração do <code>ServiceMonitor</code>:</p>
<pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1 # versão da API
kind: ServiceMonitor # tipo de recurso, no caso, um ServiceMonitor do Prometheus Operator
metadata: # metadados do recurso
  name: nginx-servicemonitor # nome do recurso
  labels: # labels do recurso
    app: nginx # label que identifica o app
spec: # especificação do recurso
  selector: # seletor para identificar os pods que serão monitorados
    matchLabels: # labels que identificam os pods que serão monitorados
      app: nginx # label que identifica o app que será monitorado
  endpoints: # endpoints que serão monitorados
    - interval: 10s # intervalo de tempo entre as requisições
      path: /metrics # caminho para a requisição
      targetPort: 9113 # porta do target
      relabelings: # regras de relabeling
        - sourceLabels: [__meta_kubernetes_service_label_team] # label original que será usada como base para a regra
          regex: '(.*)' # regex que será aplicada na label original
          targetLabel: team # label que será criada
          replacement: '${1}' # valor que será atribuído a label criada, neste caso, o valor da label original
</code></pre>
<p>Percebe, somente adicionamos o bloco <code>relabelings</code> e dentro dele adicionamos as regras de relabeling. Agora, vamos entender como funciona cada uma dessas regras.</p>
<ul>
<li><code>sourceLabels</code>: é a label original que será usada como base para a regra. Neste caso, estamos usando a label <code>__meta_kubernetes_service_label_team</code> que vou explicar logo menos o que significa.</li>
<li><code>regex</code>: é a regex que será aplicada na label original. Neste caso, estamos usando a regex <code>(.*)</code> que significa que será aplicada a regex em toda a label original.</li>
<li><code>targetLabel</code>: é a label que será criada. Neste caso, estamos criando a label <code>team</code>.</li>
<li><code>replacement</code>: é o valor que será atribuído a label criada. Neste caso, estamos atribuindo o valor da label original.</li>
</ul>
<p>Simples demais, né? Evidente que existem outras regras que podem ser usadas, e tudo vai depender da sua necessidade e da sua criatividade! Acessar a documentação oficial do projeto com certa frequência é super importante, portanto, o faça!</p>
<h5 id="exemplos-de-uso-do-relabeling"><a class="header" href="#exemplos-de-uso-do-relabeling">Exemplos de uso do Relabeling</a></h5>
<h6 id="removendo-uma-métrica-baseado-em-uma-label"><a class="header" href="#removendo-uma-métrica-baseado-em-uma-label">Removendo uma métrica baseado em uma label</a></h6>
<p>Essa regra de relabeling está definindo que a etiqueta endpoint será removida (drop) das métricas coletadas pelo Prometheus. Isso significa que todas as métricas coletadas que possuem essa etiqueta serão descartadas e não estarão disponíveis para consulta posterior.</p>
<p>É sempre muito bom usar essa regra com muita atenção, pois ela pode fazer com que você perca muitas métricas que podem ser muito importantes para você.</p>
<pre><code class="language-yaml">      relabelings: # regras de relabeling
        - sourceLabels: [app] # label original que será usada como base para a regra
          action: drop # ação que será aplicada na label original
</code></pre>
<p>Com isso, toda métrica que possuir a label <code>app</code> não será coletada pelo Prometheus.</p>
<h6 id="junta-duas-labels-em-uma-só"><a class="header" href="#junta-duas-labels-em-uma-só">Junta duas labels em uma só</a></h6>
<p>Caso queira juntar duas labels em uma só, é super simples. </p>
<p>Em nosso exemplo, vamos unir as labels app e team para criar um label chamado <code>app_team</code>:</p>
<pre><code class="language-yaml">      relabelings: # regras de relabeling
        - sourceLabels: [app, team] # labels originais que serão usadas como base para a regra
          targetLabel: app_team # label que será criada
          regex: (.*);(.*) # regex que será aplicada nas labels originais, neste caso, estamos usando uma regex que irá separar as labels originais em dois grupos
          replacement: ${1}_${2} # junção das labels originais
</code></pre>
<p>Com isso, criamos uma terceira label chamada <code>app_team</code> que é a junção das labels <code>app</code> e <code>team</code>.</p>
<h6 id="adicionando-uma-nova-label"><a class="header" href="#adicionando-uma-nova-label">Adicionando uma nova label</a></h6>
<p>Vamos imaginar agora que queremos adicionar uma nova label em nossa métrica. No nosso exemplo, nós estamos com o nosso cluster EKS rodando na região <code>us-east-1</code>, certo? E se nós adicionarmos uma label chamada <code>region</code> com o valor <code>us-east-1</code> em todas as nossas métricas para esse <code>target</code>? Seria legal hein!</p>
<p>Para fazer isso, basta adicionar a seguinte regra:</p>
<pre><code class="language-yaml">      relabelings: # regras de relabeling
        - sourceLabels: [] # Valor vazio, pois não estamos usando nenhuma label original
          targetLabel: region # label que será criada
          replacement: us-east-1 # valor que será atribuído a label criada
</code></pre>
<h6 id="armazenando-somente-métricas-específicas"><a class="header" href="#armazenando-somente-métricas-específicas">Armazenando somente métricas específicas</a></h6>
<p>Agora é o seguinte, eu somente quero armazenas as métricas que possuem a label <code>app</code> com o valor <code>nginx</code> ou <code>redis</code>. Como eu faço isso?</p>
<p>Bom, é super simples, basta adicionar a seguinte regra:</p>
<pre><code class="language-yaml">      relabelings: # regras de relabeling
        - sourceLabels: [app] # label original que será usada como base para a regra
          regex: '(nginx|redis)' # regex que será aplicada na label original
          action: keep # ação que será aplicada na label original
</code></pre>
<p>Perceba que estamos usando a regex <code>(nginx|redis)</code> que significa que iremos armazenar somente as métricas que possuem a label <code>app</code> com o valor <code>nginx</code> ou <code>redis</code> e ainda estamos usando a ação <code>keep</code> que significa que iremos armazenar somente as métricas que possuem essas labels.</p>
<h6 id="mapeando-todas-as-labels-do-kubernetes"><a class="header" href="#mapeando-todas-as-labels-do-kubernetes">Mapeando todas as labels do Kubernetes</a></h6>
<p>Uma forma super simples de adicionar todas as labels que estão declaradas em um service ou pod é usando a meta label <code>__meta_kubernetes_service_label_&lt;nome_da_label&gt;</code> ou <code>__meta_kubernetes_pod_label_&lt;nome_da_label&gt;</code>. </p>
<p>Porém e se quisermos fazer isso de forma dinâmica? Como podemos fazer isso?</p>
<p>Vamos para um exemplo onde iremos pegar todas as labels de um service e adicionar em uma métrica. Vamos supor que temos um service com o seguinte arquivo:</p>
<pre><code class="language-yaml">apiVersion: v1 # versão da API
kind: Service # tipo de recurso, no caso, um Service
metadata: # metadados do recurso
  name: nginx-svc # nome do recurso
  labels: # labels do recurso
    app: nginx # label para identificar o svc
    team: platform-engineering
    environment: production
    version: 1.0.0
    type: web
spec: # especificação do recurso
  ports: # definição da porta do svc 
  - port: 9113 # porta do svc
    name: metrics # nome da porta
  selector: # seletor para identificar os pods/deployment que esse svc irá expor
    app: nginx # label que identifica o pod/deployment que será exposto
</code></pre>
<p>Adicionamos algumas tags em nosso arquivo somente para ficar mais fácil de entender o exemplo.</p>
<p>Agora vamos adicionar a nossa regra para pegar todas as labels desse service e adiciona-las como labels da nossa métrica.</p>
<pre><code class="language-yaml">      relabelings: # regras de relabeling
        - action: labelmap # ação que será aplicada na label original
          regex: __meta_kubernetes_service_label_(.+) # regex que será aplicada na label original
</code></pre>
<p>No exemplo acima, usamos a <code>action</code> <code>labelmap</code> que irá mapear todas as labels do service para labels da métrica. Usamos a regex <code>__meta_kubernetes_service_label_(.+)</code> que irá pegar todas as labels do service, e através do <code>.+</code> irá mapear todas as labels para labels da métrica.</p>
<p>Com isso, todas as labels que estão declaradas no service serão adicionadas como labels da métrica. \o/</p>
<h4 id="as-meta-labels-do-prometheus"><a class="header" href="#as-meta-labels-do-prometheus">As meta labels do Prometheus</a></h4>
<p>Um coisa que é super importante é ter um bom entendimento sobre as meta labels que o Prometheus disponibiliza. Essas meta labels são labels que são adicionadas automaticamente pelo Prometheus e que podem ser usadas para criar regras de relabeling entre outras coisas.</p>
<p>Por exemplo, temos a meta label <code>__meta_kubernetes_service_label_team</code> que usei no exemplo anterior. Essa meta label é adicionada automaticamente, e possui a seguinte estrutura: <code>__meta_kubernetes_service_label_&lt;nome_da_label&gt;</code>.</p>
<p>No caso, em meu service eu adicionei a label <code>team</code> com o valor <code>platform-engineering</code>. Vamos dar um olhada como ficou o arquivo onde definimos o service:</p>
<pre><code class="language-yaml">apiVersion: v1 # versão da API
kind: Service # tipo de recurso, no caso, um Service
metadata: # metadados do recurso
  name: nginx-svc # nome do recurso
  labels: # labels do recurso
    app: nginx # label para identificar o svc
    team: platform-engineering
spec: # especificação do recurso
  ports: # definição da porta do svc 
  - port: 9113 # porta do svc
    name: metrics # nome da porta
  selector: # seletor para identificar os pods/deployment que esse svc irá expor
    app: nginx # label que identifica o pod/deployment que será exposto
</code></pre>
<p>Veja que agora nós temos a label <code>team</code> com o valor <code>platform-engineering</code>, sendo assim o Prometheus vai adicionar a meta label <code>__meta_kubernetes_service_label_team</code> com o valor <code>platform-engineering</code> em todas as métricas que forem coletadas a partir desse service.</p>
<p>Simples demais, como tudo no Prometheus e Kubernetes!</p>
<p>Abaixo vou listar algumas das meta labels que o Prometheus disponibiliza:</p>
<ul>
<li><code>__meta_kubernetes_pod_name</code>: nome do pod</li>
<li><code>__meta_kubernetes_pod_node_name</code>: nome do node onde o pod está rodando</li>
<li><code>__meta_kubernetes_pod_label_&lt;labelname&gt;</code>: valor da label do pod</li>
<li><code>__meta_kubernetes_pod_annotation_&lt;annotationname&gt;</code>: valor da annotation do pod</li>
<li><code>__meta_kubernetes_pod_container_name</code>: nome do container</li>
<li><code>__meta_kubernetes_pod_container_port_number</code>: número da porta do container</li>
<li><code>__meta_kubernetes_pod_container_port_name</code>: nome da porta do container</li>
<li><code>__meta_kubernetes_service_name</code>: nome do service</li>
<li><code>__meta_kubernetes_service_label_&lt;labelname&gt;</code>: valor da label do service</li>
<li><code>__meta_kubernetes_service_annotation_&lt;annotationname&gt;</code>: valor da annotation do service</li>
<li><code>__meta_kubernetes_endpoint_port_name</code>: nome da porta do endpoint</li>
<li><code>__meta_kubernetes_namespace</code>: namespace do pod/service/deployment</li>
<li><code>__meta_kubernetes_node_name</code>: nome do node</li>
<li><code>__meta_kubernetes_node_label_&lt;labelname&gt;</code>: valor da label do node</li>
<li><code>__meta_kubernetes_node_annotation_&lt;annotationname&gt;</code>: valor da annotation do node</li>
<li><code>__meta_kubernetes_node_address_&lt;addressname&gt;</code>: valor do endereço do node</li>
</ul>
<p>A lista é enorme e você pode conferir no link abaixo:</p>
<p>https://prometheus.io/docs/prometheus/latest/configuration/configuration/#kubernetes_sd_config</p>
<p>E claro que nem tudo é sobre Kubernetes! Existem me labels que não são específicas do Kubernetes, como por exemplo, caso você esteja utilizando a AWS, você pode usar a meta label <code>__meta_ec2_instance_id</code> para pegar o ID da instância ou ainda o <code>__meta_ec2_public_ip</code> para pegar o IP público de uma instância.</p>
<p>Agora, se você estiver utilizando o GCP, você pode usar a meta label <code>__meta_gce_instance_id</code> para pegar o ID da instância ou ainda o <code>__meta_gce_public_ip</code> para pegar o IP público de uma instância, padrão é tudo, não é mesmo?</p>
<p>Se for Azure? Claro que temos e ainda, seguimos o mesmo padrão, ou melhor, quase o mesmo padrão. A meta label <code>__meta_azure_machine_id</code> é para pegar o ID da instância e o <code>__meta_azure_machine_public_ip</code> para pegar o IP público de uma instância.</p>
<p>Mais uma vez, da um olhada na documentação oficial do projeto para saber mais sobre as meta labels disponíveis.</p>
<p>Segue o link para a documentação oficial: https://prometheus.io/docs/prometheus/latest/configuration/configuration/</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->

        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </body>
</html>